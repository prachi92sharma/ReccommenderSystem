learning active learning data paper suggest novel data driven approach active learning key idea train regressor predicts expected error reduction candidate sample particular learning state formulating query selection procedure regression problem restricted working existing heuristics instead learn strategies based experience previous outcomes show strategy learnt either simple synthetic datasets subset domain specific data method yields strategies work well real data wide range domains
scalable variational inference dynamical systems gradient matching promising tool learning parameters state dynamics ordinary differential equations grid free inference approach fully observable systems times competitive numerical integration however many real world applications sparse observations available even unobserved variables included model description cases gradient matching methods difficult apply simply provide satisfactory results despite high computational cost numerical integration still gold standard many applications using existing gradient matching approach propose scalable variational inference framework infer states parameters simultaneously offers computational speedups improved accuracy works well even model misspecifications partially observable system
active learning peers paper addresses challenge learning peers online multitask setting instead always requesting label human oracle proposed method first determines learner task acquire label sufficient confidence peers either task similarity weighted sum single similar task saves oracle query later use difficult cases queries human oracle paper develops new algorithm exhibit behavior proves theoretical mistake bound method compared best linear predictor hindsight experiments three multitask learning benchmark datasets show clearly superior performance baselines assuming task independence learning oracle learning peer tasks
gradient episodic memory continuum learning major obstacle towards artificial intelligence poor ability current models reuse knowledge acquired past quickly learn new tasks forgetting previously learned work formalize emph continuum learning setting training examples emph iid generated continuous stream tasks unknown relationship first propose new set metrics continuum learning characterize learning systems terms average accuracy also terms ability transfer knowledge previous future tasks second propose model continuum learning termed gradient episodic memory gem reduces forgetting allows potential improvements performance previous tasks experiments variants mnist cifar100 datasets demonstrate strong performance model compared variety state art contenders
consistent multitask learning nonlinear output relations key multitask learning exploiting relationships different tasks improve prediction performance relations linear regularization approaches used successfully however practice assuming tasks linearly related might restrictive allowing nonlinear structures challenge paper tackle issue casting problem within framework structured prediction main contribution novel algorithm learning multiple tasks related system nonlinear equations joint outputs need satisfy show algorithm consistent efficiently implemented experimental results show potential proposed method
joint distribution optimal transportation domain adaptation paper deals unsupervised domain adaptation problem one wants estimate prediction function
given target domain without labeled sample exploiting knowledge available source domain labels known work makes following assumption exists non linear transformation joint feature label space distributions two domain propose solution problem optimal transport allows recover estimated target ptf optimizing simultaneously optimal coupling show method corresponds minimization bound target error provide efficient algorithmic solution convergence proved versatility approach terms class hypothesis loss functions demonstrated real world classification regression problems reach surpass state art results
learning multiple tasks deep relationship networks deep networks trained large scale data learn transferable features promote learning multiple tasks deep features eventually transition general specific along deep networks fundamental problem exploit relationship across different tasks improve feature transferability task specific layers paper propose deep relationship networks drn discover task relationship based novel tensor normal priors parameter tensors multiple task specific layers deep convolutional networks jointly learning transferable features task relationships drn able alleviate dilemma negative transfer feature layers transfer classifier layer extensive experiments show drn yields state art results standard multi task learning benchmarks
label efficient learning transferable representations acrosss domains tasks propose framework learns representation transferable across different domains tasks data efficient manner approach battles domain shift domain adversarial loss generalizes embedding novel task using metric learning based approach model simultaneously optimized labeled source data unlabeled sparsely labeled data target domain method shows compelling results novel classes within new domain even labeled examples per class available outperforming prevalent fine tuning approach addition demonstrate effectiveness framework transfer learning task image object recognition video action recognition
matching neural paths transfer recognition correspondence search many machine learning tasks require finding per part correspondences objects work focus low level correspondences highly ambiguous matching problem propose use hierarchical semantic representation objects coming convolutional neural network solve ambiguity training low level correspondence prediction directly might option domains ground truth correspondences hard obtain show transfer recognition used avoid training idea mark parts matching features close levels convolutional feature hierarchy neural paths although overall number paths exponential number layers propose polynomial algorithm aggregating single backward pass empirical validation done task stereo correspondence demonstrates achieve competitive results among methods use labeled target domain data
deep neural networks suffer crowding crowding visual effect suffered humans object recognized isolation longer recognized objects called clutter placed close work study effect crowding artificial deep neural networks dnns object recognition analyze deep convolutional neural networks dcnns well extension dcnns multi scale change receptive field size convolution filters position image called eccentricity dependent models latter networks recently proposed modeling feedforward path primate visual cortex results reveal incorporating clutter images training set learning dnns lead robustness clutter seen training also dnns trained objects isolation find recognition accuracy dnns falls closer clutter target object clutter find visual similarity target clutter also plays role pooling early layers dnn leads crowding finally show eccentricity dependent model trained objects isolation recognize target objects clutter objects near center image whereas dcnn cannot
svcca singular vector canonical correlation analysis deep understanding improvement continuing empirical successes deep networks becomes increasingly important develop better methods understanding training models representations learned within paper propose singular value canonical correlation analysis svcca tool quickly comparing two representations way invariant affine transform allowing comparison different layers networks fast compute allowing comparisons calculated previous methods deploy tool measure intrinsic dimensionality layers showing cases needless parameterization probe learning dynamics throughout training finding networks converge final representations bottom show class specific information networks formed suggest new training regimes simultaneously save computation overfit less
neural expectation maximization many real world tasks reasoning physical interaction require iden tification manipulation conceptual entities first step towards solving tasks automated discovery symbol like representations distributed disentangled paper explicitly formalize problem inference spatial mixture model component parametrized neural network based expectation maximization framework derive differentiable clustering method simultaneously learns group represent individual entities evaluate method sequential perceptual grouping task find accurately able recover constituent objects demonstrate learned representations useful predictive coding
pointnet deep hierarchical feature learning point sets metric space prior works study deep learning point sets pointnet pioneer direction however design pointnet capture local structures induced metric space points live limiting ability recognize fine grained patterns generalizability complex scenes work introduce hierarchical neural network applies pointnet recursively nested partitioning input point set exploiting metric space distances network able learn local features increasing contextual scales observation point sets usually sampled varying densities results greatly decreased performance networks trained uniform densities propose novel set learning layers adaptively combine features multiple scales experiments show network called pointnet able learn deep point set features efficiently robustly particular results significantly better state art obtained challenging benchmarks point clouds
preserving proximity global ranking node embedding investigate unsupervised generative approach network embedding multi task siamese neural network structure formulated connect embedding vectors objective preserve global node ranking local proximity nodes provide deeper analysis connect proposed proximity objective link prediction community detection network show model satisfy following design properties scalability asymmetry unity simplicity experiment results verify design properties also demonstrate superior performance learning rank classification regression link prediction tasks
unsupervised transformation learning via convex relaxations goal extract meaningful transformations data thickness lines handwriting lighting portrait raw images work propose unsupervised approach learn transformations based reconstructing nearest neighbors using linear combination transformations derive new algorithm unsupervised linear transformation learning handwritten digits celebrity portrait datasets show even linear transformations method extracts meaningful transformations generates visually high quality transformed outputs moreover method semiparametric model data distribution allowing learned transformations extrapolate training data work new types images
hunt unique stable sparse fast feature learning graphs purpose learning graphs hunt graph representation exhibit certain uniqueness stability sparsity properties also amenable fast computation leads graph representation based discovery family graph spectral distances denoted fgsd prove possess desired properties evaluate quality graph features produced fgsd demonstrate utility apply graph classification problem extensive experiments show simple svm based classification algorithm driven powerful fgsd based graph features significantly outperforms sophisticated state art algorithms unlabeled node datasets terms accuracy speed also yields competitive results labeled datasets despite fact utilize node label information
deep subspace clustering network present novel deep neural network architecture unsupervised subspace clustering architecture built upon deep auto encoders non linearly map input data latent space key idea introduce novel self expressive layer encoder decoder mimic self expressiveness property proven effective traditional subspace clustering differentiable new self expressive layer provides simple effective way learn pairwise affinities data points standard back propagation procedure nonlinear neural network based method able cluster data points complex often nonlinear structures propose pre training fine tuning strategies let effectively learn parameters subspace clustering networks experiments show proposed method significantly outperforms state art unsupervised subspace clustering methods
learning graph embeddings embedding propagation propose embedding propagation unsupervised learning framework graph structured data learns vector representations graphs passing two types messages neighboring nodes forward messages consist label representations representations words features associated nodes backward messages consist gradients results aggregating representations applying reconstruction loss node representations finally computed representation labels significantly fewer parameters hyperparameters instance competitive often outperforms state art unsupervised learning methods range benchmark data sets
unsupervised sequence classification using sequential output statistics consider learning sequence classifier without labeled data using sequential output statistics problem highly valuable since obtaining labels training data often costly sequential output statistics language models could obtained independently input data thus low cost address problem propose unsupervised learning cost function study properties show compared earlier works less inclined stuck trivial solutions avoids need strong generative model although harder optimize functional form stochastic primal dual gradient method developed effectively solve problem experiment results real world datasets demonstrate new unsupervised learning method gives drastically lower errors baseline methods specifically reaches test errors twice obtained fully supervised learning
context selection embedding models word embeddings effective tool analyze language recently extended model types data beyond text items recommendation systems embedding models consider probability target observation word item conditioned elements context words items paper show conditioning elements context optimal instead improve predictions quality embedding representations modeling probability target conditioned subset elements context develop model account use amortized variational inference automatically choose subset experiments demonstrate model outperforms standard embedding methods datasets different domains terms held predictions quality embedding representations
probabilistic rule realization selection abstraction realization bilateral processes key deriving intelligence creativity many domains two processes approached emph rules high level principles reveal invariances within similar yet diverse examples probabilistic setting discrete input spaces focus rule realization problem generates input sample distributions follow given rules ambitiously beyond mechanical realization takes whatever given instead ask proactively selecting reasonable rules realize goal demanding practice since initial rule set may always consistent thus intelligent compromises needed formulate rule realization selection two strongly connected components within single symmetric convex problem derive efficient algorithm works large scale taking music compositional rules main example throughout paper demonstrate model efficiency music realization composition also music interpretation understanding analysis
trimmed density ratio estimation density ratio estimation become versatile tool machine learning community recently however due unbounded nature density ratio estimation vulnerable corrupted data points often pushes estimated ratio toward infinity paper present robust estimator automatically identifies trims outliers proposed estimator convex formulation global optimum obtained via subgradient descent analyze parameter estimation error estimator high dimensional settings experiments conducted verify effectiveness estimator
minimax optimal algorithm crowdsourcing consider problem accurately estimating reliability workers based noisy labels provide fundamental question crowdsourcing propose novel lower bound minimax estimation error applies estimation procedure propose triangular estimation algorithm estimating reliability workers low complexity may implemented streaming setting labels provided workers real time rely iterative procedure prove minimax optimal matches lower bound conclude assessing performance state art algorithms synthetic real world data
introspective classification convolutional nets propose introspective convolutional networks icn emphasize importance convolutional neural networks empowered generative capabilities employ reclassification synthesis algorithm perform training using formulation stemmed bayes theory icn tries iteratively synthesize pseudo negative samples enhance improving classification single cnn classifier learned time generative able directly synthesize new samples within discriminative model conduct experiments benchmark datasets including mnist cifar svhn using state art cnn architectures observe improved classification results
adaptive classification prediction budget propose novel adaptive approximation approach test time resource constrained prediction given input instance test time gating function identifies prediction model input among collection models objective minimize overall average cost without sacrificing accuracy learn gating prediction models fully labeled training data means bottom strategy novel bottom method first trains high accuracy complex model low complexity gating prediction model subsequently learnt adaptively approximate high accuracy model regions low cost models capable making highly accurate predictions pose empirical loss minimization problem cost constraints jointly train gating prediction models number benchmark datasets method outperforms state art achieving higher accuracy cost
learning feature evolvable streams learning streaming data attracted much attention past years though studies consider data stream fixed features real practice features may evolvable example features data gathered limited lifespan sensors change sensors substituted new ones paper propose novel learning paradigm feature evolvable streaming learning old features would vanish new features occur rather relying current features attempt recover vanished features exploit improve performance specifically learn two models recovered features current features respectively benefit recovered features develop two ensemble methods first method combine predictions two models theoretically show assistance old features performance new features improved second approach dynamically select best single prediction establish better performance guarantee best model switches experiments synthetic real data validate effectiveness proposal
aggressive sampling multi class binary reduction applications text classification address problem multi class classification case number classes large propose double sampling strategy top multi class binary reduction strategy transforms original multi class problem binary classification problem pairs examples aim sampling strategy overcome curse long tailed class distributions exhibited majority large scale multi class classification problems reduce number pairs examples expanded data show strategy alter consistency empirical risk minimization principle defined double sample reduction experiments carried dmoz wikipedia collections 000 100 000 classes show efficiency proposed approach terms training prediction time memory consumption predictive performance respect state art approaches
adversarial surrogate losses ordinal regression ordinal regression seeks class label predictions penalty incurred mistakes increases according ordering labels absolute error canonical example many existing methods task reduce binary classification problems employ surrogate losses hinge loss instead derive uniquely defined surrogate ordinal regression loss functions seeking predictor robust worst case approximations training data labels subject matching certain provided training data statistics demonstrate advantages approach surrogate losses based hinge loss approximations using uci ordinal prediction tasks
formal guarantees robustness classifier adversarial manipulation recent work shown state art classifiers quite brittle sense small adversarial change originally high confidence correctly classified input leads wrong classification high confidence raises concerns classifiers vulnerable attacks calls question usage safety critical systems show paper first time formal guarantees robustness classifier giving instance specific emph lower bounds norm input manipulation required change classifier decision based analysis propose cross lipschitz regularization functional show using form regularization kernel methods resp neural networks improves robustness classifier without loss prediction performance
cost efficient gradient boosting many applications require learning classifiers regressors accurate cheap evaluate prediction cost drastically reduced learned predictor constructed majority inputs uses cheap features fast evaluations main challenge little loss accuracy work propose budget aware strategy based deep boosted regression trees contrast previous approaches learning cost penalties method grow deep trees average nonetheless cheap compute evaluate method number datasets find outperforms current state art large margin algorithm easy implement learning time comparable original gradient boosting source code made available acceptance
highly efficient gradient boosting decision tree gradient boosting decision tree gbdt popular machine learning algorithm quite effective implementations xgboost pgbrt although many engineering optimizations adopted implementations efficiency scalability still unsatisfactory feature dimension high data size large major reason feature need scan data instances estimate information gain possible split points time consuming tackle problem propose two novel techniques emph gradient based one side sampling goss emph exclusive feature bundling efb goss exclude significant proportion data instances small gradients use rest estimate information gain prove since data instances larger gradients play important role computation information gain goss obtain quite accurate estimation information gain much smaller data size efb bundle mutually exclusive features rarely take nonzero values simultaneously reduce number features prove finding optimal bundling exclusive features hard greedy algorithm achieve quite good approximation ratio thus effectively reduce number features without hurting accuracy split point determination much call new gbdt implementation goss efb emph lightgbm experiments multiple public datasets show lightgbm speeds training process conventional gbdt times achieving almost accuracy
estimating accuracy unlabeled data probabilistic logic approach propose efficient method estimate accuracy classifiers using unlabeled data consider setting multiple classification problems target classes may tied together logical constraints example set classes may mutually exclusive meaning data instance belong one proposed method based intuition classifiers agree likely correct classifiers make prediction violates constraints least one classifier must making error experiments four real world data sets produce accuracy estimates within percent true accuracy using solely unlabeled data models also outperform existing state art solutions estimating accuracies combining multiple classifier outputs results emphasize utility logical constraints estimating accuracy thus validating intuition
inferring generative model structure static analysis obtaining enough labeled training data complex discriminative models major bottleneck machine learning pipeline popular solution combining multiple sources weak supervision using generative models structure models affects quality training labels difficult learn without ground truth labels instead rely weak supervision sources structure virtue encoded programmatically present coral paradigm infers generative model structure statically analyzing code heuristics thus reducing data required learn structure significantly prove coral sample complexity scales quasilinearly number heuristics number relations found improving standard sample complexity exponential identifying degree relations experimentally coral matches outperforms traditional structure learning approaches points using coral model dependencies instead assuming independence results performing better fully supervised model accuracy points heuristics used label radiology data without ground truth labels
scalable model selection belief networks propose scalable algorithm model selection sigmoid belief networks sbns based factorized asymptotic bayesian fab framework derive corresponding generalized factorized information criterion gfic sbn proven statistically consistent marginal log likelihood capture dependencies within hidden variables sbns recognition network employed model variational distribution resulting algorithm call fabia simultaneously execute model selection inference maximizing lower bound gfic synthetic real data experiments suggest fabia compared state art algorithms learning sbns
produces concise model thus enabling faster testing improves predictive performance iii accelerates convergence prevents overfitting
time dependent spatially varying graphical models application brain fmri data analysis spatio temporal data often exhibits nonstationary changes spatial structure often masked strong temporal dependencies nonseparability work present additive model splits data temporally correlated signal spatially correlated noise model spatially correlated portion using time varying gaussian graphical model assumptions smoothness changes graphical model structure derive strong single sample convergence results confirming ability estimate track meaningful graphical models evolve time apply methodology discovery time varying spatial structure human brain fmri signals
bayesian data augmentation approach learning deep models data augmentation essential part training process applied deep learning models motivation robust training process deep learning models depends large annotated datasets expensive acquired stored processed therefore reasonable alternative able automatically generate new annotated training samples using process known data augmentation dominant data augmentation approach field assumes new training samples obtained via random geometric appearance transformations applied annotated training samples strong assumption unclear reliable generative model producing new training samples paper provide novel bayesian formulation data augmentation allowing introduce theoretically sound algorithm based extension generative adversarial network gan new annotated training points treated missing variables generated based distribution learned training set generalised monte carlo expectation maximisation process classification results mnist cifar cifar 100 show better performance proposed method compared current dominant data augmentation approach
union intersections uoi interpretable data driven discovery prediction increasing size complexity scientific data could dramatically enhance discovery prediction basic scientific applications neuroscience genetics systems biology etc realizing potential however requires novel statistical analysis methods interpretable predictive introduce union intersections uoi method flexible modular scalable framework enhanced model selection estimation method performs model selection model estimation intersection union operations respectively show uoi satisfy criteria low variance nearly unbiased estimation small number interpretable features maintaining high quality prediction accuracy perform extensive numerical investigation evaluate uoi algorithm uoilasso synthetic real data demonstrate extraction interpretable functional networks human electrophysiology recordings well accurate prediction ofphenotypes genotype phenotype data reduced features also show uoil1logistic uoicur variants basic framework improved prediction parsimony classification matrix factorization several benchmark biomedical data sets results suggest methods based uoi framework could improve interpretation prediction data driven discovery across scientific fields
deep learning topological signatures inferring topological geometrical information data offer alternative perspective machine learning problems methods topological data analysis persistent homology enable obtain information typically form summary representations topological features however topological signatures often come unusual structure multisets intervals highly impractical machine learning techniques many strategies proposed map topological signatures machine learning compatible representations suffer agnostic target learning task contrast propose technique enables input topological signatures deep neural networks learn task optimal representation training approach realized novel input layer favorable theoretical properties classification experiments object shapes social network graphs demonstrate versatility approach case latter even outperform state art large margin
practical hash functions similarity estimation dimensionality reduction hashing basic tool dimensionality reduction employed several aspects machine learning however perfomance analysis often carried abstract assumption truly random unit cost hash functions used without concern concrete hash function employed concrete hash functions may work fine sufficiently random input question trusted real world may faced structured input paper focus two prominent applications hashing namely similarity estimation one permutation hashing oph scheme nips feature hashing weinberger icml found numerous applications approximate near neighbour search lsh classification svm consider recent mixed tabulation hash function dahlgaard focs proved theoretically perform like truly random hash function many applications including oph first show improved concentration bounds truly random hashing argue mixed tabulation performs similar input vectors dense main contribution however experimental comparison different hashing schemes inside applications find mixed tabulation hashing almost fast classic multiply mod prime scheme mod guaranteed work well sufficiently random data demonstrate applications lead bias poor concentration real world synthetic data also compare popular murmurhash3 proven guarantees mixed tabulation murmurhash3 perform similar truly random hashing experiments however mixed tabulation faster murmurhash3 proven guarantee good performance possible input making reliable
maxing ranking assumptions pac maximum maximum selection maxing ranking elements via random pairwise comparisons diverse applications studied many models assumptions one simple natural assumption strong stochastic transitivity show maxing performed linearly many comparisons yet ranking requires quadratically many comparisons assumptions show borda score metric maximum selection performed linearly many comparisons ranking performed nlog comparisons
kernel functions based triplet comparisons propose two ways defining kernel function data set available information data set consists similarity triplets form object similar object object machine learning problems based restricted information become popular recent years previous approaches construct low dimensional euclidean embedding data set reflects given similarity triplets aim defining kernel functions correspond high dimensional embeddings kernel functions subsequently used apply kernel method data set
learning structured optimal bipartite graph clustering clustering methods widely applied document clustering gene expression analysis methods make use duality features samples occurring structure sample feature clusters extracted graph based clustering methods bipartite graph constructed depict relation features samples existing clustering methods conduct clustering graph achieved original data matrix explicit cluster structure thus require post processing step obtain clustering results paper propose novel clustering method learn bipartite graph exactly connected components number clusters new bipartite graph learned model approximates original graph maintains explicit cluster structure immediately get clustering results without post processing extensive empirical results presented verify effectiveness robustness model
multi way interacting regression via factorization machines propose bayesian regression method accounts multi way interactions arbitrary orders among predictor variables model makes use factorization mechanism representing regression coefficients interactions among predictors interaction selection guided prior distribution random hypergraphs construction generalizes finite feature model present posterior inference algorithm based gibbs sampling establish posterior consistency regression model method evaluated extensive experiments simulated data demonstrated able identify meaningful interactions several applications genetics retail demand forecasting
maximum margin interval trees learning regression function using censored interval valued output data important problem fields genomics medicine goal learn real valued prediction function training output labels indicate interval possible values whereas existing algorithms task linear models paper investigate learning nonlinear tree models propose learn tree minimizing margin based discriminative objective function provide dynamic programming algorithm computing optimal solution log linear time show empirically algorithm achieves state art speed prediction accuracy benchmark several data sets
kernel feature selection via conditional covariance minimization propose framework feature selection employs kernel based measures independence find subset covariates maximally predictive response building past work kernel dimension reduction formulate approach constrained optimization problem involving trace conditional covariance operator
improved graph laplacian via geometric self consistency address problem setting kernel bandwidth epps used manifold learning algorithms construct graph laplacian exploiting connection manifold geometry represented riemannian metric laplace beltrami operator set epps optimizing laplacian ability preserve geometry data experiments show principled approach effective robust
mixture rank matrix approximation collaborative filtering low rank matrix approximation lrma methods achieved excellent accuracy among today collaborative filtering methods existing lrma methods rank user item feature matrices typically fixed rank adopted describe users items however studies show submatrices different ranks could coexist user item rating matrix approximations fixed ranks cannot perfectly describe internal structures rating matrix therefore leading inferior recommendation accuracy paper mixture rank matrix approximation mrma method proposed user item ratings characterized mixture lrma models different ranks meanwhile learning algorithm capitalizing iterated condition modes proposed tackle non convex optimization problem pertaining mrma experimental studies movielens netflix datasets demonstrate mrma outperform six state art lrma based methods terms recommendation accuracy
predictive state recurrent neural networks present new model called predictive state recurrent neural networks psrnns filtering prediction dynamical systems psrnns draw insights recurrent neural networks rnns predictive state representations psrs inherit advantages types models like many successful rnn architectures psrnns use potentially deeply composed bilinear transfer functions combine information multiple sources one source act gate another bilinear functions arise naturally connection state updates bayes filters like psrs observations viewed gating belief states show psrnns learned effectively combining backpropogation time bptt initialization based statistically consistent learning algorithm psrs called two stage regression 2sr also show psrnns factorized using tensor decomposition reducing model size suggesting interesting theoretical connections existing multiplicative architectures lstms applied psrnns datasets showed outperform several popular alternative approaches modeling dynamical systems cases
hierarchical methods moments spectral methods moments provide powerful tool learning parameters latent variable models despite theoretical appeal applicability methods real data still limited due lack robustness model misspecification paper present hierarchical approach methods moments circumvent limitations method based replacing tensor decomposition step used previous algorithms approximate joint diagonalization experiments topic modeling show method outperforms previous tensor decomposition methods terms speed model quality
multitask spectral learning weighted automata consider problem estimating multiple related functions computed weighted automata wfa first present natural notion relatedness wfas considering extent several wfas share common underlying representation introduce model vector valued wfa conveniently helps formalize notion relatedness finally propose spectral learning algorithm vector valued wfas tackle multitask learning problem jointly learning multiple tasks form vector valued wfa algorithm enforces discovery representation space shared tasks benefits proposed multitask approach theoretically motivated showcased experiments synthetic real world datasets
generative local metric learning kernel regression paper shows metric learning used nadaraya watson kernel regression compared standard approaches bandwidth selection show metric learning significantly reduce mean square error mse kernel regression particularly high dimensional data propose method efficiently learning good metric function based upon analyzing performance estimator gaussian distributed data key feature approach estimator learned metric uses information global local structure training data theoretical empirical results confirm learned metric considerably reduce bias mse kernel regression
principles riemannian geometry neural networks study deals neural networks sense differential transformations systems differential equations forms part attempt construct formalized general theory neural networks branch riemannian geometry perspective following theoretical results developed proven feedforward networks limit number network layers goes infinity first shown residual neural networks dynamical systems first order differential equations opposed ordinary networks static implying network learning systems differential equations organize data second shown limit metric tensor residual networks converges smooth thus defines riemannian manifold third shown limit backpropagation graphs converges differentiable tensor fields results suggest analogy einstein general relativity particle trajectories geodesics curved space time manifolds neural networks learning curved space layer manifolds determine trajectory data moves network
subset selection sequential data subset selection task finding small subset informative items large ground set finds numerous applications different areas sequential data including time series ordered data contain important structural relationships among items imposed underlying dynamic models data play vital role selection representatives however nearly existing subset selection techniques ignore underlying dynamics data treat items independently leading incompatible set representatives paper develop new framework sequential subset selection takes advantage underlying dynamic models data promoting select set representatives high quality diversity also compatible according underlying dynamic models equip items transition dynamic models pose problem integer binary optimization assignments sequential items representatives leads high encoding diversity transition potentials proposed formulation non convex derive max sum message passing algorithm solve problem efficiently experiments synthetic real data including instructional video summarization motion capture segmentation show sequential subset selection framework achieves better encoding diversity state art also successfully incorporates dynamic data leading compatible representatives
quadratic convergence proximal newton algorithm nonconvex sparse learning propose proximal newton algorithm solving nonconvex regularized sparse learning problems high dimensions proposed algorithm integrates proximal newton algorithm multi stage convex relaxation based difference convex programming enjoys strong computational statistical guarantees specifically leveraging sophisticated characterization sparse modeling structures assumptions local restricted strong convexity hessian smoothness prove within stage convex relaxation proposed algorithm achieves local quadratic convergence eventually obtains sparse approximate local optimum optimal statistical properties convex relaxations numerical experiments provided support theory
fast sample efficient algorithms structured phase retrieval consider problem recovering signal magnitude measurements also known phase retrieval problem fundamental challenge nano bio astronomical imaging systems astronomical imaging speech processing problem ill posed therefore additional assumptions signal measurements necessary paper first study case underlying signal sparse develop novel recovery algorithm call compressive phase retrieval alternating minimization copram algorithm simple obtained via natural combination classical alternating minimization approach phase retrieval cosamp algorithm sparse recovery despite simplicity prove algorithm achieves sample complexity log gaussian samples matches best known existing results also demonstrates linear convergence theory practice requires extra tuning parameters signal sparsity level consider case underlying signal arises structured sparsity models specifically examine case block sparse signals uniform block size block sparsity problem design recovery algorithm call block copram reduces sample complexity log sufficiently large block lengths theta bound equates log knowledge constitutes first end end linearly convergent algorithm phase retrieval gaussian sample complexity sub quadratic dependence sparsity level signal
support ordered weighted sparsity overlapping groups hardness algorithms support owl norms generalize norm providing better prediction accuracy better handling correlated variables study norms obtained extending support norm owl norms setting overlapping groups resulting norms general hard compute tractable certain collections groups demonstrate fact develop dynamic program problem projecting onto set vectors supported fixed number groups dynamic program utilizes tree decompositions complexity scales treewidth program converted extended formulation associated group structure models group support norms overlapping group variant ordered weighted norm numerical results demonstrate efficacy new penalties
parametric simplex method sparse learning high dimensional sparse learning imposed great computational challenge large scale data analysis paper investiage broad class sparse learning approaches formulated linear programs parametrized regularization factor solve parametric simplex method psm psm offers significant advantages competing methods psm naturally obtains complete solution path values regularization parameter psm provides high precision dual certificate stopping criterion psm yields sparse solutions iterations solution sparsity significantly reduces computational cost per iteration particularly demonstrate superiority psm various sparse learning approaches including dantzig selector sparse linear regression sparse support vector machine sparse linear classification sparse differential network estimation provide sufficient conditions psm always outputs sparse solutions computational performance significantly boosted thorough numerical experiments provided demonstrate outstanding performance psm method
learned amp principled neural network based compressive image recovery compressive image recovery challenging problem requires fast accurate algorithms recently neural networks applied problem promising results exploiting massively parallel gpu processing architectures oodles training data able run orders magnitude faster existing techniques unfortunately methods difficult train often times specific single measurement matrix largely unprincipled blackboxes recently demonstrated iterative sparse signal recovery algorithms unrolled form interpretable deep neural networks taking inspiration work develop novel neural network architecture mimics behavior denoising based approximate message passing amp algorithm call new network learned amp ldamp ldamp network easy train applied variety different measurement matrices comes state evolution heuristic accurately predicts performance importantly network outperforms state art bm3d amp nlr algorithms terms accuracy runtime high resolutions used matrices fast matrix multiply implementations ldamp runs faster bm3d amp hundreds times faster nlr
falkon optimal large scale kernel method kernel methods provide principled way perform non linear nonparametric learning rely solid functional analytic foundations enjoy optimal statistical properties however least basic form limited applicability large scale scenarios stringent computational requirements terms time especially memory paper take substantial step scaling kernel methods proposing falkon novel algorithm allows efficiently process millions points falkon derived combining several algorithmic principles namely stochastic subsampling iterative solvers preconditioning theoretical analysis shows optimal statistical accuracy achieved requiring essentially
memory time extensive experiments show state art results available large scale datasets achieved even single machine
recursive sampling nystrom method give first algorithm kernel nystrom approximation runs linear time number training points provably accurate kernel matrices without dependence regularity incoherence conditions algorithm projects kernel onto set landmark points sampled ridge leverage scores requiring kernel evaluations additional runtime leverage score sampling long known give strong theoretical guarantees nystrom approximation employing fast recursive sampling scheme algorithm first make approach scalable empirically show finds accurate kernel approximations less time popular techniques classic nystrom approximation random fourier features method
efficient approximation algorithms strings kernel based sequence classification sequence classification algorithms svm require definition distance similarity measure two sequences commonly used notion similarity number matches mers length subsequences two sequences extending definition considering two mers match distance yields better classification performance however makes problem computationally much complex known algorithms compute similarity computational complexity render applicable small values work develop novel techniques efficiently accurately estimate pairwise similarity score enables use much larger values get higher predictive accuracy opens broad avenue applying classification approach audio images text sequences algorithm achieves excellent approximation performance theoretical guarantees process solve open combinatorial problem posed major hindrance scalability existing solutions give analytical bounds quality runtime algorithm report empirical performance real world biological music sequences datasets
robust hypothesis test functional effect gaussian processes work constructs hypothesis test detecting whether data generating function realp real belongs specific reproducing kernel hilbert space structure partially known utilizing theory reproducing kernels reduce hypothesis simple one sided score test scalar parameter develop testing procedure robust mis specification kernel functions also propose ensemble based estimator null model guarantee test performance small samples demonstrate utility proposed method apply test problem detecting nonlinear interaction groups continuous features evaluate finite sample performance test different data generating functions estimation strategies null model results revealed interesting connection notions machine learning model underfit overfit statistical inference type error power hypothesis test also highlighted unexpected consequences common model estimating strategies estimating kernel hyperparameters using maximum likelihood estimation model inference
invariance stability deep convolutional representations paper study deep signal representations near invariant groups transformations stable action diffeomorphisms without losing signal information achieved generalizing multilayer kernel introduced context convolutional kernel networks studying geometry corresponding reproducing kernel hilbert space show signal representation stable models functional space large class convolutional neural networks may enjoy stability
testing learning distributions symmetric noise invariance kernel embeddings distributions maximum mean discrepancy mmd resulting distance distributions useful tools fully nonparametric two sample testing learning distributions however rarely possible differences samples interest discovered differences due different types measurement noise data collection artefacts irrelevant sources variability propose distances distributions encode invariance additive symmetric noise aimed testing whether assumed true underlying processes differ moreover construct invariant features distributions leading learning algorithms robust impairment input distributions symmetric additive noise
empirical study properties random bases kernel methods kernel machines neural networks possess universal function approximation properties nevertheless practice way choosing appropriate function class differ thus limits usage emerge specifically neural networks learn representation adapting basis functions data task kernel methods typically use one kernels adapted width rbf kernel change anymore contribute work contrasting neural network kernel methods empirical study analysis reveals random adaptive bases affect quality learning furthermore present kernel basis adaptation schemes make efficient usage features retaining universality properties
max margin invariant features transformed unlabelled data study representations invariant common transformations data important learning techniques focused local approximate invariance implemented within expensive optimization frameworks lacking explicit theoretical guarantees paper study kernels invariant unitary group theoretical guarantees addressing important practical issue unavailability transformed versions labelled data problem call unlabeled transformation problem special form semi supervised learning one shot learning present theoretically motivated alternate approach invariant kernel svm based propose max margin invariant features mmif solve problem illustration design framework face recognition demonstrate efficacy approach large scale semi synthetic dataset 153 000 images new challenging protocol labelled faces wild lfw performing strong baselines
safetynets verifiable execution deep neural networks untrusted cloud inference using deep neural networks often outsourced cloud since computationally demanding task however raises fundamental issue trust client sure cloud performed inference correctly lazy cloud provider might use simpler less accurate model reduce computational load worse maliciously modify inference results sent client propose safetynets framework enables untrusted server cloud provide client short mathematical proof correctness inference tasks perform behalf client specifically safetynets develops implements specialized interactive proof protocol verifiable execution class deep neural networks represented arithmetic circuits empirical results three four layer deep neural networks demonstrate run time costs safetynets client server low safetynets detects incorrect computations neural network untrusted server high probability achieving state art accuracy mnist digit recognition timit speech recognition tasks
multi output polynomial networks factorization machines factorization machines polynomial networks supervised polynomial models based efficient low rank decomposition extend models multi output setting learning vector valued functions application multi class multi task problems cast problem learning way tensor whose slices share common decomposition propose convex formulation problem develop efficient conditional gradient algorithm prove global convergence despite fact involves non convex hidden unit selection step classification tasks show algorithm achieves excellent accuracy much sparser models existing methods recommendation system tasks show combine algorithm reduction ordinal regression multi output classification show resulting algorithm outperforms existing baselines terms ranking accuracy
neural hawkes process neurally self modulating multivariate point process many events occur world event types stochastically excited inhibited sense probabilities elevated decreased patterns sequence previous events discovering patterns help predict type event happen next propose model streams discrete events continuous time constructing neurally self modulating multivariate point process intensities multiple event types evolve according novel continuous time lstm generative model allows past events influence future complex realistic ways conditioning future event intensities hidden state recurrent neural network consumed stream past events model desirable qualitative properties achieves competitive likelihood predictive accuracy real synthetic datasets including missing data conditions
maximizing spread influence training data consider canonical problem influence maximization social networks since seminal work kempte kleinberg tardos two largely disjoint efforts problem first studies problem associated learning generative model produces cascades second focuses algorithmic challenge identifying set influencers assuming generative model known recent results learning optimization imply general generative model known rather learned training data algorithm influence maximization yield constant factor approximation guarantee using polynomially many samples drawn distribution paper describe simple algorithm maximizing influence training data main idea behind algorithm leverage strong community structure social networks identify set individuals influentials whose communities little overlap although general approximation guarantee algorithm unbounded show algorithm performs well experimentally analyze performance prove algorithm obtains constant factor approximation guarantee graphs generated stochastic block model traditionally used model networks community structure
inductive representation learning large graphs low dimensional embeddings nodes large graphs proved extremely useful variety prediction tasks content recommendation identifying protein functions however existing approaches require nodes graph present training embeddings previous approaches inherently transductive naturally generalize unseen nodes present graphsage general inductive framework leverages node feature information text attributes efficiently generate node embeddings instead training individual embeddings node learn function generates embeddings sampling aggregating features node local neighborhood algorithm outperforms strong baselines three inductive node classification benchmarks classify category unseen nodes evolving information graphs based citation reddit post data show algorithm generalizes completely unseen graphs using multi graph dataset protein protein interactions
meta learning perspective cold start recommendations items matrix factorization one popular techniques product recommendation known suffer serious cold start problems item cold start problems particularly acute settings tweet recommendation new items arrive continuously paper present meta learning strategy address item cold start new items arrive continuously propose two deep neural network architectures implement meta learning strategy first architecture learns linear classifier whose weights determined item history second architecture learns neural network whose biases instead adapted based item history evaluate techniques real world problem tweet recommendation production data twitter demonstrate proposed techniques significantly beat baseline lookup table based user embeddings also outperform state art production model tweet recommendation
dropoutnet addressing cold start recommender systems latent models become default choice recommender systems due performance scalability however research area primarily focused modeling user item interactions latent models developed cold start deep learning recently achieved remarkable success showing excellent results diverse input types inspired results propose neural network based latent model handle cold start recommender systems unlike existing approaches incorporate additional content based objective terms instead focus learning show neural network models explicitly trained handle cold start dropout model trained top existing latent model effectively providing cold start capabilities full power deep architectures empirically demonstrate state art accuracy publicly available benchmarks
federated multi task learning federated learning poses new statistical systems challenges training machine learning models distributed networks devices work show multi task learning naturally suited handle statistical challenges setting propose novel systems aware optimization method mocha robust practical systems issues method theory first time consider issues high communication cost stragglers fault tolerance distributed multi task learning resulting method achieves significant speedups compared alternatives federated setting demonstrate extensive simulations real world federated datasets
flexpoint adaptive numerical format efficient training deep neural networks deep neural networks commonly developed trained bit floating point format significant gains performance energy efficiency could realized training inference numerical formats optimized deep learning despite substantial advances limited precision inference recent years training neural networks low bit width remains challenging problem present flexpoint data format aiming complete replacement bit floating point format training inference designed support deep network topologies without modifications flexpoint tensors shared exponent dynamically adjusted minimize overflows maximizing available dynamic range validate flexpoint training alexnet deep residual network generative adversarial network using simulator implemented emph neon deep learning framework demonstrate bit flexpoint closely matches bit floating point training three models without need tuning model hyper parameters results suggest flexpoint promising numerical format future hardware training inference
bayesian inference individualized treatment effects using multi task gaussian processes predicated increasing abundance electronic health records investigate problem inferring individualized treatment effects using observational data stemming potential outcomes model propose novel multi task learning framework factual counterfactual outcomes modeled outputs function vector valued reproducing kernel hilbert space vvrkhs develop nonparametric bayesian method learning treatment effects using multi task gaussian process linear coregionalization kernel prior vvrkhs bayesian approach allows compute individualized measures confidence estimates via pointwise credible intervals crucial realizing full potential precision medicine impact selection bias alleviated via risk based empirical bayes method adapting multi task prior jointly minimizes empirical error factual outcomes uncertainty unobserved counterfactual outcomes conduct experiments observational datasets interventional social program applied premature infants left ventricular assist device applied cardiac patients wait listed heart transplant experiments show method significantly outperforms state art
tomography london underground scalable model origin destination data paper addresses classical network tomography problem inferring local traffic given origin destination observations focussing large complex public transportation systems build scalable model exploits input output information estimate unobserved link station loads users path preferences based reconstruction users travel time distribution model flexible enough capture possible different path choice strategies correlations users travelling similar paths similar times corresponding likelihood function intractable medium large scale networks propose two distinct strategies namely exact maximum likelihood inference approximate tractable model variational inference original intractable model application approach consider emblematic case london underground network tap tap system tracks start exit time location journeys day set synthetic simulations real data provided transport london used validate test model predictions observable unobservable quantities
matching balanced nonlinear representations treatment effects estimation estimating treatment effects observational data challenging problem due missing counterfactuals matching effective strategy tackle problem widely used matching estimators nearest neighbor matching nnm pair treated units similar control units terms covariates estimate treatment effects accordingly however existing matching estimators poor performance distributions control treatment groups unbalanced moreover theoretical analysis suggests bias causal effect estimation would increase dimension covariates paper aim address problems learning low dimensional balanced nonlinear representations bnr observational data particular convert counterfactual prediction classification problem develop kernel learning model domain adaptation constraint design novel matching estimator dimension covariates significantly reduced projecting data low dimensional subspace experiments several synthetic real world datasets demonstrate effectiveness approach
moleculenet continuous filter convolutional neural network modeling quantum interactions deep learning potential revolutionize quantum chemistry ideally suited learn representations structured data speed exploration chemical space convolutional neural networks proven first choice images audio video data atoms molecules restricted grid instead precise locations contain essential physical information would get lost discretized thus propose use textit continuous filter convolutional layers able model local correlations without requiring data lie grid apply layers moleculenet novel deep learning architecture modeling quantum interactions molecules obtain joint model total energy interatomic forces follows fundamental quantum chemical principles includes rotationally invariant energy predictions smooth differentiable potential energy surface architecture achieves state art performance benchmarks equilibrium molecules molecular dynamics trajectories finally introduce challenging benchmark chemical structural variations suggests path work
hiding images plain sight deep steganography steganography practice concealing secret message within another ordinary message commonly steganography used unobtrusively hide small message within noisy regions larger image study attempt place full size color image within another image size deep neural networks simultaneously trained create hiding revealing processes designed specifically work pair system trained images drawn randomly imagenet database works well natural images wide variety sources beyond demonstrating successful application deep learning hiding images carefully examine result achieved explore extensions unlike many popular steganographic methods encode secret message within least significant bits carrier image approach compresses distributes secret image representation across available bits
universal style transfer via feature transforms universal style transfer aims transfer arbitrary visual styles content images existing feed forward based methods enjoying inference efficiency mainly limited inability generalizing unseen styles compromised visual quality paper present simple yet effective method tackles limitations without training pre defined styles key ingredient method pair feature transforms whitening coloring embedded image reconstruction network whitening coloring transforms reflect direct matching feature covariance content image given style image shares similar spirits optimization gram matrix based cost neural style transfer demonstrate effectiveness algorithm generating high quality stylized images comparisons number recent methods also analyze method visualizing whitened features synthesizing textures simple feature coloring
attend predict understanding gene regulation selective attention chromatin past decade seen revolution genomic technologies enable flood genome wide profiling chromatin marks recent literature tried understand gene regulation predicting gene expression large scale chromatin measurements two fundamental challenges exist learning tasks genome wide chromatin signals spatially structured high dimensional highly modular core aim understand relevant factors work together previous studies either failed model complex dependencies among input signals relied separate feature analysis explain decisions paper presents attention based deep learning approach call chromattention uses unified architecture model interpret dependencies among chromatin factors controlling gene regulation chromattention uses hierarchy multiple long short term memory lstm modules encode input signals model various chromatin marks cooperate automatically chromattention trains two levels attention jointly target prediction enabling attend differentially relevant marks locate important positions per mark evaluate model across different cell types tasks human proposed architecture accurate attention scores also provide better interpretation state art feature visualization methods saliency map
unbounded cache model online language modeling open vocabulary propose extension recurrent networks language modeling adapt prediction changes data distribution associate non parametric large scale memory component stores hidden activations seen past approach seen unbounded continuous cache make use modern approximate search quantization algorithms stores millions representations searching efficiently show approach helps adapting pretrained neural networks novel data distribution tackle called rare word problem
deconvolutional paragraph representation learning learning latent representations long text sequences important first step many natural language processing applications recurrent neural networks rnns become cornerstone challenging task however quality sentences rnn based decoding reconstruction decreases length text propose sequence sequence purely convolutional deconvolutional autoencoding framework free issue also computationally efficient proposed method simple easy implement leveraged building block many applications show empirically compared rnns framework better reconstructing correcting long paragraphs quantitative evaluation semi supervised text classification summarization tasks demonstrate potential better utilization long unlabeled text data
analyzing hidden representations end end automatic speech recognition systems neural models become ubiquitous automatic speech recognition systems neural networks typically used acoustic models complex systems recent studies explored end end speech recognition systems based neural networks trained directly predict text input acoustic features although systems conceptually elegant simpler traditional systems less obvious interpret trained models work analyze speech representations learned deep end end model based convolutional recurrent layers trained connectionist temporal classification ctc loss use pre trained model generate frame level features given classifier trained frame classification phones evaluate representations different layers deep model compare quality predicting phone labels experiments shed light important aspects end end model layer depth model complexity design choices
best worlds transferring knowledge discriminative learning generative visual dialog model present novel training framework neural sequence models particularly grounded dialog generation standard training paradigm models maximum likelihood estimation mle minimizing cross entropy human responses across variety domains recurring problem mle trained generative neural dialog models tend produce safe generic responses like know tell contrast discriminative dialog models trained rank list candidate human responses outperform generative counterparts terms automatic metrics diversity informativeness responses however useful practice since deployed real conversations users work aims achieve best worlds practical usefulness strong performance via knowledge transfer primary contribution end end trainable generative visual dialog model receives gradients perceptual adversarial loss sequence sampled leverage recently proposed gumbel softmax approximation discrete distribution specifically rnn augmented sequence samplers coupled straight gradient estimator enables end end differentiability also introduce stronger encoder visual dialog employ self attention mechanism answer encoding along metric learning loss aid better capturing semantic similarities answer responses overall proposed model outperforms state art visdial dataset significant margin recall
teaching machines describe images natural language feedback robots eventually part every household thus critical enable algorithms learn guided non expert users paper bring human loop enable human teacher give feedback learning agent form natural language descriptive sentence provide stronger learning signal numeric reward easily point mistakes correct focus problem image captioning quality output easily judged non experts propose phrase based captioning model trained policy gradients design critic provides reward learner conditioning human provided feedback show exploiting descriptive feedback model learns perform better given independently written human captions
high order attention models visual question answering quest algorithms enable cognitive abilities important part machine learning common trait recent cognitive like tasks take account different data modalities visual lingual paper propose novel generally applicable form attention mechanism learns high order correlations various data modalities show high order correlations effectively direct appropriate attention relevant elements different data modalities required solve joint task demonstrate effectiveness high order attention mechanism task visual question answering vqa achieve state art performance standard vqa dataset
visual reference resolution using attention memory visual dialog visual dialog task answering series inter dependent questions given input image often requires resolve visual references among questions problem different visual question answering vqa relies spatial attention visual grounding estimated image question pair propose novel attention mechanism exploits visual attentions past resolve current reference visual dialog scenario proposed model equipped associative attention memory storing sequence previous attention key pairs memory model retrieves previous attention taking account recency relevant current question order resolve potentially ambiguous reference model merges retrieved attention tentative one obtain final attention current question specifically use dynamic parameter prediction combine two attentions conditioned question extensive experiments new synthetic visual dialog dataset show model significantly outperforms state art points situation visual reference resolution plays important role moreover proposed model presents superior performance points improvement visual dialog dataset despite significantly fewer parameters baselines
semi supervised learning optical flow generative adversarial networks convolutional neural networks cnns recently applied optical flow estimation problem training cnns requires sufficiently large ground truth training data existing approaches resort synthetic unrealistic datasets hand unsupervised methods capable leveraging real world videos training ground truth flow fields available methods however rely fundamental assumptions brightness constancy spatial smoothness priors hold near motion boundaries paper propose exploit unlabeled videos semi supervised learning optical flow generative adversarial network key insight adversarial loss capture structural patterns flow warp errors without making explicit assumptions extensive experiments benchmark datasets demonstrate proposed semi supervised algorithm performs favorably purely supervised semi supervised learning schemes
associative embedding end end learning joint detection grouping introduce associative embedding novel method supervising convolutional neural networks task detection grouping number computer vision problems framed manner including multi person pose estimation instance segmentation multi object tracking usually grouping detections achieved multi stage pipelines instead propose approach teaches network simultaneously output detections group assignments technique easily integrated state art network architecture produces pixel wise predictions show apply method multi person pose estimation report state art performance multi person pose mpii dataset coco dataset
learning deep structured multi scale features using attention gated crfs contour prediction recent works shown exploiting multi scale representations deeply learned via convolutional neural networks cnn tremendous importance accurate contour detection paper presents novel approach predicting contours advances state art two fundamental aspects multi scale feature generation fusion different previous works directly considering multi scale feature maps obtained inner layers primary cnn architecture introduce hierarchical deep model produces rich complementary representations furthermore refine robustly fuse representations learned different scales novel attention gated conditional random fields crfs proposed experiments ran two publicly available datasets bsds500 nyudv2 demonstrate effectiveness latent crf model overall hierarchical framework
incorporating side information adaptive convolution computer vision tasks often side information available helpful solve task example crowd counting camera perspective camera angle height gives clue appearance scale people scene side information shown useful counting systems using traditional hand crafted features fully utilized counting systems based deep learning order incorporate available side information propose adaptive convolutional neural network acnn convolution filter weights adapt current scene context via side information particular model filter weights low dimensional manifold within high dimensional space filter weights filter weights generated using learned filter manifold sub network whose input side information help side information adaptive weights acnn disentangle variations related side information extract discriminative features related current context camera perspective noise level blur kernel parameters demonstrate effectiveness acnn incorporating side information tasks crowd counting corrupted digit recognition image deblurring experiments show acnn improves performance compared plain cnn similar number parameters since existing crowd counting datasets contain ground truth side information collect new dataset ground truth camera angle height side information
learning multi view stereo machine show learn multi view stereopsis system contrast recent learning based methods reconstruction leverage underlying geometry problem feature projection unprojection along viewing rays formulating operations differentiable manner able learn system end end task metric reconstructions end end learning allows utilize priors object shapes enabling reconstruction objects much fewer images even single image required classical approaches well completion unseen surfaces thoroughly evaluate approach shapenet dataset demonstrate benefits classical approaches recent learning based methods
pose guided person image generation paper proposes novel pose guided person generation network allows synthesize person images arbitrary poses based image person novel pose generation framework utilizes pose information explicitly consists two key stages coarse structure generation detailed appearance refinement first stage condition image target pose fed net like network generate initial coarse image person target pose second stage refines initial blurry result based autoencoder conjunction discriminator adversarial way extensive experimental results 12864 identification images 256256 fashion photos show model generates high quality person images convincing details
working hard know neighbor margins local descriptor learning loss introduce novel loss learning local feature descriptors inspired sift matching scheme show proposed loss relies maximization distance closest positive closest negative patches could replace complex regularization methods used local descriptor learning works well shallow deep convolution network architectures resulting descriptor compact dimensionality sift 128 shows state art performance matching patch verification retrieval benchmarks fast compute gpu
multimodal image image translation enforcing cycle consistency many image image translation problems ambiguous single input image corresponding multiple possible outputs work aim model distribution possible outputs conditional generative modeling setting ambiguity mapping encoded low dimensional latent vector randomly sampled test time generator learns map input along latent code output explicitly enforce cycle consistency latent code output encouraging invertibility helps prevent many one mapping latent code output training also known problem mode collapse helps produce diverse results evaluate relationship perceptual realism diversity images generated method test variety domains
deep supervised discrete hashing rapid growth image video data web hashing extensively studied image video search recent years benefit recent advances deep learning deep hashing methods achieved promising results image retrieval however limitations previous deep hashing methods semantic information fully exploited paper develop deep supervised discrete hashing algorithm based assumption learned binary codes ideal classification pairwise label information classification information used learn hash codes within one stream framework constrain outputs last layer binary codes directly rarely investigated deep hashing algorithm discrete nature hash codes alternating minimization method used optimize objective function experimental results shown method outperforms current state art methods benchmark datasets
svd softmax fast softmax approximation large vocabulary neural networks propose fast approximation method softmax function large vocabulary using singular value decomposition svd svd softmax targets fast accurate probability estimation topmost probable words inference recurrent neural network language models proposed method transforms weight matrix used calculation logits using svd approximate probability word estimated fraction svd transformed matrix apply technique language modeling neural machine translation present guideline good approximation algorithm requires arithmetic operations 800k vocabulary case shows speedup gpu
hash embeddings efficient word representations present hash embeddings efficient method representing words continuous vector form hash embedding may seen interpolation standard word embedding word embedding created using random hash function hashing trick hash embeddings token represented dimensional embeddings vectors one dimensional weight vector final dimensional representation token product two rather fitting embedding vectors token selected hashing trick shared pool embedding vectors experiments show hash embeddings easily deal huge vocabularies consisting millions tokens using hash embedding need create dictionary training perform kind vocabulary pruning training show models trained using hash embeddings exhibit least level performance models trained using regular embeddings across wide range tasks furthermore number parameters needed embedding fraction required regular embedding since standard embeddings embeddings constructed using hashing trick actually special cases hash embedding hash embeddings considered extension improvement existing regular embedding types
regularized framework sparse structured neural attention modern neural networks often augmented attention mechanism tells network focus within input propose paper new framework sparse structured attention building upon max operator regularized strongly convex function show operator differentiable gradient defines mapping real values probabilities suitable attention mechanism framework includes softmax slight generalization recently proposed sparsemax special cases however also show framework incorporate modern structured penalties resulting new attention mechanisms focus entire segments groups input encouraging parsimony interpretability derive efficient algorithms compute forward backward passes attention mechanisms enabling use neural network trained backpropagation showcase potential drop replacement existing attention mechanisms evaluate three large scale tasks textual entailment machine translation sentence summarization attention mechanisms improve interpretability without sacrificing performance notably textual entailment summarization outperform existing attention mechanisms based softmax sparsemax
attentional pooling action recognition introduce simple yet surprisingly powerful model incorporate attention action recognition human object interaction tasks proposed attention module trained without extra supervision gives sizable boost accuracy keeping network size computational cost nearly leads significant improvements state art base architecture standard action recognition benchmarks across still images videos establishes new state art mpii relative improvement hmdb rgb datasets also perform extensive analysis attention module empirically analytically terms latter introduce novel derivation bottom top attention low rank approximations bilinear pooling methods typically used fine grained classification perspective attention formulation suggests novel characterization action recognition fine grained recognition problem
plan attend generate planning sequence sequence models investigate integration planning mechanism encoder decoder architectures attention present model plans ahead computes alignments input output sequences constructing matrix proposed future alignments commitment vector governs whether follow recompute plan mechanism inspired strategic attentive reader writer straw model proposed model end end trainable fully differentiable operations show outperforms strong baseline character level translation tasks wmt algorithmic task finding eulerian circuits graphs among others analysis demonstrates model computes qualitatively intuitive alignments converges faster baselines achieves superior performance fewer parameters
dilated recurrent neural networks notoriously learning recurrent neural networks rnns long sequences difficult task three major challenges extracting complex dependencies vanishing exploding gradients efficient parallelization paper introduce simple yet effective rnn connection structure dilatedrnn simultaneously tackles challenges proposed architecture characterized multi resolution dilated recurrent skip connections combined flexibly different rnn cells moreover dilatedrnn reduces number parameters enhances training efficiency significantly matching state art performance even vanilla rnn cells tasks involving long term dependencies provide theory based quantification architecture advantages introduce memory capacity measure mean recurrent length suitable rnns long skip connections existing measures rigorously prove advantages dilatedrnn recurrent neural architectures
thalamus gated recurrent modules propose deep learning model inspired neuroscience theories communication within neocortex model consists recurrent modules send features via routing center endowing neural modules flexibility share features multiple time steps show model learns route information hierarchically processing input data chain modules observe common architectures feed forward neural networks skip connections emerging special cases architecture novel connectivity patterns learned text8 compression task model outperforms multi layer recurrent networks three sequential tasks
wasserstein learning deep generative point process models point processes becoming popular modeling asynchronous sequential data due sound mathematical foundation strength modeling variety real world phenomena currently often characterized via intensity function limits model expressiveness due unrealistic assumptions parametric form used practice furthermore learned via maximum likelihood approach prone failure multi modal distributions sequences paper propose intensity free approach point processes modeling transforms nuisance processes target one furthermore train model using likelihood free leveraging wasserstein distance point processes experiments various synthetic real world data substantiate superiority proposed point process model conventional ones
stabilizing training generative adversarial networks regularization deep generative models based generative adversarial networks gans demonstrated impressive sample quality order work require careful choice architecture parameter initialization selection hyper parameters fragility part due dimensional mismatch model distribution true distribution causing density ratio associated divergence undefined overcome fundamental limitation propose new regularization approach low computational cost yields stable gan training procedure demonstrate effectiveness approach several datasets including common benchmark image generation tasks approach turns gan models reliable building blocks deep learning
neural variational inference learning undirected graphical models many problems machine learning naturally expressed language undirected graphical models propose learning inference algorithms undirected models optimize variational approximation log likelihood model central approach upper bound log partition function parametrized function express flexible neural network bound enables accurately track partition function learning speed sampling train broad class powerful hybrid directed undirected models via unified variational inference framework empirically demonstrate effectiveness method several popular generative modeling datasets
adversarial symmetric variational autoencoder new form variational autoencoder vae developed joint distribution data codes considered two symmetric forms observed data fed encoder yield codes latent codes drawn simple prior propagated decoder manifest data lower bounds learned marginal log likelihood fits observed data latent codes learning variational bound one seeks minimize symmetric kullback leibler divergence joint density functions simultaneously seeking maximize two marginal log likelihoods facilitate learning new form adversarial training developed extensive set experiments performed demonstrate state art data reconstruction generation several image benchmarks datasets
diverse accurate image description using variational auto encoder additive gaussian encoding space paper proposes method generate image descriptions using conditional variational auto encoder cvae data dependent gaussian prior encoding space standard cvaes fixed gaussian prior easily collapse generate descriptions little variability approach addresses problem linearly combining multiple gaussian priors based semantic content image increasing flexibility representational power generative model evaluate additive gaussian cvae cvae approach mscoco dataset show produces captions diverse accurate strong lstm baseline cvae variants
forcing training stochastic recurrent networks many efforts devoted incorporate stochastic latent variables sequential neural models recurrent neural networks rnns rnns latent variables successful capturing variability observed natural structured data speech work propose novel recurrent latent variable model unifies successful ideas recently proposed architectures model step sequence associated latent variable used condition recurrent dynamics future steps model trained amortised variational inference inference network augmented rnn runs backward sequence addition next step prediction add auxiliary cost latent variables forces reconstruct state backward recurrent network provides latent variables task independent objective enhances performance overall model although conceptually simple model achieves state art results standard speech benchmarks timit blizzard finally apply model language modeling imdb dataset auxiliary cost crucial learning interpretable latent variables setting show regular evidence lower bound significantly underestimates log likelihood model thus encouraging future works compare likelihoods methods using tighter bounds
one shot imitation learning imitation learning commonly applied solve different tasks isolation usually requires either careful feature engineering significant number samples far desire ideally robots able learn demonstrations given task instantly generalize new situations task without requiring task specific engineering paper propose meta learning framework achieving capability call one shot imitation learning specifically consider setting large maybe infinite set tasks task many instantiations example task could stack blocks table single tower another task could place blocks table two block towers etc case different instances task would consist different sets blocks different initial states training time algorithm presented pairs demonstrations subset tasks neural net trained takes input one demonstration current state initially initial state demonstration pair outputs action goal resulting sequence states actions matches closely possible second demonstration test time demonstration single instance new task presented neural net expected perform well new instances new task experiments show use soft attention allows model generalize conditions tasks unseen training data anticipate training model much greater variety tasks settings obtain general system turn demonstrations robust policies accomplish overwhelming variety tasks
reconstruct crush network article introduces energy based model adversarial regarding data minimizes energy given data distribution positive samples maximizing energy another given data distribution negative unlabeled samples model especially instantiated autoencoders energy represented reconstruction error provides general distance measure unknown data resulting neural network thus learns reconstruct data first distribution crushing data second distribution solution handle different problems positive unlabeled learning covariate shift especially imbalanced data using autoencoders allows handling large variety data images text even dialogues experiments show flexibility proposed approach dealing different types data different settings images cifar cifar 100 training setting text amazon reviews learning dialogues facebook babi next response classification dialogue completion
fader networks generating image variations sliding attribute values paper introduces new encoder decoder architecture trained reconstruct images disentangling salient information image values attributes directly latent space result training model generate different realistic versions input image varying attribute values using continuous attribute values choose much specific attribute perceivable generated image property could allow applications users modify image using sliding knobs like faders mixing console change facial expression portrait update color objects compared state art mostly relies training adversarial networks pixel space altering attribute values train time approach results much simpler training schemes nicely scales multiple attributes present evidence model significantly change perceived value attributes preserving naturalness images
predrnn recurrent neural networks video prediction using spatiotemporal lstms predictive learning video sequences aims generate future images learning historical frames spatial appearance temporal variations two crucial structures paper models structures presenting predictive recurrent neural network predrnn architecture enlightened idea video prediction system memorize spatial appearance temporal variations unified memory pool concretely memory states longer constrained inside lstm unit instead allowed zigzag two directions across stacked rnn layers vertically time steps horizontally core network new spatiotemporal lstm lstm unit extracts memorizes spatial temporal video representations simultaneously predrnn achieves state art prediction performance two standard video datasets believed general framework extended predictive learning tasks beyond video prediction
multi agent predictive modeling attentional commnets multi agent predictive modeling essential step understanding physical social team play systems recently interaction networks ins proposed task modeling multi agent physical systems ins scale number interactions system typically quadratic higher order number agents paper introduce vain attentional commnet multi agent predictive modeling scales linearly number agents show vain effective multi agent predictive modeling representation learned transferable learning new data poor tasks method evaluated tasks challenging multi agent prediction domains chess soccer outperforms competing multi agent approaches
real time image saliency black box classifiers work develop fast saliency detection method applied differentiable image classifier train masking model manipulate scores classifier masking salient parts input image model generalises well unseen images requires single forward pass perform saliency detection therefore suitable use real time systems test approach cifar imagenet datasets show produced saliency maps easily interpretable sharp free artifacts suggest new metric saliency test method imagenet object localisation task achieve results outperforming weakly supervised methods
prototypical networks shot learning propose prototypical networks problem shot classification classifier must generalize new classes seen training set given small number examples new class prototypical networks learn metric space classification performed computing distances prototype representations class compared recent approaches shot learning reflect simpler inductive bias beneficial limited data regime achieve excellent results provide analysis showing simple design decisions yield substantial improvements recent approaches involving complicated architectural choices meta learning extend prototypical networks zero shot learning achieve state art results birds dataset
shot learning information retrieval lens shot learning refers understanding new concepts examples propose information retrieval inspired approach problem motivated increased importance maximally leveraging available information low data regime define training objective aims extract much information possible training batch effectively optimizing relative orderings batch points simultaneously particular view batch point query ranks remaining ones based predicted relevance define model framework structured prediction optimize mean average precision rankings method produces state art results standard benchmarks shot learning
reversible residual network backpropagation without storing activations residual networks resnets demonstrated significant improvement traditional convolutional neural networks cnns image classification increasing performance networks grow deeper wider however memory consumption becomes bottleneck one needs store intermediate activations calculating gradients using backpropagation work present reversible residual network revnet variant resnets layer activations reconstructed exactly next layer therefore activations layers need stored memory backprop demonstrate effectiveness revnets cifar imagenet establishing nearly identical performance equally sized resnets activation storage requirements independent depth
gated recurrent convolution neural network ocr optical character recognition ocr aims recognize text natural images widely researched computer vision community paper present new architecture named gated recurrent convolution layer grcl challenge grcl constructed adding gate recurrent convolution layer rcl find equipped gate control context modulation rcl balancing feed forward component well recurrent component addition build bidirectional long short term memory blstm sequence modelling test several variants blstm find suitable architecture ocr finally combine gated recurrent convolution neural network grcnn blstm recognize text natural image grcnn blstm trained end end outperforms benchmark datasets terms state art results including iiit street view text svt icdar
learning efficient object detection models knowledge distillation despite significant accuracy improvement convolutional neural networks cnn based object detectors often require prohibitive runtimes process image real time applications state art models often use deep networks large number floating point operations efforts model compression learn compact models fewer number parameters much reduced accuracy work propose new framework learn compact fast object detection networks improved accuracy using knowledge distillation hint learning although knowledge distillation demonstrated excellent improvements simpler classification setups complexity detection poses new challenges form regression region proposals less voluminous labels address several innovations weighted cross entropy loss address class imbalance teacher bounded loss handle regression component adaptation layers better learn intermediate teacher distributions conduct comprehensive empirical evaluation different distillation configurations multiple datasets including pascal kitti ilsvrc coco results show consistent improvement accuracy speed trade offs modern multi class detection models
active bias training accurate neural network emphasizing high variance samples self paced learning hard example mining weight training instances improve learning accuracy paper presents two improved alternatives based lightweight estimates sample uncertainty stochastic gradient descent sgd variance predicted probability correct class across iterations mini batch sgd proximity correct class probability decision threshold extensive experimental results six datasets show methods reliably improve accuracy various network architectures including additional gains top popular training techniques residual learning momentum adam batch normalization dropout distillation
decoupling update update deep learning requires data useful approach obtain data creative mine data various sources created different purposes unfortunately approach often leads noisy labels paper propose meta algorithm tackling noisy labels problem key idea decouple update fromhow update demonstrate effectiveness algorithm mining data gender classification combining labeled faces wild lfw face recognition dataset textual genderizing service leads noisy dataset approach simple implement leads state art results analyze convergence properties proposed algorithm
langevin dynamics continuous tempering training deep neural networks minimizing non convex high dimensional objective functions challenging especially training modern deep neural networks paper novel approach proposed divides training process two consecutive phases obtain better generalization performance bayesian sampling stochastic optimization first phase explore energy landscape capture fat modes thesecondo etu theparameter domthefirstphase inthebayesian arn gphase weapplycont uoustemper gands imation othelan dynamics createanefficientandeffectivesamp whichthetemperatureisadjustedau maticallyaord thedesig temperature dynamics strategies overcome challenge early trapping bad local minima achieved remarkable improvements various types neural networks shown theoretical analysis empirical experiments
differentiable learning logical rules knowledge base reasoning study problem learning probabilistic first order logical rules knowledge base reasoning learning problem difficult requires learning parameters continuous space well structure discrete space propose framework neural logic programming combines parameter structure learning first order logical rules end end differentiable model approach inspired recently developed differentiable logic called tensorlog inference tasks compiled sequences differentiable operations design neural controller system learns compose operations empirically method obtains state art results multiple knowledge base benchmark datasets including freebase wikimovies
deliberation networks sequence generation beyond one pass decoding encoder decoder framework achieved promising progress many sequence generation tasks including machine translation text summarization dialog system image captioning etc framework adopts one pass forward process decoding generating sequence lacks deliberation process generated sequence directly used final output without polishing however deliberation common behavior human daily life like reading news writing papers articles books work introduce deliberation process encoder decoder framework propose deliberation networks sequence generation deliberation network two levels decoders first pass decoder generates raw sequence second pass decoder polishes refines raw sentence deliberation since second pass deliberation decoder overall picture sequence generated might potential generate better sequence looking future words raw sentence experiments neural machine translation text summarization demonstrate effectiveness proposed deliberation networks
neural program meta induction recently proposed methods neural program induction work assumption large set input output examples learning given input output mapping paper aims address problem data computation efficiency program induction leveraging information related tasks specifically propose two novel approaches cross task knowledge transfer improve program induction limited data scenarios first proposal portfolio adaptation set induction models pretrained set related tasks best model adapted towards new task using transfer learning second approach meta program induction shot learning approach used make model generalize new tasks without additional training test efficacy methods constructed new benchmark programs written karel programming language using extensive experimental evaluation karel benchmark demonstrate proposals dramatically outperform baseline induction method use knowledge transfer also analyze relative performance two approaches study conditions perform best particular meta induction outperforms existing approaches extreme data sparsity small number examples available fewer ten number available examples increase thousand portfolio adapted program induction becomes best approach intermediate data sizes demonstrate combined method adapted meta program induction strongest performance
saliency based sequential image attention multiset prediction humans process visual scenes selectively sequentially using attention central models human visual attention saliency map propose hierarchical visual architecture operates saliency map uses novel attention mechanism sequentially focus salient regions take additional glimpses within regions architecture motivated human visual attention used multi label image classification novel multiset task demonstrating achieves high precision recall localizing objects attention unlike conventional multi label image classification models model supports multiset prediction due reinforcement learning based training process allows arbitrary label permutation multiple instances per label
protein interface prediction using graph convolutional networks present general framework graph convolution classification tasks labeled graphs node edge features performing convolution operation neighborhood node interest able stack multiple layers convolution learn effective latent representations integrate information across input graph demonstrate effectiveness approach prediction interfaces proteins challenging problem important applications drug discovery design proposed approach achieves accuracy better state art svm method task also outperforms recently proposed diffusion convolution form graph convolution
dual agent gans photorealistic identity preserving profile face synthesis synthesizing realistic profile faces promising efficiently training deep pose invariant models large scale unconstrained face recognition populating samples extreme poses avoiding tedious annotations however learning synthetic faces may achieve desired performance due discrepancy distributions synthetic real face images narrow gap propose dual agent generative adversarial network gan model improve realism face simulator output using unlabeled real faces preserving identity information realism refinement dual agents specifically designed distinguishing real fake identities simultaneously particular employ shelf face model simulator generate profile face images varying poses gan leverages fully convolutional network generator generate high resolution images auto encoder discriminator dual agents besides novel architecture make several key modifications standard gan preserve pose texture preserve identity stabilize training process pose perception loss identity perception loss iii adversarial loss boundary equilibrium regularization term experimental results show gan presents compelling perceptual results also significantly outperforms state arts large scale challenging nist ijb unconstrained face recognition benchmark addition proposed gan also promising new approach solving generic transfer learning problems effectively
toward robustness label noise training deep discriminative neural networks collecting large training datasets annotated high quality labels costly process paper proposes novel framework training deep convolutional neural networks noisy labeled datasets problem formulated using undirected graphical model represents relationship noisy clean labels trained semi supervised setting proposed structure inference latent clean labels tractable regularized training using auxiliary sources information proposed model applied image labeling problem shown effective labeling unseen images well reducing label noise training cifar coco datasets
soft hard vector quantization end end learning compressible representations present new approach learn compressible representations deep architectures end end training strategy method based soft continuous relaxation quantization entropy anneal discrete counterparts throughout training showcase method two challenging applications image compression neural network compression tasks typically approached different methods soft hard quantization approach gives results competitive state art
selective classification deep neural networks selective classification techniques also known reject option yet considered context deep neural networks dnns techniques potentially significantly improve dnns prediction performance trading coverage paper propose method construct selective classifier given trained neural network method allows user set desired risk level test time classifier rejects instances needed grant desired risk high probability empirical results cifar imagenet convincingly demonstrate viability method opens possibilities operate dnns mission critical applications example using method unprecedented error top imagenet classification guaranteed probability almost test coverage
deep lattice networks partial monotonic functions propose learning deep models monotonic respect user specified set inputs alternating layers linear embeddings ensembles lattices calibrators piecewise linear functions appropriate constraints monotonicity jointly training resulting network implement layers projections new computational graph nodes tensorflow use adam optimizer batched stochastic gradients experiments benchmark real world datasets show six layer monotonic deep lattice networks achieve state art performance classification regression monotonicity guarantees
learning prune deep neural networks via layer wise optimal brain surgeon develop slim accurate deep neural networks become crucial real world applications especially employed embedded systems though previous work along research line shown promising results existing methods either fail significantly compress well trained deep network require heavy retraining process pruned deep network boost prediction performance paper propose new layer wise pruning method deep neural networks proposed method parameters individual layer pruned independently based second order derivatives layer wise error function respect corresponding parameters prove final prediction performance drop pruning bounded linear combination reconstructed errors caused layer therefore guarantee one needs perform light retraining process pruned network resume original prediction performance conduct extensive experiments benchmark datasets demonstrate effectiveness pruning method compared several state art baseline methods
bayesian compression deep learning compression computational efficiency deep learning become problem great significance work argue principled effective way attack problem taking bayesian point view sparsity inducing priors prune large parts network introduce two novelties paper use hierarchical priors prune nodes instead individual weights use posterior uncertainties determine optimal fixed point precision encode weights factors significantly contribute achieving state art terms compression rates still staying competitive methods designed optimize speed energy efficiency
lower bounds robustness adversarial perturbations input output mappings learned state art neural networks significantly discontinuous possible cause neural network used image recognition misclassify input applying specific hardly perceptible perturbations input called adversarial perturbations many hypotheses proposed explain existence peculiar samples well several methods mitigate proven explanation remains elusive however work take steps towards formal characterization adversarial perturbations deriving lower bounds magnitudes perturbations necessary change classification neural networks bounds experimentally verified mnist cifar data sets
sobolev training neural networks heart deep learning aim use neural networks function approximators training produce outputs inputs emulation ground truth function data creation process many cases access input output pairs ground truth however becoming common access derivatives target output respect input example ground truth function neural network network compression distillation generally target derivatives computed ignored paper introduces sobolev training neural networks method incorporating target derivatives addition target values training optimising neural networks approximate function outputs also function derivatives encode additional information target function within parameters neural network thereby improve quality predictors well data efficiency generalization capabilities learned function approximation provide theoretical justifications approach well examples empirical evidence three distinct domains regression classical optimisation datasets distilling policies agent playing atari large scale applications synthetic gradients three domains use sobolev training employing target derivatives addition target values results models higher accuracy stronger generalisation
structured bayesian pruning via log normal multiplicative noise dropout based regularization methods regarded injecting random noise pre defined magnitude different parts neural network training recently shown bayesian dropout procedure improves generalization also leads extremely sparse neural architectures automatically setting individual noise magnitude per weight however sparsity hardly used acceleration since unstructured paper propose new bayesian model takes account computational structure neural networks provides structured sparsity removes neurons convolutional channels cnns inject noise neurons outputs keeping weights unregularized establish probabilistic model proper truncated log uniform prior noise truncated log normal variational approximation ensures term evidence lower bound computed closed form model leads structured sparsity removing elements low snr computation graph provides significant acceleration number deep neural architectures model easy implement corresponds addition one dropout like layer computation graph
population matching discrepancy applications deep learning differentiable estimation distance two distributions based samples important many deep learning tasks one estimation maximum mean discrepancy mmd however mmd suffers sensitive kernel bandwidth hyper parameter weak gradients large mini batch size used training objective paper propose population matching discrepancy pmd estimating distribution distance based samples well algorithm learn parameters distributions using pmd objective pmd defined minimum weight matching sample populations distribution prove pmd strongly consistent estimator first wasserstein metric apply pmd two deep learning tasks domain adaptation generative modeling empirical results demonstrate pmd overcomes aforementioned drawbacks mmd outperforms mmd tasks terms performance well convergence speed
investigating learning dynamics deep neural networks using random matrix theory evidence well conditioned singular value distribution input output jacobian lead substantial improvements training performance deep neural networks deep linear networks conclusive evidence initializing using orthogonal random matrices lead dramatic improvements training however benefit initialization strategies proven much less obvious realistic nonlinear networks use random matrix theory study conditioning jacobian nonlinear neural networks random initialization show singular value distribution jacobian sensitive distribution weights also nonlinearity surprisingly find benefit orthogonal initialization negligible rectified linear networks substantial tanh networks provide rule thumb initializing tanh networks display dynamical isometry full depth finally perform experiments mnist cifar10 using wide array optimizers show conclusively singular value distribution jacobian intimately related learning dynamics finally show spectral density jacobian evolves relatively slowly training good initialization affects learning dynamics far initial setting weights
robust imitation diverse behaviors deep generative models recently shown great promise imitation learning motor control given enough data even supervised approaches one shot imitation learning however vulnerable cascading failures agent trajectory diverges demonstrations compared purely supervised methods generative adversarial imitation learning gail learn robust controllers fewer demonstrations inherently mode seeking difficult train paper show combine favourable aspects two approaches base model new type variational autoencoder demonstration trajectories learns semantic policy embeddings show embeddings learned dof jaco robot arm reaching tasks smoothly interpolated resulting smooth interpolation reaching behavior leveraging policy representations develop new version gail much robust purely supervised controller especially demonstrations avoids mode collapse capturing many diverse behaviors gail demonstrate approach learning diverse gaits demonstration biped dof humanoid mujoco physics environment
question asking program generation hallmark human intelligence ability ask rich creative revealing questions introduce cognitive model capable constructing human like questions approach treats questions formal programs executed state world output answer model specifies probability distribution complex compositional space programs favoring concise programs help agent learn current context evaluate approach modeling types open ended questions generated humans attempting learn ambiguous situation game find model predicts questions people ask generalize novel situations creative ways addition compare number model variants assess features critical producing human like questions
variational laws visual attention dynamic scenes computational models visual attention crossroad disciplines like cognitive science computational neuroscience computer vision paper proposes approach based principle foundational laws drive emergence visual attention devise variational laws eye movement rely generalized view least action principle physics potential energy captures details well peripheral visual features kinetic energy corresponds classic interpretation analytic mechanics addition lagrangian contains brightness invariance term characterizes significantly scanpath trajectories obtain differential equations visual attention stationary point generalized action propose algorithm estimate model parameters finally report experimental results validate model tasks saliency detection
flexible statistical inference mechanistic models neural dynamics mechanistic models single neuron dynamics extensively studied computational neuroscience however identifying models quantitatively reproduce empirically measured data challenging propose overcome limitation using likelihood free inference approaches also known approximate bayesian computation abc perform full bayesian inference single neuron models approach builds recent advances abc learning neural network maps features observed data posterior distribution parameters learn bayesian mixture density network approximating posterior multiple rounds adaptively chosen simulations furthermore propose efficient approach handling missing features parameter settings simulator fails prevalent issues models neural dynamics well strategy automatically learning relevant features using recurrent neural networks synthetic data approach efficiently estimates posterior distributions recovers ground truth parameters vitro recordings membrane voltages recover multivariate posteriors biophysical parameters yield model predicted voltage traces accurately match empirical data approach enable neuroscientists perform bayesian inference complex neuron models without design model specific algorithms closing gap mechanistic statistical approaches single neuron modelling
training recurrent networks generate hypotheses brain solves hard navigation problems self localization navigation noisy sensors ambiguous world computationally challenging yet animals humans excel robotics simultaneous location mapping slam algorithms solve problem though joint sequential probabilistic inference coordinates external spatial landmarks generate first neural solution slam problem training recurrent lstm networks perform set hard navigation tasks require generalization completely novel trajectories environments goal make sense diverse phenomenology brain spatial navigation circuits related function show hidden unit representations exhibit several key properties hippocampal place cells including stable tuning curves remap environments result also proof concept end end learning slam algorithm using recurrent networks demonstration approach may advantages robotic slam
yass yet another spike sorter spike sorting critical first step extracting neural signals large scale electrophysiological data manuscript describes automatic efficient reliable pipeline spike sorting dense multi electrode arrays meas neural signals appear across many electrodes spike sorting currently represents major computational bottleneck present several new techniques make dense mea spike sorting robust scalable pipeline based efficient multi stage triage cluster pursuit approach initially extracts clean high quality waveforms electrophysiological time series temporarily discarding noisy orcollided events representing two neurons firing synchronously accomplished developing neural net detection method followed efficient outlier triaging clean waveforms used infer number neurons shapes nonparametric bayesian clustering clustering approach adapts coreset approach data reduction uses efficient inference methods dirichlet process mixture model framework dramatically improve scalability reliability entire pipeline thetriaged waveforms finally recovered matching pursuit deconvolution techniques proposed methods improve state art terms accuracy stability real biophysically realistic simulated mea data furthermore proposed pipeline efficient learning templates clustering much faster real time 512 electrode dataset using primarily single cpu core
neural system identification large populations separating neuroscientists classify neurons different types perform similar computations different locations visual field traditional neural system identification methods capitalize separation learning deep convolutional feature spaces shared among many neurons provides exciting path forward architectural design needs account data limitations new experimental techniques enable recordings thousands neurons experimental time limited one sample small fraction neuron response space show major bottleneck fitting convolutional neural networks cnns neural data estimation individual receptive field locations problem scratched surface thus far propose cnn architecture sparse pooling layer factorizing spatial feature dimensions network scales well thousands neurons short recordings trained end end explore architecture ground truth data explore challenges limitations cnn based system identification moreover show network model outperforms current state art system identification model mouse primary visual cortex publicly available dataset
simple model recognition recall memory show several striking differences memory performance recognition recall tasks explained ecological bias endemic classic memory experiments experiments universally involve stimuli retrieval cues show sensible think recall simply retrieving items probed cue typically item list better think recognition retrieving cues probed items test theory manipulating number items cues memory experiment show crossover effect memory performance within subjects recognition performance superior recall performance number items greater number cues recall performance better recognition converse holds build simple computational model around theory using sampling approximate ideal bayesian observer encoding retrieving situational occurrence frequencies stimuli retrieval cues model robustly reproduces number dissociations recognition recall previously used argue dual process accounts declarative memory
gaussian process based nonlinear latent structure discovery multivariate spike train data large body recent work focused methods identifying low dimensional latent structure multi neuron spike train data methods employed either linear latent dynamics linear log linear mappings latent space spike rates propose doubly nonlinear latent variable model population spike trains identify nonlinear low dimensional structure underlying apparently high dimensional spike train data model poisson gaussian process latent variable model gplvm defined low dimensional latent variable governed gaussian process nonlinear tuning curves parametrized exponentiated samples second gaussian process poisson observations nonlinear tuning curves allow discovery low dimensional latent embeddings even spike rates span high dimensional subspace hippocampal place cell codes learn model introduce decoupled laplace approximation fast approximate inference method allows efficiently maximize marginal likelihood latent path integrating tuning curves show method outperforms previous approaches maximizing laplace approximation based marginal likelihoods convergence speed value final objective apply model spike trains recorded hippocampal place cells show outperforms variety previous methods latent structure discovery including variational auto encoder based methods parametrize nonlinear mapping latent space spike rates deep neural network
deep adversarial neural decoding present novel approach solve problem reconstructing perceived stimuli brain responses combining probabilistic inference deep learning approach first inverts linear transformation latent features brain responses maximum posteriori estimation inverts nonlinear transformation perceived stimuli latent features adversarial training convolutional neural networks test approach functional magnetic resonance imaging experiment show generate state art reconstructions perceived faces brain activations
cross spectral factor analysis neuropsychiatric disorders schizophrenia depression often disruption way different regions brain communicate one another order build greater understanding neurological basis disorders introduce novel model multisite local field potentials lfps low frequency voltage oscillations measured electrodes implanted many brain regions simultaneously proposed model called cross spectral factor analysis csfa breaks observed lfps electrical functional connectomes electomes defined differing spatiotemporal properties electome defined unique frequency power phase coherence patterns many brain regions properties granted features via gaussian process formulation multiple kernel learning framework critically electomes interpretable used design follow causal studies furthermore using formulation lfp signals mapped lower dimensional space better traditional approaches remarkably addition interpretability proposed approach achieves state art predictive ability compared black box approaches looking behavioral paradigms genotype prediction tasks mouse model demonstrating feature basis capturing neural dynamics related outcomes conclude discussion csfa analysis used conjunction experiments design causal studies provide gold standard validation inferred neural relationships
cognitive impairment prediction alzheimer disease regularized modal regression accurate automatic predictions cognitive assessment via neuroimaging markers critical early detection alzheimer disease linear regression models successfully used association study neuroimaging features cognitive performance alzheimer disease study however existing methods built least squares mean square error mse criterion sensitive outliers performance may degraded heavy tailed noise complex brain disorder data paper beyond criterion investigating regularized modal regression statistical learning viewpoint new regularized scheme based modal regression proposed estimation variable selection robust outliers heavy tailed noise skewed noise conduct theoretical analysis establish approximation bound learning conditional mode function sparsity analysis variable selection robustness characterization experimental evaluations simulated data adni cohort data provided support promising performance proposed algorithm
stochastic submodular maximization case coverage functions continuous optimization techniques sgd extensions main workhorse modern machine learning nevertheless variety important machine learning problems require solving discrete optimization problems submodular objectives goal paper unleash toolkit modern continuous optimization discrete problems first introduce framework emph stochastic submodular optimization instead emph oracle access underlying objective one explicitly considers statistical computational aspects evaluating objective provide formalization emph stochastic submodular maximization class important discrete optimization problems show state art techniques continuous optimization lifted realm discrete optimization extensive experimental evaluation demonstrate practical impact proposed approach
gradient methods submodular maximization paper study problem maximizing continuous submodular functions naturally arise many learning applications involving utility functions active learning sensing matrix approximations network inference despite apparent lack convexity functionals prove stochastic projected gradient methods provide strong approximation guarantees maximizing continuous submodular functions convex constraints specifically prove monotone continuous submodular functions fixed points projected gradient ascent provide factor approximation global maxima also study stochastic gradient mirror methods show iterations methods reach solutions achieve expectaion objective values exceeding opt2 one immediate implication result bridge discrete continuous submodular maximization finally experiments real data demonstrate projected gradient methods consistently achieve best utility compared continuous baselines remaining competitive terms computational effort
non convex finite sum optimization via scsg methods develop class algorithms variants stochastically controlled stochastic gradient scsg methods smooth nonconvex finite sum optimization problem assuming smoothness component complexity scsg reach stationary point min 1n2 strictly outperforms stochastic gradient descent moreover scsg never worse state art methods based variance reduction significantly outperforms target accuracy low similar acceleration also achieved functions satisfy polyak lojasiewicz condition empirical experiments demonstrate scsg outperforms stochastic gradient methods training multi layers neural networks terms training validation loss
influence maximization almost submodular threshold function influence maximization problem selecting nodes social network maximize influence spread problem extensively studied works focus submodular influence diffusion models paper motivated empirical evidences explore influence maximization non submodular regime particular study general threshold model fraction nodes non submodular threshold functions threshold functions closely upper lower bounded submodular functions call almost submodular first show strong hardness result approximation influence maximization unless networks almost submodular nodes parameter depending although threshold function close submodular influence maximization still hard approximate provide approximation algorithms number almost submodular nodes finally conduct experiments number real world datasets results demonstrate approximation algorithms outperform benchmark algorithms
subset selection noise problem selecting best element subset universe involved many applications previous studies assumed noise free environment noisy monotone submodular objective function paper considers realistic general situation evaluation subset noisy monotone function necessarily submodular multiplicative additive noises understand impact noise firstly show approximation ratio greedy algorithm poss two powerful algorithms noise free subset selection noisy environments propose incorporate noise aware strategy poss resulting new ponss algorithm better approximation ratio empirical results influence maximization sparse regression problems show superior performance ponss
polynomial time algorithms dual volume sampling study dual volume sampling method selecting columns short wide matrix probability selection proportional volume spanned rows induced submatrix method proposed avron boutsidis 2013 showed promising method column subset selection multiple applications however wider adoption hampered lack polynomial time sampling algorithms remove hindrance developing exact randomized polynomial time sampling algorithm well derandomization thereafter study dual volume sampling via theory real stable polynomials prove distribution satisfies strong rayleigh property result remarkable consequences especially implies provably fast mixing markov chain sampler makes dual volume sampling much attractive practitioners sampler closely related classical algorithms popular experimental design methods date lacking theoretical analysis known empirically work well
lookahead bayesian optimization inequality constraints consider task optimizing objective function subject inequality constraints objective constraints expensive evaluate bayesian optimization popular way tackle optimization problems expensive objective function evaluations mostly applied unconstrained problems several approaches proposed address expensive constraints limited greedy strategies maximizing immediate reward address limitation propose lookahead approach selects next evaluation order maximize long term feasible reduction objective function present numerical experiments demonstrating performance improvements lookahead approach compared two greedy algorithms constrained expected improvement eic predictive entropy search constraint pesc
non monotone continuous submodular maximization structure algorithms submodular continuous functions important objectives wide real world applications spanning map inference determinantal point processes dpps mean field inference probabilistic submodular models amongst others submodularity captures subclass non convex functions enables exact minimization approximate maximization polynomial time work study problem maximizing non monotone submodular continuous functions general closed convex constraints start investigating several properties underlie objectives used devise two optimization algorithms provable guarantees concretely first devise two phase algorithm approximation guarantee algorithm allows use existing methods ensured find approximate stationary points subroutine thus enabling utilize recent progress non convex optimization present non monotone frank wolfe variant approximation guarantee sublinear convergence rate finally extend approach broader class generalized submodular continuous functions captures wider spectrum applications theoretical findings validated several synthetic real world problem instances
solving almost systems random quadratic equations paper deals finding dimensional solution bmx system quadratic equations bmai bmx general known hard put forth novel procedure starts emph weighted maximal correlation initialization obtainable power iterations followed successive refinements based emph iteratively reweighted gradient type iterations novel techniques distinguish prior works inclusion fresh weighting regularization certain random measurement models proposed procedure returns true solution bmx high probability time proportional reading data bmai provided number equations constant times number unknowns namely empirically upshots contribution perfect signal recovery high dimensional regime given information theoretic limit number equations near optimal statistical accuracy presence additive noise extensive numerical tests using synthetic data real images corroborate improved signal recovery performance computational efficiency relative state art approaches
learning relus via gradient descent paper study problem learning rectified linear units relus functions form vctx max vctw vctx vctw denoting weight vector study problem high dimensional regime number observations fewer dimension weight vector assume weight vector belongs closed set convex nonconvex captures known side information structure focus realizable model inputs chosen gaussian distribution labels generated according planted weight vector show projected gradient descent initialization vct0 converges linear rate planted model number samples optimal numerical constants results dynamics convergence shallow neural nets may provide insights towards understanding dynamics deeper architectures
stochastic mirror descent non convex optimization paper examine class non convex stochastic programs call emph variationally coherent properly includes quasi pseudo convex optimization problems establish convergence class problems study well known smd method show algorithm last iterate converges problem global optimum probability results contribute landscape non convex optimization clarifying convexity quasi convexity essential global convergence rather variational coherence much weaker requirement suffices localize class account locally variationally coherent problems show last iterate stochastic mirror descent converges local optima high probability finally consider last iterate convergence rates problems sharp minima derive special case conclusion probability last iterate stochastic gradient descent reaches exact global optimum finite number steps result contrasted existing work linear programs exhibit asymptotic convergence rates
accelerated first order methods geodesically convex optimization riemannian manifolds paper propose accelerated first order method geodesically convex optimization generalization standard nesterov accelerated method euclidean space nonlinear riemannian space first derive two equations approximate linearization gradient like updates euclidean space geodesically convex optimization particular analyze global convergence properties accelerated method geodesically strongly convex problems show method improves convergence rate sqrt moreover method also improves global convergence rate geodesically general convex problems finally give specific iterative scheme matrix karcher mean problems validate theoretical results experiments
fine grained complexity empirical risk minimization kernel methods neural networks empirical risk minimization erm ubiquitous machine learning underlies supervised learning methods large body work algorithms various erm problems exact computational complexity erm still understood address issue multiple popular erm problems including kernel svms kernel ridge regression training final layer neural network particular give conditional hardness results problems based complexity theoretic assumptions strong exponential time hypothesis assumptions show algorithms solve aforementioned erm problems high accuracy sub quadratic time also give similar hardness results computing gradient empirical loss main computational burden many non convex learning tasks
large scale quadratically constrained quadratic program via low discrepancy sequences consider problem solving large scale quadratically constrained quadratic program problems occur naturally many scientific web applications although efficient methods tackle problem mostly scalable paper develop method transforms quadratic constraint linear form sampling set low discrepancy points transformed problem solved applying state art large scale solvers show convergence approximate solution true solution well finite sample error bounds experimental results also shown prove scalability practice
new alternating direction method linear programming well known linear program constraint matrix alternating direction method multiplier converges globally linearly rate log however rate related problem dimension algorithm exhibits slow fluctuating tail convergence practice paper propose new variable splitting method prove method convergence rate 2log proof based simultaneously estimating distance pair primal dual iterates optimal primal dual solution set certain residuals practice result new first order solver exploit sparsity specific structure matrix significant speedup important problems basis pursuit inverse covariance matrix estimation svm nonnegative matrix factorization problem compared current fastest solvers
dykstra algorithm admm coordinate descent connections insights extensions study connections dykstra algorithm projecting onto intersection convex sets augmented lagrangian method multipliers admm block coordinate descent prove coordinate descent regularized regression problem separable penalty functions seminorms exactly equivalent dykstra algorithm applied dual problem admm dual problem also seen equivalent special case two sets one linear subspace connections aside interesting right suggest new ways analyzing extending coordinate descent example existing convergence theory dykstra algorithm polyhedra discern coordinate descent lasso problem converges asymptotically linear rate also develop two parallel versions coordinate descent based dykstra admm connections
smooth primal dual coordinate descent algorithms nonsmooth convex optimization propose new randomized coordinate descent method convex optimization template broad applications analysis relies novel combination four ideas applied primal dual gap function smoothing acceleration homotopy non uniform sampling result method features first convergence rate guarantees best known variety common structure assumptions template provide numerical evidence support theoretical results comparison state art algorithms
first order adaptive sample size methods reduce complexity empirical risk minimization paper studies empirical risk minimization erm problems large scale datasets incorporates idea adaptive sample size methods improve guaranteed convergence bounds first order stochastic deterministic methods contrast traditional methods attempt solve erm problem corresponding full dataset directly adaptive sample size schemes start small number samples solve corresponding erm problem statistical accuracy sample size grown geometrically scaling factor two use solution previous erm warm start new erm theoretical analyses show use adaptive sample size methods reduces overall computational cost achieving statistical accuracy whole dataset broad range deterministic stochastic first order methods gains specific choice method particularized accelerated gradient descent stochastic variance reduce gradient computational cost advantage logarithm number training samples numerical experiments various datasets confirm theoretical claims showcase gains using proposed adaptive sample size scheme
accelerated consensus via min sum splitting apply min sum message passing protocol solve consensus problem distributed optimization show ordinary min sum algorithm converge modified version known splitting yields convergence problem solution prove proper choice tuning parameters allows min sum splitting yield subdiffusive accelerated convergence rates matching rates obtained shift register methods acceleration scheme embodied min sum splitting consensus problem bears similarities lifted markov chains techniques multi step first order methods convex optimization
integration methods optimization algorithms show accelerated optimization methods seen particular instances multi step integration schemes numerical analysis applied gradient flow equation compared recent advances vein differential equation considered basic gradient flow derive class multi step schemes includes accelerated algorithms using classical conditions numerical analysis multi step schemes integrate differential equation using larger step sizes intuitively explains acceleration phenomenon
efficient use limited memory resources accelerate linear learning work propose generic approach efficiently use compute accelerators gpus fpgas training large scale machine learning models training data exceeds memory capacity technique builds upon primal dual coordinate selection uses duality gaps selection criteria dynamically decide part data made available fast processing provide strong theoretical guarantees motivating gap based selection scheme provide efficient practical implementation thereof illustrate power approach demonstrate performance training generalized linear models large scale datasets exceeding memory size modern gpu showing order magnitude speedup existing approaches
screening rule regularized ising model estimation discover screening rule regularized ising model estimation simple closed form screening rule necessary sufficient condition exactly recovering blockwise structure solution given regularization parameters enough sparsity screening rule combined exact inexact optimization procedures deliver solutions efficiently practice screening rule especially suitable large scale exploratory data analysis number variables dataset thousands interested relationship among handful variables within moderate size clusters interpretability experimental results various datasets demonstrate efficiency insights gained introduction screening rule
uprooting rerooting higher order graphical models idea uprooting rerooting graphical models introduced specifically binary pairwise models weller way transform model whole equivalence class related models inference one model yields inference results others helpful since inference relevant bounds may much easier obtain accurate model class introduce methods extend approach models higher order potentials develop theoretical insights example demonstrate triplet consistent polytope tri unique universally rooted demonstrate empirically rerooting significantly improve accuracy methods inference higher order models negligible computational cost
concentration multilinear functions ising model applications network data prove near tight concentration measure polynomial functions ising model high temperature improving radius concentration guaranteed known results polynomial factors dimension number nodes ising model show results optimal logarithmic factors dimension obtain results extending strengthening exchangeable pairs approach used prove concentration measure setting chatterjee demonstrate efficacy functions statistics testing strength interactions social networks synthetic real world data
inference graphical models via semidefinite programming hierarchies maximum posteriori probability map inference graphical models amounts solving graph structured combinatorial optimization problem popular inference algorithms belief propagation generalized belief propagation gbp intimately related linear programming relaxation within sherali adams hierarchy despite popularity algorithms well understood sum squares sos hierarchy based semidefinite programming sdp provide superior guarantees unfortunately sos relaxations graph vertices require solving sdp variables degree hierarchy practice approach scale beyond tens variables paper propose sdp relaxations map inference using sos hierarchy two innovations focused computational efficiency firstly analogy variants introduce decision variables corresponding contiguous regions graphical model secondly solve resulting sdp using non convex burer monteiro style method develop sequential rounding procedure demonstrate resulting algorithm solve problems tens thousands variables within minutes significantly outperforms gbp practical problems image denoising ising spin glasses finally specific graph types establish sufficient condition tightness proposed partial sos relaxation
beyond normality learning sparse probabilistic graphical models non gaussian setting present algorithm identify sparse dependence structure continuous non gaussian probability distributions given corresponding set data conditional independence structure arbitrary distribution represented undirected graph markov random field algorithms learning structure restricted discrete gaussian cases new approach allows realistic accurate descriptions distribution question turn better estimates sparse markov structure sparsity graph interest accelerate inference improve sampling methods reveal important dependencies variables algorithm relies exploiting connection sparsity graph sparsity transport maps deterministically couple one probability measure another
dynamic importance sampling anytime bounds partition function computing partition function key inference task many graphical models paper propose dynamic importance sampling scheme provides anytime finite sample bounds partition function algorithm balances advantages three major inference strategies heuristic search variational bounds monte carlo methods blending sampling search refine variationally defined proposal algorithm combines generalizes recent work anytime search probabilistic bounds partition function using intelligently chosen weighted average samples construct unbiased estimator partition function strong finite sample confidence intervals inherit rapid early improvement rate sampling long term benefits improved proposal search gives significantly improved anytime behavior flexible trade offs memory time solution quality demonstrate effectiveness approach empirically real world problem instances taken recent uai competitions
nonbacktracking bounds influence independent cascade models paper develops upper lower bounds influence measure network precisely expected number nodes seed set influence independent cascade model particular bounds exploit nonbacktracking walks fortuin kasteleyn ginibre fkg type inequalities computed message passing implementation nonbacktracking walks recently allowed headways community detection paper shows use also impact influence computation provide knob control trade efficiency accuracy bounds finally tightness bounds illustrated simulations various network models
rigorous dynamics consistent estimation arbitrarily conditioned linear systems problem estimating random vector noisy linear measurements unknown parameters distributions must also learned arises wide range statistical learning linear inverse problems show computationally simple iterative message passing algorithm provably obtain asymptotically consistent estimates certain high dimensional large system limit lsl general parameterizations previous message passing techniques required sub gaussian matrices often fail matrix ill conditioned proposed algorithm called adaptive vector approximate message passing adaptive vamp auto tuning applies right rotationally random importantly class includes matrices arbitrarily bad conditioning show parameter estimates mean squared error mse iteration converge deterministic limits precisely predicted simple set state evolution equations addition simple testable condition provided mse matches bayes optimal value predicted replica method paper thus provides computationally simple method provable guarantees optimality consistency large class linear inverse problems
learning disentangled representations semi supervised deep generative models variational autoencoders vaes learn representations data jointly training probabilistic encoder decoder network typically models encode features data single variable interested learning disentangled representations encode distinct aspects data separate variables propose learn representations using model architectures generalize standard vaes employing general graphical model structure encoder decoder allows train partially specified models make relatively strong assumptions subset interpretable variables rely flexibility neural networks learn representations remaining variables define general objective semi supervised learning model class approximated using importance sampling procedure applies generally class models evaluate framework ability learn disentangled representations qualitative exploration generative capacity quantitative evaluation discriminative ability variety models datasets
gauging variational inference computing partition function important statistical inference task arising applications graphical models since computationally intractable approximate methods used resolve issue practice mean field belief propagation arguably popular successful approaches variational type paper propose two new variational schemes coined gauged gauged improving respectively provide lower bounds partition function utilizing called gauge transformation modifies factors keeping partition function invariant moreover prove exact gms single loop special structure even though bare perform badly case extensive experiments complete gms relatively small size large 300 variables confirm newly proposed algorithms outperform generalize
variational inference via upper bound minimization variational inference widely used efficient alternative mcmc posits family approximating distributions finds member closest true posterior closeness usually measured via divergence though successful approach also problems notably typically leads underestimation posterior variance paper propose chivi new black box variational inference algorithm minimizes divergence chivi minimizes upper bound model evidence term cubo minimizing cubo leads better estimates posterior used classical lower bound elbo provide sandwich estimate marginal likelihood study chivi three models probit regression gaussian process classification cox process model basketball plays compared classical chivi produces better error rates accurate estimates posterior variance
collapsed variational bayes markov jump processes markov jump processes continuous time stochastic processes widely used statistical applications natural sciences recently machine learning inference models typically proceeds via markov chain monte carlo suffer various computational challenges work propose novel collapsed variational inference algorithm address issue work leverages ideas discrete time markov chains exploits connection two idea called uniformization algorithm proceeds marginalizing parameters markov jump process approximating distribution trajectory factored distribution segments piecewise constant function unlike mcmc schemes marginalize transition times piecewise constant process scheme optimizes discretization time resulting significant computational savings apply ideas synthetic data well dataset check recordings demonstrate superior performance state art mcmc methods
bayesian dyadic trees histograms regression many machine learning tools regression based recursive partitioning covariate space smaller regions regression function estimated locally among regression trees ensembles demonstrated impressive empirical performance work shed light machinery behind bayesian variants methods particular study bayesian regression histograms bayesian dyadic trees simple regression case one predictor focus reconstruction regression surfaces piecewise constant number jumps unknown show suitably designed priors posterior distributions concentrate around true step regression function minimax rate log factor results require knowledge true number steps width true partitioning cells thus bayesian dyadic regression trees fully adaptive recover true piecewise regression function nearly well knew exact number location jumps results constitute first step towards understanding bayesian trees ensembles worked well practice aside discuss prior distributions balanced interval partitions relate problem geometric probability namely quantify probability covering circumference circle random arcs whose endpoints confined grid new variant original problem
differentially private bayesian learning distributed data many applications machine learning example health care would benefit methods guarantee privacy data subjects differential privacy become established standard protecting learning results standard algorithms require single trusted party access entire data clear weakness consider bayesian learning distributed setting party holds single sample samples data propose learning strategy based secure multi party sum function aggregating summaries data holders gaussian mechanism method builds asymptotically optimal practically efficient bayesian inference rapidly diminishing extra cost
model powered conditional independence test consider problem non parametric conditional independence testing testing continuous random variables given samples joint distribution continuous random vectors determine whether independenty approach converting conditional independence test classification problem allows harness powerful classifiers like gradient boosted trees deep neural networks models handle complex probability distributions allow perform significantly better compared prior state art high dimensional testing main technical challenge classification problem need samples conditional product distribution fci joint distribution independenty given access samples true joint distribution tackle problem propose novel nearest neighbor bootstrap procedure theoretically show generated samples indeed close fci terms total variational distance develop theoretical results regarding generalization bounds classification problem translate error bounds testing provide novel analysis rademacher type classification bounds presence non textit near independent samples empirically validate performance algorithm simulated real datasets show performance gains previous methods
worlds collide integrating different counterfactual assumptions fairness machine learning used make crucial decisions people lives nearly decisions risk individuals certain race gender sexual orientation subpopulation unfairly discriminated recent method demonstrated use techniques counterfactual inference make predictions fair across different subpopulations method requires one provides causal model generated data hand genera validating causal model impossible using observational data alone without assumptions hence desirable integrate competing causal models provide counterfactually fair decisions regardless world correct one paper show possible make predictions approximately fair respect multiple possible causal models thus bypassing problem exact causal specification frame goal learning fair classifier optimization problem fairness constraints provide techniques relaxations solve optimization problem demonstrate flexibility model two real world fair classification problems show model seamlessly balance fairness multiple worlds prediction accuracy
lda uncovering latent patterns text based sequential decision processes sequential decision making often important useful end users understand underlying patterns causes lead corresponding decisions however typical deep reinforcement learning algorithms seldom provide information due black box nature paper present probabilistic model lda uncover latent patterns text based sequential decision processes model understood variant latent topic models tailored maximize total rewards draw interesting connection approximate maximum likelihood estimation lda celebrated learning algorithm demonstrate text game domain proposed method provides viable mechanism uncover latent patterns decision processes also obtains state art rewards games
probabilistic models integration error assessment functional cardiac models paper studies numerical computation integrals representing estimates predictions output computational model respect distribution uncertain inputs model functional cardiac models motivate work neither possess closed form expression evaluation either requires 100 cpu hours precluding standard numerical integration methods proposal treat integration estimation problem joint model priori unknown function priori unknown distribution result posterior distribution integral explicitly accounts dual sources numerical approximation error due severely limited computational budget construction applied account statistically principled manner impact numerical errors present confounding factors functional cardiac model assessment
expectation propagation exponential family using algebra exponential family distributions highly useful machine learning since calculation performed efficiently natural parameters exponential family recently extended emph exponential family contains student distributions family members thus allows handle noisy data well however since exponential family defined emph deformed exponential cannot derive efficient learning algorithm exponential family expectation propagation paper borrow mathematical tools algebra statistical physics show pseudo additivity distributions allows perform calculation exponential family distributions natural parameters develop expectation propagation algorithm exponential family provides deterministic approximation posterior predictive distribution simple moment matching finally apply proposed algorithm bayes point machine student process classification demonstrate performance numerically
probabilistic framework nonlinearities stochastic neural networks present probabilistic framework nonlinearities based doubly truncated gaussian distributions setting truncation points appropriately able generate various types nonlinearities within unified framework including sigmoid tanh relu commonly used nonlinearities neural networks framework readily integrates existing stochastic neural networks hidden units characterized random variables allowing one first time learn nonlinearities alongside model weights networks extensive experiments demonstrate performance improvements brought proposed framework integrated restricted boltzmann machine rbm temporal rbm truncated gaussian graphical model tggm
clone mcmc parallel high dimensional gaussian gibbs sampling propose generalized gibbs sampler algorithm obtaining samples approx imately distributed high dimensional gaussian distribution similarly hogwild methods approach target original gaussian distribution interest approximation contrary hogwild methods single parameter allows trade bias variance show empirically method flexible performs well compared hogwild type algorithms
learning spatiotemporal piecewise geodesic trajectories longitudinal manifold valued data introduce hierarchical model allows estimate group average piecewise geodesic trajectory riemannian space measurements individual variability model falls well defined mixed effect models subject specific trajectories defined spatial temporal transformations group average piecewise geodesic path component component thus apply model wide variety situations due non linearity model use stochastic approximation expectation maximization algorithm estimate model parameters experiments synthetic data validate choice model applied metastatic renal cancer chemotherapy monitoring run estimations recist scores treated patients estimate time escape treatment experiments highlight role different parameters response treatment
scalable levy process priors spectral kernel learning gaussian processes rich distributions functions generalisation properties determined kernel function propose distribution kernels formed modelling spectral density levy process resulting distribution support stationary covariances including popular rbf periodic matern kernels combined inductive biases enable automatic data efficient learning long range extrapolation state art predictive performance posterior inference develop reversible jump mcmc approach includes automatic selection model order exploit algebraic structure proposed process training predictions show proposed model empirically recover flexible ground truth covariances demonstrate extrapolation several benchmarks
inferring latent structure human decision making raw visual inputs goal imitation learning match example expert behavior without access reinforcement signal expert demonstrations provided humans however often show significant variability due latent factors explicitly modeled introduce extension generative adversarial imitation learning method infer latent structure human decision making unsupervised way method imitate complex behaviors also learn interpretable meaningful representations demonstrate approach applicable high dimensional environments including raw visual inputs highway driving domain show model learned demonstrations able produce different driving styles accurately anticipate human actions method surpasses various baselines terms performance functionality
hybrid reward architecture reinforcement learning one main challenges reinforcement learning generalisation typical deep methods achieved approximating optimal value function low dimensional representation using deep network approach works well many domains domains optimal value function cannot easily reduced low dimensional representation learning slow unstable paper contributes towards tackling challenging domains proposing new method called hybrid reward architecture hydra hydra takes input decomposed reward function learns separate value function component reward function component typically depends subset features overall value function much smoother easier approximated low dimensional representation enabling effective learning demonstrate hydra toy problem atari game pac man hydra achieves human performance
shallow updates deep reinforcement learning deep reinforcement learning drl methods deep network dqn achieved state art results variety challenging high dimensional domains success mainly attributed power deep neural networks learn rich domain representations approximating value function policy batch reinforcement learning methods linear representations hand stable require less hyper parameter tuning yet substantial feature engineering necessary achieve good results work propose hybrid approach least squares deep network dqn combines rich feature representations learned drl algorithm stability linear least squares method periodically training last hidden layer drl network batch least squares update key approach bayesian regularization term least squares update prevents fitting recent data tested dqn five atari games demonstrate significant improvement vanilla dqn double dqn also investigated reasons superior performance method interestingly found performance improvement attributed large batch size used method optimizing last layer
towards generalization simplicity continuous control remarkable successes deep learning speech recognition computer vision motivated efforts adapt similar techniques problem domains including reinforcement learning consequently methods produced rich motor behaviors simulated robot tasks success largely attributed use multi layer neural networks work among first carefully study might responsible recent advancements main result calls emerging narrative question showing much simpler architectures based linear rbf parameterizations achieve comparable performance state art results study different policy representations regard performance measures hand also towards robustness external perturbations find learned neural network policies standard training scenarios robust linear rbf policies fact three remarkably brittle finally directly modify training scenarios order favor robust policies find compelling case favor multi layer architectures overall study suggests multi layer architectures default choice unless side side comparison simpler architectures shows otherwise generally hope results lead interest carefully studying architectural choices associated trade offs training generalizable robust policies
interpolated policy gradient merging policy policy gradient estimation deep reinforcement learning policy model free deep reinforcement learning methods using previously collected data improve sample efficiency policy policy gradient techniques hand policy algorithms often stable easier use paper examines theoretically empirically approaches merging policy updates deep reinforcement learning theoretical results show policy updates value function estimator interpolated policy policy gradient updates whilst still satisfying performance bounds analysis uses control variate methods produce family policy gradient algorithms several recently proposed algorithms special cases family provide empirical comparison techniques remaining algorithmic details fixed show different mixing policy gradient estimates policy samples contribute improvements empirical performance final algorithm provides generalization unification existing deep policy gradient techniques theoretical guarantees bias introduced policy updates improves state art model free deep methods number openai gym continuous control benchmarks
scalable planning tensorflow hybrid nonlinear domains given recent deep learning results demonstrate ability effectively optimize high dimensional non convex functions gradient descent optimization gpus ask paper whether symbolic gradient optimization tools tensorflow effective planning hybrid mixed discrete continuous nonlinear domains high dimensional state action spaces end demonstrate hybrid planning tensorflow rmsprop gradient descent competitive mixed integer linear program milp based optimization piecewise linear planning domains compute optimal solutions substantially outperforms state art interior point methods nonlinear planning domains furthermore remark tensorflow highly scalable converging strong policy large scale concurrent domain total 576 000 continuous actions horizon time steps minutes provide number insights clarify strong performance including observations despite long horizons rmsprop avoids vanishing exploding gradients problem together results suggest new frontier highly scalable planning nonlinear hybrid domains leveraging gpus power recent advances gradient descent highly optmized toolkits like tensorflow
task based end end model learning stochastic optimization machine learning techniques becoming widespread become common see prediction algorithms operating within larger process however criteria train algorithms often differ ultimate criteria evaluate paper proposes end end approach learning probabilistic machine learning models within context stochastic programming manner directly captures ultimate task based objective used present two experimental evaluations proposed approach classical inventory stock problem real world electrical grid scheduling task cases show proposed approach outperform traditional modeling purely black box policy optimization approaches
value prediction network paper proposes novel deep reinforcement learning approach called value prediction network vpn integrates model free model based methods single neural network contrast typical model based methods vpn learns dynamics model whose abstract states trained make option conditional predictions future values rather future observations experimental results show vpn several advantages model free model based baselines stochastic environment careful planning required building accurate observation prediction model difficult furthermore vpn outperforms deep network dqn several atari games even short lookahead planning demonstrating potential new way learning good state representation
variable importance using decision trees decision trees random forests well established models offer good predictive performance also provide rich feature importance information practitioners often employ variable importance methods rely impurity based information methods remain poorly characterized theoretical perspective provide novel insights performance methods deriving finite sample performance guarantees high dimensional setting various modeling assumptions demonstrate effectiveness impurity based methods via extensive set simulations
expressive power neural networks view width expressive power neural networks important understanding deep learning existing works consider problem view depth network paper study width affects expressiveness neural networks classical results state emph depth bounded depth networks suitable activation functions universal approximators show universal approximation theorem emph width bounded relu networks width relu networks input dimension universal approximators moreover except measure zero set functions cannot approximated width relu networks exhibits phase transition several recent works demonstrate benefits depth proving depth efficiency neural networks classes deep networks cannot realized shallow network whose size emph exponential bound pose dual question width efficiency relu networks wide networks cannot realized narrow networks whose size substantially larger show exist classes wide networks cannot realized narrow network whose depth emph polynomial bound hand demonstrate extensive experiments narrow networks whose depth exceed polynomial bound constant factor approximate wide shallow network high accuracy results provide comprehensive evidence depth effective width expressiveness relu networks
sgd learns conjugate kernel class network show standard stochastic gradient decent sgd algorithm guaranteed learn polynomial time function competitive best function conjugate kernel space network defined daniely frostig singer result holds log depth networks rich family architectures best knowledge first polynomial time guarantee standard neural network learning algorithm networks depth two corollaries follows neural networks depth log sgd guaranteed learn polynomial time constant degree polynomials polynomially bounded coefficients likewise follows sgd large enough networks learn continuous function polynomial time complementing classical expressivity results
radon machines effective parallelisation machine learning order simplify adaptation learning algorithms growing amounts data well growing need accurate confident predictions critical applications paper propose novel provably effective parallelisation scheme contrast parallelisation techniques scheme applied broad class learning algorithms without mathematical derivations without writing single line additional code achieve treating learning algorithm black box applied parallel random data subsets resulting hypotheses assigned leaves aggregation tree bottom replaces set hypotheses corresponding inner node tree radon point considering confidence parameters epsilon delta input learning algorithm efficient sample complexity polynomial epsilon delta time complexity polynomial sample complexity parallelisation scheme algorithm achieve guarantees applied polynomial number cores polylogarithmic time result allows effective parallelisation broad class learning algorithms intrinsically related nick class decision problems well learnability exact learning cost parallelisation form slightly larger sample complexity empirical study confirms potential parallisation scheme range data sets several learning algorithms
noise tolerant interactive learning using pairwise comparisons study problem interactively learning binary classifier using noisy labeling pairwise comparison oracles comparison oracle answers one given two instances likely positive learning oracles multiple applications obtaining direct labels harder pairwise comparisons easier algorithm leverage types oracles paper attempt characterize access easier comparison oracle helps improving label total query complexity show comparison oracle reduces learning problem learning threshold function present algorithm interactively queries label comparison oracles characterize query complexity tsybakov adversarial noise conditions comparison labeling oracles lower bounds show label total query complexity almost optimal
pac bayesian analysis randomized learning application stochastic gradient descent analyze generalization properties randomized learning algorithms focusing stochastic gradient descent sgd using novel combination pac bayes algorithmic stability importantly risk bounds hold posterior distributions algorithm hyperparameters including distributions depend training data inspires adaptive sampling algorithm sgd optimizes posterior runtime analyze algorithm context risk bounds evaluate empirically benchmark dataset
revisiting perceptron efficient label optimal learning halfspaces long standing problem efficiently learn linear separator using labels possible presence noise work propose efficient perceptron based algorithm actively learning homogeneous linear separators uniform distribution bounded noise label flipped probability eta algorithm achieves near optimal tilde frac 2eta frac epsilon label complexity time tilde frac epsilon 2eta adversarial noise tilde omega epsilon fraction labels flipped algorithm achieves near optimal tilde frac epsilon label complexity time tilde frac epsilon furthermore show active learning algorithm converted efficient passive learning algorithm near optimal sample complexity respect epsilon
sample computationally efficient learning algorithms concave distributions provide new results noise tolerant sample efficient learning algorithms concave distributions new class concave distributions broad natural generalization log concavity includes many important additional distributions pareto distribution distribution class studied context efficient sampling integration optimization much remains unknown geometry class distributions applications context learning challenge unlike commonly used distributions learning uniform generally log concave distributions broader class closed marginalization operator many distributions fat tailed work introduce new convex geometry tools study properties concave distributions use properties provide bounds quantities interest learning including probability disagreement two halfspaces disagreement outside band disagreement coefficient use results significantly generalize prior results margin based active learning disagreement based active learning passively learning intersections halfspaces analysis geometric properties concave distributions might independent interest optimization broadly
nearest neighbor sample compression efficiency consistency infinite dimensions examine bayes consistency recently proposed nearest neighbor based multiclass learning algorithm algorithm derived sample compression bounds enjoys statistical advantages tight fully empirical generalization bounds well algorithmic advantages runtime memory savings prove algorithm strongly bayes consistent metric spaces finite doubling dimension first consistency result efficient nearest neighbor sample compression scheme rather surprisingly discover algorithm continues bayes consistent even certain infinite dimensional setting basic measure theoretic conditions classic consistency proofs hinge violated surprising since known bayes consistent setting pose several challenging open problems future research
learning identifiable gaussian bayesian networks polynomial time sample complexity learning directed acyclic graph dag structure bayesian network observational data notoriously difficult problem many non identifiability hardness results known paper propose provably polynomial time algorithm learning sparse gaussian bayesian networks equal noise variance class bayesian networks dag structure uniquely identified observational data high dimensional settings show k4log number samples suffices method recover true dag structure high probability number variables maximum markov blanket size obtain theoretical guarantees condition called emph restricted strong adjacency faithfulness rsaf strictly weaker strong faithfulness condition methods based conditional independence testing need success sample complexity method matches information theoretic limits terms dependence validate theoretical findings synthetic experiments
world graph discovering statistical structure links fundamental problem analysis social networks choosing misspecified model equivalently incorrect inference algorithm result invalid analysis even falsely uncover patterns fact artifacts model work focuses unifying two widely used link formation models stochastic block model sbm small world latent space model swm integrating techniques kernel learning spectral graph theory nonlinear dimensionality reduction develop first statistically sound polynomial time algorithm discover latent patterns sparse graphs models network comes sbm algorithm outputs block structure swm algorithm outputs estimates node latent position
mean field residual networks edge chaos study randomly initialized residual networks using mean field theory theory difference equations classical feedforward neural networks tanh activations exhibit exponential behavior average propagating inputs forward gradients backward exponential forward dynamics causes rapid collapsing input space geometry exponential backward dynamics causes drastic vanishing exploding gradients show contrast converting residual connections activations tanh power relu unit network adopt subexponential forward backward dynamics many cases fact polynomial exponents polynomials obtained analytic methods proved verified empirically correct terms edge chaos hypothesis subexponential polynomial laws allow residual networks tohover boundary stability chaos thus preserving geometry input space gradient information flow also train grid tanh residual networks mnist observe predicted theory developed paper peak performances models determined product standard deviation weights square root depth thus addition improving understanding residual networks theoretical tools guide research toward better initialization schemes
learning uncertain curves wasserstein metric gaussian processes introduce novel framework statistical analysis populations non degenerate gaussian processes gps natural representations uncertain curves allows inherent variation uncertainty function valued data properly incorporated population analysis using wasserstein metric geometrize space gps mean covariance functions compact index spaces prove existence uniqueness barycenter population gps well convergence metric barycenter finite dimensional counterparts justifies practical computations finally demonstrate framework experimental validation datasets representing brain connectivity climate change source code released upon publication
clustering network valued data community detection focuses clustering nodes detecting communities mostly single network problem considerable practical interest received great deal attention research community able cluster within network important emerging needs able cluster multiple networks largely motivated routine collection network data generated potentially different populations networks may may node correspondence node correspondence present cluster summarizing network graphon estimate whereas node correspondence present propose novel solution clustering networks associating computationally feasible feature vector network based trace powers adjacency matrix illustrate methods simulated real data sets theoretical justifications given terms consistency
power truncated svd general high rank matrix estimation problems show given estimate mata close general high rank positive semi definite psd matrix mata spectral norm mata mata simple truncated singular value decomposition mata produces multiplicative approximation mata frobenius norm observation leads many interesting results general high rank matrix estimation problems high rank matrix completion show possible recover general high rank matrix mata relative error frobenius norm partial observations sample complexity independent spectral gap mata high rank matrix denoising design algorithms recovers matrix mata relative error frobenius norm noise perturbed observations without assuming mata exactly low rank low dimensional estimation high dimensional covariance given samples dimension mat0 mata show possible estimate covariance matrix mata relative error frobenius norm improving classical covariance estimation results requires
adagan boosting generative models generative adversarial networks gan effective method training generative models complex data natural images however notoriously hard train suffer problem missing modes model able produce examples certain regions space propose iterative procedure called adagan every step add new component mixture model running gan algorithm weighted sample inspired boosting algorithms many potentially weak individual predictors greedily aggregated form strong composite predictor prove analytically incremental procedure leads convergence true distribution finite number steps step optimal convergence exponential rate otherwise also illustrate experimentally procedure addresses problem missing modes
adagan boosting generative models generative adversarial networks gan effective method training generative models complex data natural images however notoriously hard train suffer problem missing modes model able produce examples certain regions space propose iterative procedure called adagan every step add new component mixture model running gan algorithm weighted sample inspired boosting algorithms many potentially weak individual predictors greedily aggregated form strong composite predictor prove analytically incremental procedure leads convergence true distribution finite number steps step optimal convergence exponential rate otherwise also illustrate experimentally procedure addresses problem missing modes
discovering potential influence via information bottleneck discovering potential influence one variable another variable fundamental scientific practical interest existing correlation measures suitable discovering average influence fail discover potential influences bridge gap postulate set natural axioms expect measure potential influence satisfy show rate information bottleneck hypercontractivity coefficient satisfies proposed axioms iii provide novel estimator estimate hypercontractivity coefficient samples numerical experiments demonstrate proposed estimator discovers potential influence various indicators datasets robust discovering gene interactions gene expression time series data statistically powerful estimators correlation measures binary hypothesis testing canonical potential influences
phase transitions pooled data problem coded distributed computing inverse problems computationally intensive distributed parallel computing often bottlenecked small set slow workers known stragglers paper utilize emerging idea coded computation design novel error correcting code inspired technique solving linear inverse problems specific iterative methods parallelized implementation affected stragglers example applications include inverse problems personalized pagerank sampling graphs provably show coded computation technique reduce mean squared error computational deadline constraint fact ratio mean squared error replication based coded techniques diverges infinity deadline increases experiments personalized pagerank performed real systems real social networks show ratio large 104 unlike coded computation techniques proposed thus far strategy combines outputs workers including stragglers produce accurate estimates computational deadline also ensures accuracy degrades gracefully event number stragglers large paper study pooled data problem identifying labels associated large collection items based sequence pooled tests revealing counts label within pool noiseless setting exact recovery identify exact asymptotic threshold required number tests optimal decoding prove phase transition complete success complete failure addition present novel noisy variation problem provide information theoretic framework characterizing required number tests general noise models results reveal noise make problem considerably difficult strict increases scaling laws even low noise levels
query complexity clustering side information suppose given set elements clustered unknown clusters oracle interactively answer pair wise queries form two elements belong cluster goal recover optimum clustering asking minimum number queries paper initiate rigorous theoretical study basic problem query complexity interactive clustering provide strong information theoretic lower bounds well nearly matching upper bounds clustering problems come similarity matrix used automated process cluster similar points together however obtaining ideal similarity function extremely challenging due ambiguity data representation poor data quality etc one primary reasons makes clustering hard improve accuracy clustering fruitful approach recent years ask domain expert crowd obtain labeled data interactively many heuristics proposed use similarity function come querying strategy however systematic theoretical study main contribution paper show dramatic power side information aka similarity matrix reducing query complexity clustering natural model similarity matrix similarity values drawn independently arbitrary probability distribution underlying pair elements belong cluster otherwise show given similarity matrix query complexity reduces drastically similarity matrix log denotes squared hellinger divergence moreover also information theoretic optimal within logn factor algorithms efficient parameter free work without knowledge depend logarithmically
revisit fuzzy neural network demystifying batch normalization relu generalized hamming network revisit fuzzy neural network cornerstone notion textit generalized hamming distance provides novel theoretically justified approach rectifying understanding traditional neural computing turns many useful neural network methods batch normalization rectified linear units could interpreted new framework rectified generalized hamming network gnn proposed accordingly ghn lends rigiour analysis within fuzzy logics theory also demonstrates superior performances variety learning tasks terms fast learning speed well controlled behaviour simple parameter settings
posterior sampling reinforcement learning worst case regret bounds present algorithm based posterior sampling aka thompson sampling achieves near optimal worst case regret bounds underlying markov decision process mdp communicating finite though unknown diameter main result high probability regret upper bound dsat communicating mdp states actions diameter s5a regret compares total reward achieved algorithm total expected reward optimal infinite horizon undiscounted average reward policy time horizon result improves best previously known upper bound dsat achieved algorithm setting matches dependence established lower bound dsat problem
framework multi rmed andit testing online fdr control propose alternative framework existing setups controlling false alarms multiple tests run time setup arises many practical applications pharmaceutical companies test new treatment options control pills different diseases internet companies test default webpages versus various alternatives time framework proposes replace sequence tests sequence best arm mab instances continuously monitored data scientist interleaving mab tests online false discovery rate fdr algorithm obtain best worlds low sample complexity time online fdr control main contributions propose reasonable definitions null hypothesis mab instances demonstrate one derive always valid sequential value allows continuous monitoring mab test iii show using rejection thresholds online fdr algorithms confidence levels mab algorithms results sample optimality high power low fdr point time run extensive simulations verify claims also report results real data collected new yorker cartoon caption contest
monte carlo tree search best arm identification recent advances bandit tools techniques sequential learning steadily enabling new applications promising resolution range challenging related problems study game tree search problem goal quickly identify optimal move given game tree sequentially sampling stochastic payoffs develop new algorithms trees arbitrary depth operate summarizing deeper levels tree confidence intervals depth one applying best arm identification procedure root prove new sample complexity guarantees refined dependence problem instance show experimentally algorithms outperform existing elimination based algorithms match previous special purpose methods depth two trees
minimal exploration structured stochastic bandits paper introduces addresses wide class stochastic bandit problems function mapping arm corresponding reward exhibits known structural properties existing structures linear lipschitz unimodal combinatorial dueling covered framework derive asymptotic instance specific regret lower bound problems develop ossb algorithm whose regret matches fundamental limit ossb based classical principle optimism face uncertainty thompson sampling rather aims matching minimal exploration rates sub optimal arms characterized derivation regret lower bound illustrate efficiency ossb using numerical experiments case linear bandit problem show ossb outperforms existing algorithms including thompson sampling
regret analysis continuous dueling bandit dueling bandit learning framework feedback information learning process restricted noisy comparison pair actions paper address dueling bandit problem based cost function continuous space propose stochastic mirror descent algorithm show algorithm achieves sqrtt logt regret bound strong convexity smoothness assumptions cost function clarify equivalence regret minimization dueling bandit convex optimization cost function moreover considering lower bound convex optimization turned algorithm achieves optimal convergence rate convex optimization optimal regret dueling bandit except logarithmic factor
elementary symmetric polynomials optimal experimental design revisit classical problem optimal experimental design oed new mathematical model grounded geometric motivation specifically introduce models based elementary symmetric polynomials polynomials capture partial volumes offer graded interpolation widely used optimal optimal design models obtaining special cases analyze properties models derive greedy convex relaxation algorithms computing associated designs analysis establishes approximation guarantees algorithms empirical results substantiate claims demonstrate curious phenomenon concerning greedy algorithm finally byproduct obtain new results theory elementary symmetric polynomials may independent interest
online learning linear dynamical systems present efficient practical algorithm online prediction discrete time linear dynamical systems despite non convex optimization problem using improper learning convex relaxation algorithm comes provable guarantees near optimal regret bounds compared best lds hindsight overparameterizing small logarithmic factor analysis brings together ideas improper learning convex relaxations online regret minimization spectral theory hankel matrices
efficient flexible inference stochastic systems many real world dynamical systems described stochastic differential equations thus parameter inference challenging important problem many disciplines provide grid free flexible algorithm offering parameter state inference stochastic systems compare approch based variational approximations state art methods showing significant advantages runtime accuracy
group sparse additive machine family learning algorithms generated additive models attracted much attention recently flexibility interpretability high dimensional data analysis among learning models grouped variables shown competitive performance prediction variable selection however previous works mainly focus least squares regression problem classification task thus desired design new additive classification model variable selection capability many real world applications focus high dimensional data classification address challenging problem paper investigate classification group sparse additive models reproducing kernel hilbert spaces novel classification method called emph group sparse additive machine groupsam proposed explore utilize structure information among input variables generalization error bound derived proved integrating sample error analysis empirical covering numbers hypothesis error estimate stepping stone technique new bound shows groupsam achieve satisfactory learning rate polynomial decay experimental results synthetic data seven benchmark datasets consistently show effectiveness new approach
bregman divergence stochastic variance reduction saddle point adversarial prediction adversarial machines learner competes adversary gained much recent interest machine learning naturally form saddle point optimization often separable structure sometimes also unmanageably large dimension work show adversarial prediction multivariate losses solved much faster used first reduce problem size exponentially using appropriate sufficient statistics adapt new stochastic variance reduced algorithm balamurugan bach 2016 allow bregman divergence prove linear rate convergence retained show adversarial prediction using divergence achieve speedup example times compared euclidean alternative verify theoretical findings extensive experiments two example applications adversarial prediction lpboosting
online multiclass boosting recent work extended theoretical analysis boosting algorithms multiclass problems online settings however multiclass extension batch setting online extensions consider binary classification fill gap literature defining justifying weak learning condition online multiclass boosting condition leads optimal boosting algorithm requires minimal number weak learners achieve certain accuracy additionally propose adaptive algorithm near optimal enjoys excellent performance real data due adaptive property
universal consistency minimax rates online mondrian forest establish consistency algorithm mondrian forest cite lakshminarayanan2014mondrianforests lakshminarayanan2016mondrianuncertainty randomized classification algorithm implemented online first amend original mondrian forest algorithm proposed cite lakshminarayanan2014mondrianforests considers emph fixed lifetime parameter indeed fact parameter fixed actually hinders statistical consistency original procedure modified mondrian forest algorithm grows trees increasing lifetime parameters uses alternative updating rule allowing work also online fashion second provide theoretical analysis establishing simple conditions consistency theoretical analysis also exhibits surprising fact algorithm achieves minimax rate optimal rate estimation lipschitz regression function strong extension previous results cite arlot2014purf_bias emph arbitrary dimension
mean teachers better role models weight averaged consistency targets improve semi supervised deep learning results recently proposed temporal ensembling achieved state art results several semi supervised learning benchmarks maintains exponential moving average label predictions training example penalizes predictions inconsistent target however targets change per epoch temporal ensembling becomes unwieldy learning large datasets overcome problem propose mean teacher method averages model weights instead label predictions additional benefit mean teacher improves test accuracy enables training fewer labels temporal ensembling mean teacher achieves error rate svhn 250 labels better temporal ensembling 1000 labels
learning complementary labels collecting labeled data costly thus critical bottleneck real world classification tasks mitigate problem consider complementary label specifies class pattern belong collecting complementary labels would less laborious ordinary labels since users carefully choose correct class many candidate classes however complementary labels less informative ordinary labels thus suitable approach needed better learn complementary labels paper show unbiased estimator classification risk obtained complementary labels loss function satisfies particular symmetric condition theoretically prove estimation error bounds proposed method experimentally demonstrate usefulness proposed algorithms
positive unlabeled learning non negative risk estimator emph positive emph unlabeled data binary classifier trained learning state art emph unbiased learning however model flexible empirical risk training data negative suffer serious overfitting paper propose emph non negative risk estimator learning minimized robust overfitting thus able train flexible models given limited data moreover analyze emph bias emph consistency emph mean squared error reduction proposed risk estimator emph estimation error corresponding risk minimizer experiments show proposed risk estimator successfully fixes overfitting problem unbiased counterparts
semisupervised clustering queries locally encodable source coding source coding canonical problem data compression information theory locally encodable source coding compressed bit depends bits input paper show recently popular model semisupervised clustering equivalent locally encodable source coding model task perform multiclass labeling unlabeled elements beginning ask parallel set simple queries oracle provides possibly erroneous binary answers queries queries cannot involve two fixed constant number elements labeling elements clustering must done based noisy query answers goal recover correct labelings minimizing number queries equivalence locally encodable source codes leads find lower bounds number queries required variety scenarios also able show fundamental limitations pairwise cluster queries propose pairwise queries provably performs better
learning errors structured prediction approximate inference work try understand differences exact approximate inference algorithms structured prediction compare estimation approximation error underestimate overestimate models result shows perspective learning errors performances approximate inference could good exact inference error analyses also suggest new margin existing learning algorithms empirical evaluations text classification sequential labelling dependency parsing witness success approximate inference benefit proposed margin
optimal generalizability parametric learning consider parametric learning problem objective learner determined parametric loss function employing empirical risk minimization possibly regularization inferred parameter vector biased toward training samples bias measured cross validation procedure practice data set partitioned training set used training validation set used training left measure sample performance classical cross validation strategy leave one cross validation loocv one sample left validation training done rest samples presented learner process repeated samples loocv rarely used practice due high computational complexity paper first develop computationally efficient approximate loocv aloocv provide theoretical guarantees performance use aloocv provide optimization algorithm finding optimal regularizer empirical risk minimization framework numerical experiments illustrate accuracy efficiency aloocv well proposed framework optimal regularizer
multi objective non parametric sequential prediction online learning research mainly focusing minimizing one objective function many real world applications however several objective functions considered simultaneously recently algorithm dealing several objective functions case presented paper extend multi objective framework case stationary ergodic processes thus allowing dependencies among observations first identify asymptomatic lower bound prediction strategy present algorithm whose predictions achieve optimal solution fulfilling continuous convex constraining criterion
fixed rank approximation positive semidefinite matrix streaming data several important applications streaming pca semidefinite programming involve large scale positive semidefinite psd matrix presented sequence linear updates storage limitations may possible retain sketch psd matrix paper develops new algorithm fixed rank psd approximation sketch approach combines nystr approximation novel mechanism rank truncation theoretical analysis establishes proposed method achieve prescribed relative error schatten norm exploits spectral decay input matrix computer experiments show proposed method dominates alternative techniques fixed rank psd matrix approximation across wide range examples
communication efficient stochastic gradient descent applications neural networks parallel implementations stochastic gradient descent sgd received significant research attention thanks excellent scalability properties fundamental barrier parallelizing sgd high bandwidth cost communicating gradient updates nodes consequently several lossy compresion heuristics proposed nodes communicate quantized gradients although effective practice heuristics always guarantee convergence clear whether improved paper propose quantized sgd qsgd family compression schemes gradient updates provides convergence guarantees qsgd allows user smoothly trade emph communication bandwidth emph convergence time nodes adjust number bits sent per iteration cost possibly higher variance show trade inherent sense improving past threshold would violate information theoretic lower bounds qsgd guarantees convergence convex non convex objectives asynchrony extended stochastic variance reduced techniques applied training deep neural networks image classification automated speech recognition qsgd leads significant reductions end end training time example 16gpus train resnet152 network full accuracy imagenet faster full precision variant
machine learning adversaries byzantine tolerant gradient descent study resilience byzantine failures distributed implementations stochastic gradient descent sgd far distributed machine learning frameworks largely ignored possibility failures especially arbitrary byzantine ones causes failures include software bugs network asynchrony biases local datasets well attackers trying compromise entire system assuming set workers byzantine ask resilient sgd without limiting dimension size parameter space first show gradient aggregation rule based linear combination vectors proposed workers current approaches tolerates single byzantine failure formulate resilience property aggregation rule capturing basic requirements guarantee convergence despite byzantine workers propose emph krum aggregation rule satisfies resilience property argue first provably byzantine resilient algorithm distributed sgd also report experimental evaluations krum
ranking data continuous labels oriented recursive partitions formulate supervised learning problem referred continuous ranking continuous real valued label assigned observable taking values feature space goal order possible observations means scoring function tend increase decrease together highest probability problem generalizes multi partite ranking certain extent task finding optimal scoring functions naturally cast optimization dedicated functional cri terion called iroc curve maximization kendall related pair theoretical side describe optimal elements problem provide statistical guarantees empirical kendall maximiza tion appropriate conditions class scoring function candidates also propose recursive statistical learning algorithm tailored empirical iroc curve optimization producing piecewise constant scoring function fully described oriented binary tree preliminary numerical experiments highlight difference nature regression continuous ranking provide strong empirical evidence performance empirical optimizers criteria proposed
practical data dependent metric compression provable guarantees introduce new distance preserving compact representation multi dimensional point sets given points dimensional space coordinate represented using bits bits per point produces representation size log epsilon log bits per point one approximate distances factor epsilon algorithm almost matches recent bound indyk 2017 much simpler compare algorithm product quantization jegou 2011 state art heuristic metric compression method evaluate algorithms several data sets sift mnist new york city taxi time series synthetic one dimensional data set embedded high dimensional space algorithm produces representations comparable better produced provable guarantees performance
simple strategies recovering inner products coarsely quantized random projections random projections increasingly adopted diverse set tasks machine learning involving dimensionality reduction one specific line research topic investigated use quantization subsequent projection aim additional data compression motivated applications nearest neighbor search linear learning revisit problem recovering inner products respectively cosine similarities setting show even coarse scalar quantization bits per projection loss accuracy tends range negligible tomoderate one implication scenarios practical interest need sophisticated recovery approach like maximum likelihood estimation considered previous work subject propose herein also yields considerable improvements terms accuracy hamming distance based approach icml 2014 comparable terms simplicity
clustering stable instances euclidean means euclidean means problem arguably widely studied clustering problem machine learning means objective hard worst case practitioners enjoyed remarkable success applying heuristics like lloyd algorithm problem address disconnect study following question properties real world instances enable design efficient algorithms prove guarantees finding optimal clustering consider natural notion called additive perturbation stability believe captures many practical instances euclidean means clustering stable instances unique optimal means solutions change even point perturbed little euclidean distance captures property means optimal solution tolerant measurement errors uncertainty points design efficient algorithms provably recover optimal clustering instances additive perturbation stable instance additional separation design simple efficient algorithm provable guarantees also robust outliers also complement results studying amount stability real datasets demonstrating algorithm performs well benchmark datasets
distributed hierarchical clustering graph clustering fundamental task many data mining machine learning pipelines particular identifying good hierarchical structure time fundamental challenging problem several applications amount data analyze increasing astonishing rate day hence need new solutions efficiently compute effective hierarchical clusterings huge data main focus paper minimum spanning tree mst based clusterings particular propose affinity novel hierarchical clustering based boruvka mst algorithm prove certain theoretical guarantees affinity well classic algorithms show practice superior several state art clustering algorithms furthermore present two mapreduce algorithms affinity first one works case input graph dense takes constant rounds based mst algorithm dense graphs improves upon prior work karloff second algorithm assumption density input graph finds affinity clustering log rounds using distributed hash tables dhts show experimentally algorithms scalable huge data sets
sparse means embedding means clustering algorithm ubiquitous tool data mining machine learning shows promising performance however high computational cost hindered applications broad domains researchers successfully addressed obstacles dimensionality reduction methods recently cite dblp journals tit boutsidiszmd15 develop state art random projection method faster means clustering method delivers many improvements dimensionality reduction methods example compared advanced singular value decomposition based feature extraction approach cite dblp journals tit boutsidiszmd15 reduce running time factor min 2log data matrix data points features losing factor one approximation accuracy unfortunately still require ndk 2log matrix multiplication cost prohibitive large values break bottleneck carefully build sparse embedded means clustering algorithm requires nnz nnz denotes number non zeros fast matrix multiplication moreover proposed algorithm improves cite dblp journals tit boutsidiszmd15 results approximation accuracy factor one empirical studies corroborate theoretical findings demonstrate approach able significantly accelerate means clustering achieving satisfactory clustering performance
medoids means seeding show experimentally algorithm clarans han 1994 finds better medoids solutions voronoi iteration algorithm hastie 2001 finding along similarity voronoi iteration algorithm lloyd means algorithm motivates use clarans means initializer show clarans outperforms algorithms datasets mean decrease means initialization mean squared error mse final mse introduce algorithmic improvements clarans improve complexity runtime making extremely viable initialization scheme large datasets
applied algorithmic foundation hierarchical clustering hierarchical clustering data analysis method used decades despite widespread use lack analytical foundation method foundation would support methods currently used guide future improvements paper gives applied algorithmic foundation hierarchical clustering goal paper give analytic framework supporting observations seen practice paper considers dual problem framework hierarchical clustering introduced dasgupta main results one popular algorithms used practice average linkage agglomerative clustering small constant approximation ratio paper establishes using recursive means divisive clustering poor lower bound approximation ratio perhaps explaining popular practice motivated poor performance means seek find divisive algorithms perform well theoretically paper gives two constant approximation algorithms paper represents first work giving foundation hierarchical clustering algorithms used practice
inhomogoenous hypergraph clustering applications hypergraph partitioning important problem machine learning computer vision network analytics widely used method hypergraph partitioning relies minimizing normalized sum costs partitioning hyperedges across clusters algorithmic solutions based approach assume different partitions hyperedge incur cost however assumption fails leverage fact different subsets vertices within hyperedge may different structural importance hence propose new hypergraph clustering technique termed inhomogeneous hypergraph partitioning assigns different costs different hyperedge cuts prove inhomogeneous partitioning produces quadratic approximation optimal solution inhomogeneous costs satisfy submodularity constraints moreover demonstrate inhomogenous partitioning offers significant performance improvements applications structure learning rankings subspace segmentation motif clustering
subspace clustering via tangent cones given samples lying near number fixed subspaces subspace clustering task grouping samples based corresponding subspaces many subspace clustering methods operate assigning affinity pair points feeding affinities common clustering algorithm paper proposes new paradigm subspace clustering computes affinities based underlying conic geometry union subspaces proposed conic subspace clustering csc approach considers convex hull collection normalized data points tangent cones sample union subspaces underlying data imposes strong association tangent cone point original subspace containing addition describing novel geometric perspective paper provides practical algorithm subspace clustering leverages perspective tangent cone membership test estimate affinities algorithm accompanied deterministic stochastic guarantees properties learned affinity matrix directly translate overall clustering accuracy
tensor biclustering consider dataset data collected multiple features multiple individuals multiple times type data represented three dimensional individual feature time tensor become increasingly prominent various areas science tensor biclustering problem computes subset individuals subset features whose signal trajectories time lie low dimensional subspace modeling similarity among signal trajectories allowing different scalings across different individuals different features study information theoretic limit problem generative model moreover propose efficient spectral algorithm solve tensor biclustering problem analyze achievability bound asymptotic regime finally show efficiency proposed method several synthetic real datasets
unified approach interpreting model predictions understanding model made certain prediction crucial many applications however large modern datasets best accuracy often achieved complex models even experts struggle interpret ensemble deep learning models creates tension accuracy interpretability response variety methods recently proposed help users interpret predictions complex models present unified framework interpreting predictions namely shap shapley additive explanations assigns feature importance particular prediction key components shap framework identification class additive feature importance measures theoretical results unique solution class set desired properties class unifies six existing methods several recent methods class desired properties means framework inform development new methods explaining prediction models demonstrate several new methods presented paper based shap framework show better computational performance better consistency human intuition existing methods
efficient sublinear regret algorithms online sparse linear regression online sparse linear regression task applying linear regression analysis examples arriving sequentially subject resource constraint limited number features examples observed despite importance many practical applications recently shown polynomial time sublinear regret algorithm unless bpp exponential time sublinear regret algorithm known paper introduce mild assumptions solve problem assumptions present polynomial time sublinear regret algorithms online sparse linear regression addition thorough experiments publically available data demonstrate algorithms outperform known algorithms
unbiased estimates linear regression via volume sampling given full rank matrix columns rows consider task estimating pseudo inverse based pseudo inverse sampled subset columns size least number rows show possible subset columns chosen proportional squared volume spanned rows chosen submatrix volume sampling resulting estimator unbiased surprisingly covariance estimator also closed form equals specific factor times pseudo inverse plays important part solving linear least squares problem try predict label column assume labels expensive given labels small subset columns sample using methods show weight vector solution sub problem unbiased estimator optimal solution whole problem based column labels believe new formulas establish fundamental connection linear least squares volume sampling use methods obtain algorithm volume sampling faster state art obtaining bounds total loss estimated least squares solution labeled columns
separability loss functions revisiting discriminative generative models revisit classical analysis generative discriminative models general exponential families high dimensional settings towards develop novel technical machinery including notion separability general loss functions allow provide general framework obtain convergence rates general estimators use machinery analyze convergence rates generative discriminative models provide insights nuanced behaviors high dimensions results also applicable differential parameter estimation quantity interest difference generative model parameters
generalized linear model regression distance set penalties estimation generalized linear models glm complicated presence constraints one handle constraints maximizing penalized log likelihood penalties lasso effective high dimensions often lead severe shrinkage paper explores instead penalizing squared distance constraint sets distance penalties flexible algebraic regularization penalties avoid drawback shrinkage optimize distance penalized objectives make use majorization minimization principle resulting algorithms constructed within framework amenable acceleration come global convergence guarantees applications shape constraints sparse regression rank restricted matrix regression synthetic real data showcase strong empirical performance distance penalization even non convex constraints
group additive structure identification kernel nonparametric regression additive model one popularly used models high dimensional nonparametric regression analysis however main drawback neglects possible interactions predictor variables paper reexamine group additive model proposed literature rigorously define intrinsic group additive structure relationship response variable
predictor vector vectx develop effective structure penalized kernel method simultaneous identification intrinsic group additive structure nonparametric function estimation method utilizes novel complexity measure derive group additive structures show proposed method consistent identifying intrinsic group additive structure simulation study real data applications demonstrate effectiveness proposed method general tool high dimensional nonparametric regression
learning overcomplete hmms study basic problem learning overcomplete hmms many hidden states small output alphabet despite significant practical importance hmms poorly understood known positive negative results efficient learning paper present several new results positive negative help define boundaries tractable learning setting intractable setting show positive results large subclass hmms whose transition matrices sparse well conditioned small probability mass short cycles also show learning impossible given polynomial number samples hmms small output alphabet whose transition matrices random regular graphs large degree
matrix norm estimation entries singular values data matrix form provide insights structure data effective dimensionality choice hyper parameters higher level data analysis tools however many practical applications collaborative filtering network analysis get partial observation scenarios consider fundamental problem recovering various spectral properties underlying matrix sampling entries propose framework first estimating schatten norms matrix several values using surrogates estimating spectral properties interest spectrum rank paper focuses technical challenges accurately estimating schatten norms sampling matrix introduce novel unbiased estimator based counting small structures graph provide guarantees match empirical performances theoretical analysis shows schatten norms recovered accurately strictly smaller number samples compared needed recover underlying low rank matrix numerical experiments suggest significantly improve upon competing approach using matrix completion methods
optimal shrinkage singular values random data contamination low rank matrix contaminated uniformly distributed noise missing values outliers corrupt entries reconstruction singular values singular vectors contaminated matrix key problem machine learning computer vision data science paper show common contamination models including arbitrary combinations uniform noise missing values outliers corrupt entries described efficiently using single framework develop asymptotically optimal algorithm estimates manipulation singular values applies contamination models considered finally find explicit signal noise cutoff estimation singular value decomposition must fail well defined sense
new theory nonconvex matrix completion prevalent matrix completion theories reply assumption locations missing data distributed uniformly randomly uniform sampling nevertheless reason observations missing often depends unseen observations thus missing data practice usually occurs nonuniform fashion rather randomly break limits randomness assumption paper introduces new hypothesis called isomeric condition provably weaker randomness assumption arguably holds even missing data placed irregularly equipped new tool prove series theorems missing data recovery matrix completion particular prove exact solutions identify target matrix included critical points commonly used nonconvex programs unlike existing nonconvex theories use condition convex programs theories show nonconvex programs work much weaker condition comparing existing theories nonuniform sampling theories flexible powerful
learning low dimensional metrics paper investigates theoretical foundations metric learning focused three key questions fully addressed prior work consider learning general low dimensional low rank metrics well sparse metrics develop upper lower minimax bounds generalization error quantify sample complexity metric learning terms dimension feature space dimension rank underlying metric also bound accuracy learned metric relative underlying true generative metric results involve novel mathematical approaches metric learning problem also shed new light special case ordinal embedding aka non metric multidimensional scaling
fast alternating minimization algorithms dictionary learning present theoretical guarantees alternating minimization algorithm dictionary learning sparse coding problem dictionary learning problem factorize samples appropriate basis dictionary times sparse vector algorithm simple alternating minimization procedure switching gradient descent minimization every step dictionary learning specifically alternating minimization algorithms dictionary learning well studied theoretically empirically however contrast previous theoretical analysis problem replace condition operator norm true underlying dictionary condition matrix infinity norm allows get convergence rates terms error estimated dictionary infinity norm also allows initialize randomly converge globally optimum guarantees reasonable generative model allow dictionaries growing operator norms handle arbitrary level overcompleteness sparsity information theoretically optimal incoherent dictionaries also present statistical guarantees present sample complexity guarantees algorithm
consistent robust regression present first efficient provably consistent estimator robust regression problem area robust learning optimization generated significant amount interest learning statistics communities recent years owing applicability scenarios corrupted data well handling model mis specifications particular special interest devoted fundamental problem robust linear regression estimators tolerate corruption constant fraction response variables widely studied surprisingly however date aware polynomial time estimator offers consistent estimate presence dense unbounded corruptions work present estimator called crr solves open problem put forward work bhatia 2015 consistency analysis requires novel two stage proof technique involving careful analysis stability ordered lists may independent interest show crr offers consistent estimates empirically far superior several recently proposed algorithms robust regression problem including extended lasso torrent algorithm comparison crr offers comparable better model recovery runtimes faster order magnitude
partial hard thresholding towards unified analysis support recovery machine learning compressed sensing central importance understand tractable algorithm recovers support sparse signal compressed measurements paper present towards principled analysis support recovery performance family hard thresholding algorithms end appeal partial hard thresholding pht operator proposed recently jain ieee trans information theory 2017 show proper conditions pht recovers arbitrary sparse signal within log iterations condition number specializing pht operator obtain best known result hard thresholding pursuit orthogonal matching pursuit replacement experiments simulated data complement theoretical findings also illustrate interesting phase transition iteration number cannot significantly reduced
minimax estimation bandable precision matrices inverse covariance matrix provides considerable insight understanding statistical models multivariate setting particular distribution variables assumed multivariate normal sparsity pattern inverse covariance matrix commonly referred precision matrix corresponds adjacency matrix representation gauss markov graph encodes conditional independence statements variables minimax results spectral norm previously established covariance matrices sparse banded sparse precision matrices establish minimax estimation bounds estimating banded precision matrices spectral norm results greatly improve upon existing bounds particular find minimax rate estimating banded precision matrices matches estimating banded covariance matrices key insight analysis able obtain barely noisy estimates times subblocks precision matrix inverting slightly wider blocks empirical covariance matrix along diagonal theoretical results complemented experiments demonstrating sharpness bounds
diffusion approximations online principal component estimation global convergence paper propose adopt diffusion approximation tools study dynamics oja iteration online stochastic gradient method principal component analysis oja iteration maintains running estimate true principal component streaming data enjoys less temporal spatial complexities show oja iteration top eigenvector generates continuous state discrete time markov chain unit sphere characterize oja iteration three phases using diffusion approximation weak convergence tools three phase analysis provides finite sample error bound running estimate matches minimax information lower bound pca bounded noise
estimation covariance structure heavy tailed distributions propose analyze new estimator covariance matrix admits strong theoretical guarantees weak assumptions underlying distribution existence moments low order estimation covariance matrices corresponding sub gaussian distributions well understood much less known case heavy tailed data balasubramanian yuan write data real world experiments oftentimes tend corrupted outliers exhibit heavy tails cases clear covariance matrix estimators remain optimal possible strategies deal heavy tailed distributions warrant studies make step towards answering question prove tight deviation inequalities proposed estimator depend parameters controlling intrinsic dimension associated covariance matrix opposed dimension ambient space particular results applicable case high dimensional observations
learning koopman invariant subspaces dynamic mode decomposition spectral decomposition koopman operator attracting attention tool analysis nonlinear dynamical systems dynamic mode decomposition popular numerical algorithm koopman spectral analysis however often need prepare nonlinear observables manually according underlying dynamics always possible since may priori knowledge paper propose fully data driven method koopman spectral analysis based principle learning koopman invariant subspaces observed data end propose minimization residual sum squares linear least squares regression estimate set functions transforms data form linear regression fits well introduce implementation neural networks evaluate performance empirically using nonlinear dynamical systems applications
tochastic approximation canonical correlation analysis propose novel first order stochastic approximation algorithms canonical correlation analysis cca algorithms presented instances noisy matrix stochastic gradient msg noisy matrix exponential gradient meg achieve suboptimality population objective time poly probability least input dimensionality also consider practical variants proposed algorithms compare methods cca theoretically empirically
diving shallows computational perspective large scale shallow learning remarkable recent success deep neural networks easy analyze theoretically particularly hard disentangle relative significance architecture optimization achieving accurate classification large datasets flip side shallow methods kernel methods encountered obstacles scaling large data practical methods variants gradient descent used successfully deep learning seem perform par applied kernel methods difficulty sometimes attributed limitations shallow architecture paper first identify basic limitation gradient descent based optimization methods used conjunctions smooth kernels analysis demonstrates vanishingly small fraction function space reachable polynomial number gradient descent iterations drastically limits approximating power gradient descent fixed computational budget leading serious regularization issue purely algorithmic persisting even limit infinite data address shortcoming practice introduce eigenpro iteration based simple direct preconditioning scheme using small number approximate eigenvectors also viewed learning new kernel optimized gradient descent turns injecting small amount approximate second order information leads major improvements convergence large data translates significant performance boost state art kernel methods particular able match improve results recently reported literature small fraction computational budget finally feel results show need broader computational perspective modern large scale learning complement traditional statistical convergence analyses
unreasonable effectiveness structured random orthogonal embeddings examine class embeddings based structured random matrices orthogonal rows applied many machine learning applications including dimensionality reduction kernel approximation johnson lindenstrauss transform angular kernel show select matrices yielding guaranteed improved performance accuracy speed compared earlier methods introduce matrices complex entries give significant accuracy improvement provide geometric markov chain based perspectives help understand benefits empirical results suggest approach helpful wider range applications
generalization properties learning random features study generalization properties ridge regression random features statistical learning framework show first time learning bounds achieved
nlog random features rather suggested previous results prove faster learning rates show might require random features unless sampled according possibly problem dependent distribution results shed light statistical computational trade offs large scale kernelized learning showing potential effectiveness random features reducing computational complexity keeping optimal generalization properties
gaussian quadrature kernel features kernel methods recently attracted resurgent interest matching performance deep neural networks tasks speech recognition random fourier features map technique commonly used scale kernel machines employing randomized feature map means samples required achieve approximation error paper investigate alternative schemes constructing feature maps deterministic rather random approximating kernel frequency domain using gaussian quadrature show deterministic feature maps constructed achieve error samples goes validate methods datasets different domains mnist timit showing deterministic features faster generate achieve comparable accuracy state art kernel methods based random fourier features
linear time kernel goodness fit test propose novel adaptive test goodness fit computational cost linear number samples learn test features best indicate differences observed samples reference model minimizing false negative rate features constructed via stein method meaning necessary compute normalising constant model analyse asymptotic bahadur efficiency new test prove mean shift alternative test always greater relative efficiency previous linear time kernel test regardless choice parameters test experiments performance method exceeds earlier linear time test matches exceeds power quadratic time kernel test high dimensions model structure may exploited goodness fit test performs far better quadratic time two sample test based maximum mean discrepancy samples drawn model
convergence rates partition based bayesian multivariate density estimation method study class non parametric density estimators bayesian settings estimators obtained adaptively partitioning sample space suitable prior analyze concentration rate posterior distribution demonstrate rate directly depend dimension problem several special cases another advantage class bayesian density estimators adapt unknown smoothness true density function thus achieving optimal conv
power absolute discounting dimensional distribution estimation categorical models natural fit many problems learning distribution categories samples high dimensionality may dilute data minimax optimality pessimistic remedy issue serendipitously discovered estimator absolute discounting corrects empirical frequencies subtracting constant observed categories redistributes among unobserved outperforms classical estimators empirically used extensively natural language modeling paper rigorously explain prowess estimator using less pessimistic notions show absolute discounting recovers classical minimax risk rates emph adaptive effective dimension rather true dimension strongly related good turing estimator inherits emph competitive properties use power law distributions corner stone results validate theory via synthetic data application global terrorism database
optimally learning populations parameters consider following fundamental estimation problem entities unknown parameter observe independent random variables binomial accurately one recover histogram cumulative density function empirical estimates would recover histogram earth mover distance equivalently distance cdfs show provided sufficiently large achieve error information theoretically optimal also extend results multi dimensional parameter case capturing settings member population multiple associated parameters beyond theoretical results demonstrate recovery algorithm performs well practice variety datasets providing illuminating insights several domains including politics sports analytics
communication efficient distributed learning discrete distributions initiate systematic study distribution learning density estimation distributed model problem data drawn unknown distribution partitioned across multiple machines machines must succinctly communicate referee end referee estimate underlying distribution data problem motivated pressing need build communication efficient protocols various distributed systems power consumption limited bandwidth impose stringent communication constraints give first upper lower bounds communication complexity nonparametric density estimation discrete probability distributions distances specifically results include following case unknown distribution arbitrary machine one sample show interactive protocol learns distribution must essentially communicate entire sample case structured distributions
histograms monotone design distributed protocols achieve better communication guarantees trivial ones show tight bounds regimes
improved dynamic regret non degeneracy functions recently growing research interest analysis dynamic regret measures performance online learner sequence local minimizers exploiting strong convexity previous studies shown dynamic regret upper bounded path length comparator sequence paper illustrate dynamic regret improved allowing learner query gradient function multiple times meanwhile strong convexity weakened non degeneracy conditions specifically introduce squared path length could much smaller path length new regularity comparator sequence multiple gradients accessible learner first demonstrate dynamic regret strongly convex functions upper bounded minimum path length squared path length extend theoretical guarantee functions semi strongly convex self concordant best knowledge first time semi strong convexity self concordance utilized tighten dynamic regret
parameter free online learning via model selection introduce new framework deriving efficient algorithms obtain model selection oracle inequalities adversarial online learning setting also sometimes described parameter free online learning work area focused specific highly structured function classes nested balls hilbert space eschew approach propose generic meta algorithm framework achieves oracle inequalities minimal structural assumptions allows derive new computationally efficient algorithms oracle bounds wide range settings results previously unavailable give first computationally efficient algorithms work arbitrary banach spaces mild smoothness assumptions previous results applied hilbert case derive new oracle inequalities various matrix classes non nested convex sets generic regularizers finally generalize providing oracle inequalities arbitrary non linear classes contextual learning model particular give new algorithms learning multiple kernels results derived unified meta algorithm scheme based novel multi scale algorithm prediction expert advice based random playout may independent interest
fast rates bandit optimization upper confidence frank wolfe consider problem bandit optimization inspired stochastic optimization online learning problems bandit feedback problem objective minimize global loss function actions necessarily cumulative loss framework allows study general class problems applications statistics machine learning fields solve problem analyze upper confidence frank wolfe algorithm inspired techniques bandits convex optimization give theoretical guarantees performance algorithm various classes functions discuss optimality results
online learning transductive regret study online learning general notion transductive regret regret modification rules applying expert sequences opposed single experts representable weighted finite state transducers show transductive regret generalizes existing notions regret including external regret internal regret swap regret conditional swap regret present general online learning algorithm minimizing transductive regret extend work design efficient algorithms time selection sleeping expert settings product study algorithm swap regret mild assumptions efficient existing methods
multi armed bandits metric movement costs consider non stochastic multi armed bandit problem setting fixed known metric action space determines cost switching pair actions loss online learner two components first usual loss selected actions second additional loss due switching actions main contribution gives tight characterization expected minimax regret setting terms complexity measure underlying metric depends covering numbers finite metric spaces max setc1 3t2 show best possible regret bound generalizes previous known regret bounds special cases unit switching cost regret max setk1 3t2 interval metric regret max sett2 infinite metrics spaces lipschitz loss functions derive tight regret bound minkowski dimension space known tight even switching costs
differentially private empirical risk minimization revisited faster general paper study differentially private empirical risk minimization erm different settings smooth strongly convex loss function without non smooth regularization give algorithms achieve either optimal near optimal utility bound less gradient complexity compared previous work erm smooth convex loss function high dimension setting give algorithm achieves upper bound less gradient complexity previous ones last generalize expected excess empirical risk convex polyak lojasiewicz condition give tighter upper bound utility comparing result cite dblp journals corr zhangzmw17
certified defenses data poisoning attacks machine learning systems trained user provided data susceptible data poisoning attacks whereby malicious users inject data aim corrupting learned model recent work proposed number attacks defenses little understood worst case performance defense face determined attacker remedy constructing upper bounds loss across broad family attacks defenders operate via outlier removal followed empirical risk minimization bound comes paired candidate attack nearly realizes upper bound giving powerful tool quickly assessing defense given dataset empirically find even simple defense mnist dogfish datasets certifiably resilient attack contrast imdb sentiment dataset driven test error adding poisoned data
sparse approximate conic hulls consider problem computing restricted nonnegative matrix factorization nmf matrix specifically seek factorization columns subset equivalently given matrix consider problem finding small subset columns conic hull eps approximates conic hull columns distance every column conic hull columns eps fraction angular diameter size smallest eps approximation produce eps2 sized eps1 approximation yielding first provable polynomial time eps approximation class nmf problems also desirably approximation independent furthermore prove approximate conic caratheodory theorem general sparsity result shows column eps approximated eps2 sparse combination results facilitated reduction problem approximating convex hulls prove convex conic hull variants sum hard resolving open problem finally provide experimental results convex conic algorithms variety feature selection tasks
estimating high dimensional non gaussian multiple index models via stein lemma consider estimating parametric components semi parametric multiple index models high dimensional non gaussian setting estimators leverage score function based second order stein lemma require gaussian elliptical symmetry assumptions made literature show estimator achieves near optimal statistical rate convergence even score function response variable heavy tailed utilize data driven truncation argument based required concentration results established supplement theoretical results via simulation experiments confirm theory
solid harmonic wavelet scattering predicting quantum molecular energy invariant descriptors electronic densities introduce solid harmonic wavelet scattering representation invariant rigid movements stable deformations regression classification images solid harmonic wavelets computed multiplying solid harmonic functions gaussian windows dilated different scales invariant scattering coefficients obtained cascading wavelet transforms complex modulus nonlinearity study application solid harmonic scattering invariants estimation quantum molecular energies also invariant rigid movements stable respect deformations introduce neural network multiplicative non linearity regression scattering invariants provide close state art results database organic molecules
clustering billions reads dna data storage storing data synthetic dna offers possibility improving information density durability several orders magnitude compared current storage technologies however dna data storage requires computationally intensive process retrieve data particular crucial step data retrieval pipeline involves clustering billions strings respect edit distance observe datasets domain many notable properties containing large number small clusters well separated edit distance metric space regime existing algorithms unsuitable either long running time low accuracy address issue present novel distributed algorithm approximately computing underlying clusters algorithm converges efficiently dataset satisfies certain separability properties coming dna storage systems also prove assumptions algorithm robust outliers high levels noise provide empirical justification accuracy scalability convergence algorithm real synthetic data compared state art algorithm clustering dna sequences algorithm simultaneously achieves higher accuracy 1000x speedup three real datasets
deep recurrent neural network based identification precursor micrornas micrornas mirnas small non coding ribonucleic acids rnas play key roles post transcriptional gene regulation direct identification mature mirnas infeasible due short lengths researchers instead aim identifying precursor mirnas pre mirnas many known pre mirnas distinctive stem loop secondary structure structure based filtering usually first step predict possibility given sequence pre mirna identify new pre mirnas often non canonical structure however need consider additional features structure obtain additional characteristics existing computational methods rely manual feature extraction inevitably limits efficiency robustness generalization computational identification address limitations existing approaches propose pre mirna identification method incorporates deep recurrent neural network rnn automated feature learning classification multimodal architecture seamless integration prior knowledge secondary structure attention mechanism improving long term dependence modeling rnn based class activation mapping highlighting learned representations contrast pre mirnas non pre mirnas experiments recent benchmarks proposed approach outperformed compared state art alternatives terms various performance metrics
decoding value networks neural machine translation neural machine translation nmt become popular technology recent years beam search facto decoding method due shrunk search space reduced computational complexity one issue beam search since searches local optima time step one step forward looking usually cannot output best target sentence inspired success methodology alphago paper propose using prediction network improve beam search takes source sentence currently available decoding output candidate word step inputs predicts long term value bleu score partial target sentence completed nmt model following practice reinforcement learning call prediction network emph value network specifically propose recurrent structure value network train parameters bilingual data test time choosing word decoding consider conditional probability given nmt model long term value predicted value network experiments show approach significantly improve translation accuracy two translation tasks english french translation chinese english translation
towards imagenet cnn nlp pretraining sentence encoders machine translation computer vision benefited initializing multiple deep layers weights pre trained large supervised training sets like imagenet contrast deep models language tasks currently benefit transfer unsupervised word vectors randomly initialize higher layers paper use encoder attentional sequence sequence model trained machine translation initialize models different language tasks show transfer improves performance using word vectors wide variety common nlp tasks sentiment analysis sst imdb question classification entailment snli question answering squad
deep voice multi speaker neural text speech introduce technique augmenting neural text speech tts low dimensional trainable speaker embeddings generate different voices single model starting point show improvements two state art approaches single speaker neural tts deep voice tacotron introduce deep voice based similar pipeline deep voice constructed higher performance building blocks demonstrates significant audio quality improvement deep voice improve tacotron introducing post processing neural vocoder demonstrate significant audio quality improvement demonstrate technique multi speaker speech synthesis deep voice tacotron two multi speaker tts datasets show single neural tts system learn hundreds unique voices less half hour data per speaker achieving high audio quality synthesis preserving speaker identities almost perfectly
modulating early visual processing language commonly assumed language refers high level visual concepts leaving low level visual processing unaffected view dominates current literature computational models language vision tasks visual linguistic input mostly processed independently fused single representation paper deviate classic pipeline propose modulate emph entire visual processing linguistic input specifically condition batch normalization parameters pretrained residual network language embedding approach call modulated residual networks mrn significantly improves strong baselines two visual question answering tasks ablation study shows modulating early stages visual processing beneficial
multimodal learning reasoning visual question answering reasoning entities relationships multimodal data key goal artificial general intelligence visual question answering vqa problem excellent way test reasoning capabilities model multimodal representation learning however current vqa models oversimplified deep neural networks comprised long short term memory lstm unit question comprehension convolutional neural network cnn learning single image representation argue single visual representation contains limited general information image contents thus limit model reasoning capabilities work introduce modular neural network model learns multimodal multifaceted representation image question proposed model learns use multimodal representation reason image entities achieves new state art performance vqa benchmark datasets vqa wide margin
learning model tail describe approach learning long tailed imbalanced datasets prevalent real world settings challenge learn accurate shot models classes tail little data available cast problem one transfer learning knowledge data rich classes head transferred data poor classes tail key insights follows first propose transfer meta knowledge learning learn head knowledge encoded meta network operates space model parameters trained predict many shot model parameters shot model parameters second transfer meta knowledge progressive manner classes head thebody body tail transfer knowledge gradual fashion regularizing meta networks shot regression trained training data allows final network capture dynamics transferring meta knowledge data rich data poor regime demonstrate results image classification datasets sun places imagenet tuned long tailed setting significantly outperform widespread heuristics data resampling reweighting
interpretable globally optimal prediction textual grounding using image concepts textual grounding important challenging task human computer interaction robotics knowledge mining existing algorithms generally formulate task selection solution set bounding box proposals obtained deep net based systems work demonstrate cast problem textual grounding unified framework permits efficient search possible bounding boxes hence able consider significantly proposals due unified formulation approach rely successful first stage beyond demonstrate trained parameters model used word embeddings capture spatial image relationships provide interpretability lastly approach outperforms current state art methods flickr 30k entities referitgame dataset respectively
multiscale quantization fast similarity search propose multiscale quantization approach fast similarity search large high dimensional datasets key insight approach quantization methods particular product quantization perform poorly variance norm data points common scenario real world datasets especially product quantization residuals obtained coarse vector quantization address issue propose multiscale formulation learn separate scalar quantizer residual norms parameters learned jointly stochastic gradient descent framework minimize overall quantization error provide theoretical motivation proposed technique conduct comprehensive experiments two large scale public datasets demonstrating substantial improvements recall existing state art methods
maskrnn instance level video object segmentation instance level video object segmentation important technique video editing compression capture temporal coherence paper develop maskrnn recurrent neural net approach fuses frame output two deep nets object instance binary segmentation net providing mask localization net providing bounding box due recurrent component localization component method able take advantage long term temporal structures video data well rejecting outliers validate proposed algorithm three challenging benchmark datasets davis 2016 dataset davis 2017 dataset segtrack dataset achieving state art performance
flat2sphere learning spherical convolution fast features 360 imagery 360 cameras offer tremendous new possibilities vision graphics augmented reality spherical images produce make core feature extraction non trivial convolutional neural networks cnns trained images perspective cameras yield flat filters yet 360 images cannot projected single plane without significant distortion naive solution repeatedly projects viewing sphere tangent planes accurate much computationally intensive real problems propose learn spherical convolutional network translates planar cnn process 360 imagery directly equirectangular projection approach learns reproduce flat filter outputs 360 data sensitive varying distortion effects across viewing sphere key benefits efficient feature extraction 360 images video ability leverage powerful pre trained networks researchers carefully honed together massive labeled image training sets perspective images validate approach compared several alternative methods terms raw cnn output accuracy well applying state art flat object detector 360 data method yields accurate results saving orders magnitude computation versus existing exact reprojection solution
deep mean shift priors image restoration paper introduce natural image prior directly represents gaussian smoothed version natural image distribution include prior formulation image restoration bayes estimator also allows solve noise blind image restoration problems gradient bound estimator involves gradient logarithm prior gradient corresponds mean shift vector natural image distribution learn mean shift vector field using denoising autoencoders demonstrate competitive results noise blind deblurring super resolution demosaicing
pixels graphs associative embedding graphs useful abstraction image content graphs represent details individual objects scene capture interactions pairs objects present method training convolutional neural network takes input image produces full graph definition done end end single stage use associative embeddings network learns simultaneously identify elements make graph piece together benchmark visual genome dataset demonstrate state art performance challenging task scene graph generation
shape reconstruction modeling sketch object reconstruction single image highly determined problem requiring strong prior knowledge plausible shapes introduces challenge learning based approaches object annotations real images scarce previous work chose train synthetic data ground truth information suffered domain adaptation issue tested real data work propose end end trainable framework sequentially estimating sketch object shape disentangled two step formulation three advantages first compared full shape sketch much easier recovered image transfer synthetic real images second reconstruction sketch easily transfer learned model synthetic data real images rendered sketches invariant object appearance variations real images including lighting texture etc relieves domain adaptation problem third derive differentiable projective functions shapes sketch making framework end end trainable real images requiring real image annotations framework achieves state art performance shape reconstruction
temporal coherency based criteria predicting video frames using deep multi stage generative adversarial networks predicting future sequence video frames recently sought yet challenging task field computer vision machine learning although efforts tracking using motion trajectories flow features complex problem generating unseen frames studied extensively paper deal problem using convolutional models within multi stage generative adversarial networks gan framework proposed method uses two stages gans generate crisp clear set future frames although gans used past predicting future none works consider relation subsequent frames temporal dimension main contribution lies formulating two objective functions based normalized cross correlation ncc pairwise contrastive divergence pcd solving problem method coupled traditional loss experimented three real world video datasets viz sports ucf 101 kitti performance analysis reveals superior results recent state art methods
learning generalize intrinsic images structured disentangling autoencoder intrinsic decomposition single image highly challenging task due inherent ambiguity scarcity training data contrast traditional fully supervised learning approaches paper propose learning intrinsic image decomposition explaining input image model rendered intrinsics network rin joins together image decomposition pipeline predicts reflectance shape lighting conditions given single image recombination function learned shading model used recompose original input based intrinsic image predictions network use unsupervised reconstruction error additional signal improve intermediate representations allows large scale unlabeled data useful training also enables transferring learned knowledge images unseen object categories lighting conditions shapes extensive experiments demonstrate method performs well intrinsic image decomposition knowledge transfer
unsupervised object learning dense equivariant image labelling one key challenges visual perception extract abstract models objects object categories visual measurements affected complex nuisance factors viewpoint occlusion motion deformations starting recent idea viewpoint factorization propose new approach given large number images object supervision extract dense object centric coordinate frame coordinate frame invariant deformations images comes dense equivariant labelling neural network map image pixels corresponding object coordinates demonstrate applicability method simple articulated objects deformable objects human faces learning embeddings random synthetic transformations optical flow correspondences without manual supervision
one sided unsupervised domain mapping unsupervised domain mapping learner given two unmatched datasets goal learn mapping gab translates sample analog sample recent approaches shown learning simultaneously gab inverse mapping gba convincing mappings obtained work present method learning gab without learning gba done learning mapping maintains distance pair samples moreover good mappings obtained even maintaining distance different parts sample mapping present experimental results new method allows one sided mapping learning also leads preferable numerical results existing circularity based constraint entire code made publicly available
contrastive learning image captioning image captioning popular topic computer vision achieved substantial progress recent years however distinctiveness natural descriptions often overlooked previous work closely related quality captions distinctive captions likely describe images unique aspects work propose new learning method contrastive learning image captioning specifically via two constraints formulated top reference model proposed method encourage distinctiveness maintaining overall quality generated captions tested method two challenging datasets improves baseline model significant margins also showed studies proposed method generic used models various structures
dynamic routing capsules capsule group neurons whose activity vector represents instantiation parameters specific type entity object object part use length activity vector represent probability entity exists orientation represent instantiation paramters active capsules one level make predictions via transformation matrices instantiation parameters higher level capsules multiple predictions agree higher level capsule becomes active show discrimininatively trained multi layer capsule system achieves state art performance mnist considerably better convolutional net recognizing highly overlapping digits achieve results use iterative routing agreement mechanism lower level capsule prefers send output higher level capsules whose activity vectors big scalar product prediction coming lower level capsule
uncertainties need bayesian deep learning computer vision two major types uncertainty one model aleatoric uncertainty captures noise inherent observations hand epistemic uncertainty accounts uncertainty model uncertainty explained away given enough data traditionally difficult model epistemic uncertainty computer vision new bayesian deep learning tools possible study benefits modeling epistemic aleatoric uncertainty bayesian deep learning models vision tasks present bayesian deep learning framework combining input dependent aleatoric uncertainty together epistemic uncertainty study models framework per pixel semantic segmentation depth regression tasks explicit uncertainty formulation leads new loss functions tasks interpreted learned attenuation makes loss robust noisy data also giving new state art results segmentation depth regression benchmarks
efficient optimization linear dynamical systems applications clustering sparse coding linear dynamical systems ldss fundamental tools modeling spatio temporal data various disciplines though rich modeling analyzing ldss free difficulty mainly ldss comply euclidean geometry hence conventional learning techniques applied directly paper propose efficient projected gradient descent method minimize general form loss function demonstrate clustering sparse coding ldss solved proposed method efficiently end first derive novel canonical form representing parameters lds show gradient descent updates projection space ldss achieved dexterously contrast previous studies solution avoids approximation lds modeling optimization process extensive experiments reveal superior performance proposed method terms convergence classification accuracy state art techniques
label distribution learning forests label distribution learning ldl general learning framework assigns instance distribution set labels rather single label multiple labels current ldl methods either restricted assumptions expression form label distribution limitations representation learning learn deep features end end manner paper presents label distribution learning forests ldlfs novel label distribution learning algorithm based differentiable decision trees several advantages decision trees potential model general form label distributions mixture leaf node predictions learning differentiable decision trees combined representation learning define distribution based loss function forest enabling trees learned jointly show update function leaf node predictions guarantees strict decrease loss function derived variational bounding effectiveness proposed ldlfs verified several ldl tasks computer vision application showing significant improvements state art ldl methods
graph matching via multiplicative update algorithm graph matching fundamental problem computer vision machine learning area problem usually formulated quadratic programming problem doubly stochastic discrete integer constraints since hard approximate algorithms required paper present new algorithm called multiplicative update graph matching mpgm develops multiplicative update technique solve matching problem mpgm three main benefits theoretically mpgm solves general problem doubly stochastic constraint naturally directly whose convergence kkt optimality guaranteed empirically mpgm generally returns sparse solution thus also incorporate discrete constraint approximately optimization efficient simple implement experiments synthetic real world matching tasks show benefits mpgm algorithm
training quantized nets deeper understanding currently deep neural networks deployed low power embedded devices first training full precision model using powerful computing hardware deriving corresponding low precision model efficient inference systems however training models directly coarsely quantized weights key step towards learning embedded platforms limited computing resources memory capacity power consumption numerous recent publications studied methods training quantized network weights studies mostly empirical work investigate training methods quantized neural networks theoretical viewpoint first explore accuracy guarantees training methods convexity assumptions look behavior algorithms non convex problems show training algorithms exploit high precision representations important annealing property purely quantized training methods lack explains many observed empirical differences types algorithms
inner loop free admm using auxiliary deep neural networks propose new method uses apply deep learning techniques accelerate popular alternating direction method multipliers admm solution inverse problems admm updates consist proximity operator least squares regression includes big matrix inversion explicit solution updating dual variables typically inner loops required solve first two sub minimization problems due intractability prior matrix inversion avoid drawbacks limitations propose textit inner loop free update rule two pre trained deep convolutional architectures specifically learn conditional denoising auto encoder imposes implicit data dependent prior regularization ground truth first sub minimization problem design follows empirical bayesian strategy leading called amortized inference matrix inversion second sub problem learn convolutional neural network approximate matrix inversion inverse mapping learned feeding input learned forward network note training neural network require ground truth measurements data independent extensive experiments synthetic data real datasets demonstrate efficiency accuracy proposed method compared conventional admm solution using inner loops solving inverse problems
towards accurate binary convolutional neural network introduce novel scheme train binary convolutional neural networks cnns cnns weights activations constrained run time known using binary weights activations drastically reduce memory size accesses replace arithmetic operations efficient bitwise operations leading much faster test time inference lower power consumption however previous works binarizing cnns usually result severe prediction accuracy degradation paper address issue two major innovations approximating full precision weights linear combination multiple binary weight bases employing multiple binary activations alleviate information loss implementation resulting binary cnn denoted abc net shown achieve much closer performance full precision counterpart even reach comparable prediction accuracy imagenet forest trail datasets given adequate binary weight bases activations
runtime neural pruning paper propose runtime neural pruning rnp framework prunes deep neural network dynamically runtime unlike existing neural pruning methods produce fixed pruned model deployment method preserves full ability original network conducts pruning according input image current feature maps adaptively pruning performed bottom layer layer manner model markov decision process use reinforcement learning training agent judges importance convolutional kernel conducts channel wise pruning conditioned different samples network pruned image easier task since ability network fully preserved balance point easily adjustable according available resources method applied shelf network structures reach better tradeoff speed accuracy especially large pruning rate
structured embedding models grouped data word embeddings powerful approach analyzing language exponential family embeddings efe extend types data develop structured exponential family embeddings efe method discovering embeddings vary across related groups data study word usage congressional speeches varies across states party affiliation words used differently across sections arxiv purchase patterns groceries vary across seasons key success method groups share statistical information develop two sharing strategies hierarchical modeling amortization demonstrate benefits approach empirical studies speeches abstracts shopping baskets show sefe enables group specific interpretation word usage outperforms efe predicting held data
poincar embeddings learning hierarchical representations representation learning become invaluable approach learning symbolic data text graphs however complex symbolic datasets often exhibit latent hierarchical structure state art methods typically learn embeddings euclidean vector spaces account property purpose introduce new approach learning hierarchical representations symbolic data embedding hyperbolic space precisely dimensional poincar ball due underlying hyperbolic geometry allows learn parsimonious representations symbolic data simultaneously capturing hierarchy similarity introduce efficient algorithm learn embeddings based riemannian optimization show experimentally poincar embeddings outperform euclidean embeddings significantly data latent hierarchies terms representation capacity terms generalization ability
language modeling recurrent highway hypernetworks provide extensive experimental theoretical support efficacy recurrent highway networks rhns recurrent hypernetworks complimentary original works demonstrate experimentally rhns benefit far better gradient flow lstms coupled greatly improved task accuracy raise provide solutions several theoretical issues hypernetworks believe yield gains future along dramatically reduced computational cost combining rhns hypernetworks make significant improvement current state art language modeling performance penn treebank relying much simpler regularization finally argue rhns drop replacement lstms analogous lstms vanilla rnns hypernetworks facto augmentation analogous attention recurrent architectures
preventing gradient explosions gated recurrent units gated recurrent unit gru successful recurrent neural network architecture time series data gru typically trained using gradient based method subject exploding gradient problem gradient increases significantly problem caused abrupt change dynamics gru due small variation parameters paper find condition dynamics gru changes drastically propose learning method address exploding gradient problem method constrains dynamics gru drastically change evaluated method experiments language modeling polyphonic music modeling experiments showed method prevent exploding gradient problem improve modeling accuracy
wider deeper cheaper faster tensorized lstms sequence learning long short term memory lstm popular approach boosting ability recurrent neural networks store longer term temporal information capacity lstm network increased widening adding layers however former introduces additional parameters latter increases runtime alternative propose tensorized lstm hidden states represented tensors updated via cross layer convolution increasing tensor size network widened efficiently without additional parameters since parameters shared across different locations tensor delaying output network deepened implicitly little additional runtime since deep computations timestep merged temporal computations sequence experiments conducted five challenging sequence learning tasks show potential proposed model
fast slow recurrent neural networks processing sequential data variable length major challenge wide range applications speech recognition language modeling generative image modeling machine translation address challenge proposing novel recurrent neural network rnn architecture fast slow rnn rnn rnn incorporates strengths multiscale rnns deep transition rnns processes sequential data different timescales learns complex transition functions one time step next evaluate rnn two character based language modeling data sets penn treebank hutter prize wikipedia improve state art results bits per character bpc respectively addition ensemble two rnns achieves bpc hutter prize wikipedia outperforming best known compression algorithm respect bpc measure also present empirical investigation learning network dynamics rnn explains improved performance compared rnn architectures approach general kind rnn cell possible building block rnn architecture thus flexibly applied different tasks
cold start reinforcement learning softmax policy gradients present learning algorithm targeted efficiently solving two fundamental problems structured output prediction exposure bias problem model exposed training data distribution may fail exposed predictions wrong objective problem training model convenient objective functions gives suboptimal performance method based policy gradient approach reinforcement learning succeeds avoiding two common overhead procedures associated approaches namely warm start training variance reduction policy updates proposed cold start reinforcement learning method based new softmax policy gradient softmax policy combines efficiency simplicity maximum likelihood approach effectiveness reward based signal empirical evidence validates method structured output predictions automatic summarization image captioning tasks
deep learning precipitation nowcasting benchmark new model goal making high resolution forecasts regional rainfall precipitation nowcasting become important fundamental technology underlying various public services ranging rainfall alerts flight safety recently convolutional lstm convlstm model shown outperform traditional optical flow based methods precipitation nowcasting suggesting deep learning models huge potential solving problem however convolutional recurrence structure convlstm based models location invariant natural motion transformation rotation location variant general furthermore since deep learning based precipitation nowcasting newly emerging area clear evaluation protocols yet established address problems propose new model benchmark precipitation nowcasting specifically beyond convlstm propose trajectory gru trajgru model actively learn location variant structure recurrent connections besides provide benchmark includes real world large scale dataset hong kong observatory new training loss comprehensive evaluation protocol facilitate future research gauge state art
recurrent ladder networks propose recurrent extension ladder network cite ladder motivated inference required hierarchical latent variable models demonstrate recurrent ladder able handle wide variety complex learning tasks need iterative inference temporal modeling architecture shows close optimal results temporal modeling video data competitive results music modeling improved perceptual grouping based higher order abstractions stochastic textures motion cues present results fully supervised semi supervised unsupervised tasks results suggest proposed architecture principles powerful tools learning hierarchy abstractions handling temporal information modeling relations interactions objects
predictive state decoders encoding future recurrent networks recurrent neural networks rnns vital modeling technique rely internal states learned indirectly optimization supervised unsupervised reinforcement training loss rnns used model dynamic processes characterized underlying latent states whose form often unknown precluding analytic representation inside rnn predictive state representation psr literature latent state processes modeled internal state representation directly models distribution future observations recent work area relied explicitly representing targeting sufficient statistics probability distribution seek combine advantages rnns psrs augmenting existing state art recurrent neural networks predictive state decoders psds add supervision network internal state representation target predicting future observations psds simple implement easily incorporated existing training pipelines via additional loss regularization demonstrate effectiveness psds experimental results three different domains probabilistic filtering imitation learning reinforcement learning method improves statistical performance state art recurrent baselines fewer iterations less data
qmdp net deep learning planning partial observability paper introduces qmdp net neural network architecture planning partial observability qmdp net combines strengths model free learning model based planning recurrent policy network represents policy connecting model planning algorithm solves model thus embedding solution structure planning network learning architecture qmdp net fully differentiable allows end end training train qmdp net set different environments generalize new ones transfer larger environments well preliminary experiments qmdp net showed strong performance several robotic tasks simulation interestingly qmdp net encodes qmdp algorithm sometimes outperforms qmdp algorithm experiments qmdp net increased robustness end end learning
filtering variational objectives evidence lower bound elbo appears many algorithms maximum likelihood estimation mle latent variables sharp lower bound marginal log likelihood neural latent variable models optimizing elbo jointly variational posterior model parameters produces state art results inspired success elbo surrogate mle objective consider extension elbo family lower bounds defined monte carlo estimator marginal likelihood show tightness bounds asymptotically related variance underlying estimator introduce special case filtering variational objectives takes arguments elbo passes particle filter form tighter bound filtering variational objectives optimized tractably stochastic gradients particularly suited mle sequential latent variable models standard sequential generative modeling tasks present uniform improvements computational budget models trained elbo iwae objectives include whole nat per timestep improvements
unsupervised learning disentangled latent representations sequential data present factorized hierarchical variational autoencoder learns disentangled representations sequential data without supervision specifically exploit multi scale nature information sequential data formulating explicitly within factorized hierarchical graphical model imposes sequence specific priors global priors different sets latent variables model evaluated two speech corpora demonstrate qualitatively ability transform speakers linguistic content manipulating different sets latent variables quantitatively ability outperform vector baseline speaker verification reduce word error rate much mismatched train test scenarios automatic speech recognition tasks
neural discrete representation learning learning useful representations without supervision remains key challenge machine learning paper propose simple yet powerful generative model learns discrete representations model vector quantised variational autoencoder vae differs vaes two key ways encoder network outputs discrete rather continuous codes prior learnt rather static order learn discrete latent representation incorporate ideas vector quantisation using method allows model circumvent issues posterior collapse latents ignored paired powerful autoregressive decoder typically observed vae framework pairing representations autoregressive prior model generate high quality images videos speech well high quality speaker inpainting providing evidence utility learnt representations
variational memory addressing generative models aiming augment generative models external memory interpret output memory module stochastic addressing conditional mixture distribution read operation corresponds sampling discrete memory address retrieving corresponding content memory perspective allows apply variational inference memory addressing enables effective training memory module using target information guide memory lookups stochastic addressing particularly well suited generative models naturally encourages multimodality prominent aspect high dimensional datasets treating chosen address latent variable also allows quantify amount information gained memory lookup measure contribution memory module generative process illustrate advantages approach incorporate variational autoencoder apply resulting model task generative shot learning intuition behind architecture memory module pick relevant template memory continuous part model concentrate modeling remaining variations demonstrate empirically model able identify access relevant memory contents even hundreds unseen omniglot characters memory
cortical microcircuits gated recurrent neural networks cortical circuits exhibit intricate recurrent architectures remarkably similar across different brain areas stereotyped structure suggests existence common computational principles remained largely elusive inspired gated memory networks namely long short term memory lstm nets introduce recurrent neural network rnn information gated inhibitory units subtractive balanced subrnn propose subrnns natural mapping onto known canonical excitatory inhibitory cortical microcircuits show networks subtractive gating easier optimise standard multiplicative gates moreover subrnns yield near exact solution standard long term dependency task temporal addition task empirical results across several long term dependency tasks generalised temporal addition multiplication temporal mnist word level language modelling show subrnns outperform achieve similar performance lstm networks tested work suggests novel view cortex solves complex contextual problems provides first step towards unifying machine learning recurrent networks biological counterparts
continual learning deep generative replay attempts train comprehensive artificial intelligence capable solving multiple tasks impeded chronic problem called catastrophic forgetting although simply replaying previous data alleviates problem requires large memory even worse often infeasible real world applications access past data limited inspired generative nature hippocampus short term memory system primate brain propose deep generative replay novel framework cooperative dual model architecture consisting deep generative model generator task solving model solver two models training data previous tasks easily sampled interleaved new task test methods several sequential learning settings involving image classification tasks
hierarchical attentive recurrent tracking class agnostic object tracking particularly difficult cluttered environments target specific discriminative models cannot learned priori inspired human visual cortex employs spatial attention separate andwhat processing pathways actively suppress irrelevant visual features work develops hierarchical attentive recurrent model single object tracking videos first layer attention discards majority background selecting region containing object interest subsequent layers tune visual features particular tracked object framework fully differentiable trained purely data driven fashion gradient methods improve training convergence augment loss function terms number auxiliary tasks relevant tracking evaluation proposed model performed two datasets increasing difficulty pedestrian tracking kth activity recognition dataset kitti object tracking dataset
vae learning via stein variational gradient descent new method learning variational autoencoders vaes developed based stein variational gradient descent key advantage approach one need make parametric assumptions form encoder distribution performance enhanced integrating proposed encoder importance sampling excellent performance demonstrated across multiple unsupervised semi supervised problems including semi supervised analysis imagenet data demonstrating scalability model large datasets
learning inpaint image compression study design deep architectures lossy image compression present two architectural recipes context multi stage progressive encoders empirically demonstrate importance compression performance specifically show predicting original image data residuals multi stage progressive architecture facilitates learning leads improved performance approximating original content learning inpaint neighboring image pixels performing compression reduces amount information must stored achieve high quality approximation incorporating design choices baseline progressive encoder yields average reduction file size similar quality compared original residual encoder
visual interaction networks glance humans make rich predictions future state wide range physical systems modern approaches engineering robotics graphics often restricted narrow domains require direct measurements underlying states introduce visual interaction network general purpose model learning dynamics physical system raw visual observations predicting future states model consists perceptual front end based convolutional neural networks dynamics predictor based interaction networks joint training perceptual front end learns parse dynamic visual scene set factored latent object representations dynamics predictor learns roll states forward time computing interactions dynamics producing predicted physical trajectory arbitrary length found six input video frames visual interaction network generate accurate future trajectories hundreds time steps wide range physical systems model also applied scenes invisible objects inferring future states effects visible objects implicitly infer unknown mass objects results demonstrate perceptual module object based dynamics predictor module induce factored latent representations support accurate dynamical predictions work opens new opportunities model based decision making planning raw sensory observations complex physical environments
neuralfdr learning discovery thresholds hypothesis features datasets grow richer important challenge leverage full features data maximize number useful discoveries controlling false positives address problem context multiple hypotheses testing hypothesis observe value along set features specific hypothesis example genetic association studies hypothesis tests correlation variant trait rich set features variant location conservation epigenetics etc could inform likely variant true association however popular testing approaches benjamini hochberg procedure independent hypothesis weighting ihw either ignore features assume features categorical propose new algorithm neuralfdr automatically learns discovery threshold function hypothesis features parametrize discovery threshold neural network enables flexible handling multi dimensional discrete continuous features well efficient end end optimization prove neuralfdr strong false discovery rate fdr guarantees show makes substantially discoveries synthetic real datasets moreover demonstrate learned discovery threshold directly interpretable
eigen distortions hierarchical representations develop method comparing hierarchical image representations terms ability explain perceptual sensitivity humans specifically utilize fisher information establish model derived prediction local sensitivity perturbations around given natural image given image compute eigenvectors fisher information matrix largest smallest eigenvalues corresponding model predicted least noticeable image distortions respectively human subjects measure amount distortion reliably detected added image compare thresholds predictions corresponding model use method test ability variety representations mimic human perceptual sensitivity find early layers vgg16 deep neural network optimized object recognition provide better match human perception later layers better match stage convolutional neural network cnn trained database human ratings distorted image quality hand find simple models early visual processing incorporating one stages local gain control trained database distortion ratings predict human sensitivity significantly better cnn layers vgg16
fly operation batching dynamic computation graphs dynamic neural networks toolkits pytorch dynet chainer offer flexibility implementing models cope data varying dimensions structure relative toolkits operate statically declared computations tensorflow cntk theano however existing toolkits static dynamic require developer organize computations batches necessary exploiting high performance data parallel algorithms hardware batching task generally difficult becomes major hurdle architectures become complex paper present algorithm implementation dynet toolkit automatically batching operations developers simply write minibatch computations aggregations single instance computations batching algorithm seamlessly executes fly computationally efficient batches variety tasks obtain throughput similar manual batches well comparable speedups single instance learning architectures impractical batch manually
learning affinity via spatial propagation networks paper propose spatial propagation networks learning affinity matrix show constructing row column linear propagation model spatially variant transformation matrix constitutes affinity matrix models dense global pairwise similarities image specifically develop three way connection linear propagation model formulates sparse transformation matrix elements output deep cnn results dense affinity matrix effective model task specific pairwise similarity instead designing similarity kernels according image features two points directly output similarities pure data driven manner spatial propagation network generic framework applied numerous tasks traditionally benefit designed affinity image matting colorization guided filtering name furthermore model also learn semantic aware affinity high level vision tasks due learning capability deep model validate proposed framework refinement object segmentation experiments helen face parsing pascal voc 2012 semantic segmentation tasks show spatial propagation network provides general effective efficient solutions generating high quality segmentation results
supervised adversarial domain adaptation work provides framework addressing problem supervised domain adaptation deep models main idea exploit adversarial learning learn embedded subspace simultaneously maximizes confusion two domains semantically aligning embedded versions supervised setting becomes attractive especially target data samples need labeled scenario alignment separation semantic probability distributions difficult lack data found carefully designing training scheme whereby typical binary adversarial discriminator augmented distinguish four different classes possible effectively address supervised adaptation problem addition approach high speed adaptation requires extremely low number labeled target training samples even one per category effective extensively compare approach state art domain adaptation two experiments one using datasets handwritten digit recognition one using datasets visual object recognition
deep hyperspherical learning convolution inner product founding basis convolutional neural networks cnns key end end visual representation learning benefiting deeper architectures recent cnns demonstrated increasingly strong representation abilities despite improvement increased depth larger parameter space also led challenges properly training network light challenges propose hyperspherical convolution sphereconv novel learning framework gives angular representations hyperspheres introduce spherenet deep hyperspherical convolution networks distinct conventional inner product based convolutional networks particular spherenet adopts sphereconv basic convolution operator supervised generalized angular softmax loss natural loss formulation sphereconv show spherenet effectively encode discriminative representation alleviate training difficulty leading easier optimization faster convergence better classification performance convolutional counterparts also provide theoretical justifications advantages hyperspherical optimization experiments ablation studies verified conclusion
riemannian approach batch normalization batch normalization proven effective algorithm deep neural network training normalizing input neuron reducing internal covariate shift space weight vectors layer naturally interpreted riemannian manifold invariant linear scaling weights following intrinsic geometry manifold provides new learning rule efficient easier analyze also propose intuitive effective gradient clipping regularization methods proposed algorithm utilizing geometry manifold resulting algorithm consistently outperforms original various types network architectures datasets
backprop without learning rates coin betting deep learning methods achieve state art performance many application scenarios yet methods require significant amount hyperparameters tuning order achieve best results particular tuning learning rates stochastic optimization process still one main bottlenecks paper propose new stochastic gradient descent procedure deep networks require learning rate setting contrary previous methods adapt learning rates make use assumed curvature objective function instead reduce optimization process game betting coin propose learning rate free optimal algorithm scenario theoretical convergence proven convex quasi convex functions empirical evidences show advantage algorithm popular stochastic gradient algorithms
convergence block coordinate descent training dnns tikhonov regularization lifting relu function higher dimensional space develop smooth multi convex formulation training feed forward deep neural networks dnns allows develop block coordinate descent bcd training algorithm consisting sequence numerically well behaved convex optimizations using ideas proximal point methods convex analysis prove bcd algorithm converge globally stationary point linear convergence rate order one experiments mnist database dnns trained bcd algorithm consistently yielded better test set error rates identical dnn architectures tarined via stochastic gradient descent sgd variants caffe toolbox
collaborative deep learning fixed topology networks significant recent interest parallelize deep learning algorithms order handle enormous growth data model sizes advances focus model parallelization engaging multiple computing agents via using central parameter server aspect data parallelization along decentralized computation explored sufficiently context paper presents new consensus based distributed sgd cdsgd momentum variant cdmsgd algorithm collaborative deep learning fixed topology networks enables data parallelization well decentralized computation framework extremely useful learning agents access local private data communication constrained environment analyze convergence properties proposed algorithm strongly convex nonconvex objective functions fixed diminishing step sizes using concepts lyapunov function construction demonstrate efficacy algorithms comparison baseline centralized sgd recently proposed federated averaging algorithm also enables data parallelism based benchmark datasets mnist cifar cifar 100
regularization affects critical points linear networks paper concerned problem representing learning linear transformation using linear neural network recent years growing interest study networks part due successes deep learning main question body research also paper pertains existence optimality properties critical points mean squared loss function primary concern robustness critical points regularization loss function optimal control model introduced purpose learning algorithm regularized form backprop derived using hamilton formulation optimal control formulation used provide complete characterization critical points terms solutions nonlinear matrix valued equation referred characteristic equation analytical numerical tools bifurcation theory used compute critical points via solutions characteristic equation main conclusion critical point diagram fundamentally different even arbitrary small amounts regularization
predicting organic reaction outcomes weisfeiler lehman network prediction organic reaction outcomes fundamental problem computational chemistry since reaction may involve hundreds atoms fully exploring space possible transformations intractable current solution utilizes reaction templates limit space suffers coverage efficiency issues paper propose template free approach efficiently explore space product molecules first pinpointing reaction center set nodes edges graph edits occur since small number atoms contribute reaction center directly enumerate candidate products generated candidates scored weisfeiler lehman difference network models high order interactions changes occurring nodes across molecule framework outperforms top performing template based approach margin running orders magnitude faster finally demonstrate model accuracy rivals performance domain experts
predicting scene parsing motion dynamics future important intelligent systems textit autonomous vehicles robotics anticipate future order plan early make decisions accordingly predicting future scene parsing motion dynamics helps agents understand visual environment better former provides dense semantic segmentations textit objects present later provides dense motion information textit objects move future paper propose novel model predict future scene parsing motion dynamics unobserved video frames simultaneously using history information preceding frames corresponding scene parsing results input model able predict scene parsing motion arbitrary time steps ahead importantly model superior compared methods predict parsing motion individually solve two prediction tasks jointly fully exploit complementary relationship best knowledge paper first aiming learn predict future scene parsing motion dynamics simultaneously large scale cityscapes dataset demonstrated model produces significantly better parsing motion prediction compared well established baselines addition also present predict steering angle vehicles using model good results verify capability model learn underlying latent parameters
houdini democratizing adversarial examples generating adversarial examples critical step evaluating improving robustness learning machines far existing methods work classification designed alter true performance measure problem hand introduce novel flexible approach named houdini generating adversarial specifically tailored final performance measure task considered successfully apply houdini range applications speech recognition pose estimation
geometric matrix completion recurrent multi graph neural networks matrix completion models among common formulations recommender systems recent works showed boost performance techniques introducing pairwise relationships users items form graphs imposing smoothness priors graphs however techniques fully exploit local stationary structures user item graphs number parameters learn linear number users items propose novel approach overcome limitations using geometric deep learning graphs matrix completion architecture combines novel multi graph convolutional neural network learn meaningful statistical graph structured patterns users items recurrent neural network applies learnable diffusion score matrix neural network system computationally attractive requires constant number parameters independent matrix size apply method several standard datasets showing outperforms state art matrix completion techniques
compression aware training deep neural networks recent years great progress made variety application domains thanks development increasingly deeper neural networks unfortunately huge number units networks makes expensive computationally memory wise overcome exploiting fact deep networks parametrized several compression strategies proposed methods however typically start network trained standard manner without considering future compression paper propose explicitly account compression training process end introduce regularizer encourages parameter matrix layer low rank training show allows learn much compact yet least effective models state art compression techniques
non parametric neural networks deep neural networks dnns probabilistic graphical models pgms two main tools statistical modeling dnns provide ability model rich complex relationships input independent output variables pgms provide ability encode dependencies among output variables end end training models structured graphical dependencies top independent neural predictions recently emerged principled ways combining two paradigms types models proven powerful discriminative settings discrete outputs extensions structured continuous spaces well performing efficient inference spaces lacking propose non parametric neural networks n3s modular approach cleanly separates non parametric structured posterior representation discriminative inference scheme allows end end training components experiments evaluate ability n3s capture structured posterior densities modeling compute complex statistics densities inference compare model number baselines including popular variational sampling based inference schemes terms accuracy speed
gibbsnet iterative adversarial inference deep graphical models directed latent variable models formulate joint distribution advantage sampling fast exact yet weakness need specify often simple fixed prior limits expressiveness model undirected latent variable models discard requirement specified prior yet sampling generally requires iterative procedure blocked gibbs sampling may require many steps achieve samples joint distribution propose novel approach learning joint distribution data latent code uses adversarially learned iterative procedure gradually refine joint distribution better match data distribution step gibbsnet best worlds theory practice achieving speed simplicity directed latent variable model guaranteed assuming adversarial game reaches virtual training criteria global minimum produce samples sampling iterations achieving expressiveness flexibility undirected latent variable model gibbsnet away need explicit ability classification class conditional generation joint image attribute modeling single model trained specific tasks show empirically gibbsnet able learn complex show leads improved inpainting iterative refinement dozens steps stable generation without collapse thousands steps despite trained three steps
exploring generalization deep learning goal understanding drives generalization deep networks consider several recently suggested explanations including norm based control sharpness robustness study measures ensure generalization highlighting importance scale normalization making connection sharpness pac bayes theory investigate well measures explain different observed phenomena
regularizing deep neural networks noise interpretation optimization overfitting one critical challenges deep neural networks various types regularization methods improve generalization performance injecting noises hidden units training dropout known successful regularizer still clear enough training techniques work well practice maximize benefit presence two conflicting objectives optimizing true data distribution preventing overfitting regularization paper addresses issues interpreting conventional training methods regularization noise injection optimize lower bound true objective proposing technique achieve tighter lower bound using multiple noise samples per mini batch demonstrate effectiveness idea several computer vision applications
extracting low dimensional dynamics multiple large scale neural population recordings learning predict correlations powerful approach understanding neural population dynamics extract low dimensional trajectories population recordings using dimensionality reduction methods current approaches dimensionality reduction neural data limited single population recordings identify dynamics embedded across multiple measurements propose approach extracting low dimensional dynamics multiple sequential recordings algorithm scales data comprising millions observed dimensions making possible access dynamics distributed across large populations multiple brain areas building subspace identification approaches dynamical systems perform parameter estimation minimizing moment matching objective using scalable stochastic gradient descent algorithm model optimized predict temporal covariations across neurons across time show approach naturally handles missing data multiple partial recordings identify dynamics predict correlations even presence severe subsampling small overlap recordings demonstrate effectiveness approach simulated data whole brain larval zebrafish imaging dataset
adaptive sampling population neurons adaptive sampling methods neuroscience primarily focused maximizing firing rate single recorded neuron recording two neurons usually possible find single stimulus maximizes firing rates neurons motivates objective function takes account recorded population neurons together propose adept adaptive sampling method optimize population objective functions simulated experiments first confirmed population objective functions elicited varied stimulus responses single neuron objective functions tested adept closed loop electrophysiological experiment population activity recorded macaque cortical area known mid level visual processing adept uses outputs deep convolutional neural network model feature embeddings predict neural responses adept elicited mean stimulus responses larger randomly chosen natural images well larger scatter stimulus responses adaptive sampling methods enable new scientific discoveries recording population neurons heterogeneous response properties
onacid online analysis calcium imaging data real time optical imaging methods using calcium indicators critical monitoring activity large neuronal populations vivo imaging experiments typically generate large amount data needs processed extract activity imaged neuronal sources deriving processing algorithms active area research existing methods require processing large amounts data time rendering vulnerable volume recorded data preventing real time experimental interrogation introduce onacid online framework analysis streaming calcium imaging data including motion artifact correction neuronal source extraction iii activity denoising deconvolution approach combines extends previous work online dictionary learning calcium imaging data analysis deliver automated pipeline discover track activity hundreds cells real time thereby enabling new types closed loop experiments apply algorithm two large scale experimental datasets benchmark performance manually annotated data show outperforms popular offline approach
detrended partial cross correlation brain connectivity analysis brain connectivity analysis critical component ongoing human connectome projects decipher healthy diseased brain recent work highlighted power law multi time scale properties brain signals however remains lack methods specifically quantify short long range brain connections paper using detrended partial cross correlation analysis dpcca propose novel functional connectivity measure delineate brain interactions multiple time scales controlling covariates use rich simulated fmri data validate proposed method apply real fmri data cocaine dependence prediction task show compared extant methods dpcca based approach distinguishes short long range functional connectivity also improves feature extraction subsequently increasing classification accuracy together paper contributes broadly new computational methodologies understand neural information processing
practical bayesian optimization model fitting bayesian adaptive direct search computational models fields computational neuroscience often evaluated via stochastic simulation numerical approximation fitting models implies difficult optimization problem complex possibly noisy parameter landscapes bayesian optimization successfully applied solving expensive black box problems engineering machine learning explore whether applied general tool model fitting first present novel algorithm bayesian adaptive direct search bads achieves competitive performance affordable computational overhead running time typical models perform extensive benchmark bads many common state art nonconvex derivative free optimizers set model fitting problems real data models six studies behavioral cognitive computational neuroscience default settings bads consistently finds comparable better solutions methods showing great promise bads particular general model fitting tool
error detection correction framework connectomics significant advances made recent years problem neural circuit reconstruction electron microscopic imagery improvements image acquisition image alignment boundary detection greatly reduced achievable error rate order make progress argue automated error detection essential focussing effort attention human machine paper report use automated error detection attention signal flood filling error correction module demonstrate significant improvements upon state art segmentation performance
cake effective brain connectivity causal kernels fundamental goal network neuroscience understand activity one region drives activity elsewhere process referred effective connectivity propose model causal interaction using integro differential equations causal kernels allow rich analysis effective connectivity approach combines tractability flexibility autoregressive modeling biophysical interpretability dynamic causal modeling causal kernels learned nonparametrically using gaussian process regression yielding efficient framework causal inference construct novel class causal covariance functions enforce desired properties causal kernels approach call cake construction model hyperparameters biophysical meaning therefore easily interpretable demonstrate efficacy cake number simulations give example realistic application magnetoencephalography meg data
learning neural representations human cognition across many fmri studies cognitive neuroscience enjoying rapid increase extensive public brain imaging datasets opening door design deploy large scale statistical models targeting unified perspective available data implies finding scalable automated solutions old challenge aggregate heterogeneous information brain function universal cognitive system relates psychological behavior brain networks cast challenge machine learning approach predict conditions statistical brain maps across different studies leverage multi task learning multi scale dimension reduction learn low dimensional representations brain images carry robust cognitive information robustly associated psychological stimuli multi dataset classification model achieves best prediction performance several large reference datasets compared models forgo learning cognitive aware low dimension representation brings substantial performance boost analysis small datasets introspected identify universal template cognitive concepts
mapping distinct timescales functional interactions among brain networks brain processes occur various timescales ranging milliseconds neurons minutes hours behavior characterizing functional coupling among brain regions diverse timescales key understanding brain produces behavior apply instantaneous lag based measures conditional linear dependence based granger geweke causality infer network connections distinct timescales functional magnetic resonance imaging fmri data due slow sampling rate fmri widely held produces spurious unreliable estimates functional connectivity applied fmri data challenge claim combining simulations novel machine learning approach first show simulated fmri data instantaneous lag based identify distinct timescales complementary patterns functional connectivity next analyzing fmri recordings 500 human subjects show linear classifier trained either instantaneous lag based connectivity reliably distinguishes task versus rest brain states cross validation accuracy importantly instantaneous lag based exploit markedly different spatial temporal patterns connectivity achieve robust classification approach provides novel framework uncovering validating functionally connected networks operate distinct timescales brain
robust estimation neural signals calcium imaging calcium imaging prominent technology neuroscience research allows simultaneous recording large numbers neurons awake animals automated extraction neurons temporal activity imaging datasets important step path producing neuroscience results however nearly imaging datasets typically contain gross contaminating sources could contributed technology used underlying biological tissue although attempts made better extract neural signals limited gross contamination scenarios effort address contamination full generality statistical estimation work proceed new direction propose extract cells activity using robust estimation derive optimal robust loss based simple abstraction calcium imaging data also find simple practical optimization routine loss provably fast convergence use proposed robust loss matrix factorization framework extract neurons temporal activity calcium imaging datasets demonstrate superiority robust estimation approach existing methods simulated real datasets
learning morphology brain signals using alpha stable convolutional sparse coding neural time series data contain wide variety prototypical signal waveforms atoms significant importance clinical cognitive research one goals analyzing data hence extract shift invariant atoms even though success reported existing algorithms limited applicability due heuristic nature moreover often vulnerable artifacts impulsive noise typically present raw neural recordings study address issues propose novel probabilistic convolutional sparse coding csc model learning shift invariant atoms raw neural signals containing potentially severe artifacts core model call csc lies family heavy tailed distributions called stable distributions develop novel computationally efficient monte carlo expectation maximization algorithm inference maximization step boils weighted csc problem develop computationally efficient optimization algorithm results show proposed algorithm achieves state art convergence speeds besides csc significantly robust artifacts compared three competing algorithms extract spike bursts oscillations even reveal subtle phenomena cross frequency coupling applied noisy neural time series
streaming weak submodularity interpreting neural networks fly many machine learning applications important explain predictions black box classifier example deep neural network assign image particular class cast interpretability black box classifiers combinatorial maximization problem propose efficient streaming algorithm solve subject cardinality constraints extending ideas badanidiyuru 2014 provide constant factor approximation guarantee algorithm case random stream order weakly submodular objective function first theoretical guarantee general class functions also show algorithm exists worst case stream order algorithm obtains similar explanations inception predictions times faster state art lime framework ribeiro 2016
decomposable submodular function minimization discrete continuous paper investigates connections discrete continuous approaches decomposable submodular function minimization provide improved running time estimates state art continuous algorithms problem using combinatorial arguments also provide systematic experimental comparison two types methods based clear distinction level level algorithms
differentiable learning submodular functions incorporate discrete optimization algorithms within modern machine learning models example possible use deep architectures layer whose output minimal cut parametrized graph given models trained end end leveraging gradient information introduction layers seems challenging due non continuous output paper focus problem submodular minimization show layers indeed possible key idea continuously relax output without sacrificing guarantees provide easily computable approximation jacobian complemented complete theoretical analysis finally contributions let experimentally learn probabilistic log supermodular models via level variational inference formulation
robust optimization non convex objectives consider robust optimization problems goal optimize worst case class objective functions develop reduction robust improper optimization bayesian optimization given oracle returns approximate solutions distributions objectives compute distribution solutions approximate worst case show derandomizing solution hard general done broad class statistical learning tasks apply results robust neural network training submodular optimization evaluate approach experimentally character classification task subject adversarial distortion robust influence maximization large networks
optimization landscape tensor decompositions non convex optimization local search heuristics widely used machine learning achieving many state art results becomes increasingly important understand work hard problems typical data landscape many objective functions learning conjectured geometric property local optima approximately global optima thus solved efficiently local search algorithms however establishing property difficult paper analyze optimization landscape random complete tensor decomposition problem many applications unsupervised leaning especially learning latent variable models practice efficiently solved gradient ascent non convex objective show small constant among set points function values factor larger expectation function local maxima approximate global maxima previously best known result characterizes geometry small neighborhoods around true components result implies even initialization barely better random guess gradient ascent algorithm guaranteed solve problem main technique uses kac rice formula random matrix theory best knowledge first time kac rice formula successfully applied counting number local minima highly structured random polynomial dependent coefficients
gradient descent take exponential time escape saddle points although gradient descent almost always escapes saddle points asymptotically lee 2016 paper shows even fairly natural random initialization schemes non pathological functions significantly slowed saddle points take exponential time escape hand gradient descent perturbations 2015 jin 2017 slowed saddle points find approximate local minimizer polynomial time result concludes gradient descent inherently slower justifies importance adding perturbations efficient non convex optimization experiments also provided demonstrate theoretical findings
convolutional phase retrieval study convolutional phase retrieval problem asks recover unknown signal length measurements consisting magnitude cyclic convolution known kernel length model motivated applications channel estimation optics underwater acoustic communication signal interest acted given channel filter phase information difficult impossible acquire show random mathbf efficiently recovered global phase using combination spectral initialization generalized gradient descent main challenge coping dependencies measurement operator overcome challenge using ideas decoupling theory suprema chaos processes restricted isometry property random circulant matrices recent analysis alternating minimizing methods
implicit regularization matrix factorization study implicit regularization optimizing underdetermined quadratic objective matrix gradient descent factorization conjecture provide empirical theoretical evidence small enough step sizes initialization close enough origin gradient descent full dimensional factorization converges minimum nuclear norm solution
near linear time approximation algorithms optimal transport via sinkhorn iteration computing optimal transport distances earth mover distance fundamental problem machine learning statistics computer vision despite recent introduction several algorithms good empirical performance unknown whether general optimal transport distances approximated near linear time paper demonstrates ambitious goal fact achieved cuturi sinkhorn distances provides guidance towards parameter tuning algorithm result relies new analysis sinkhorn iterations also directly suggests new algorithm greenkhorn theoretical guarantees numerical simulations clearly illustrate greenkhorn significantly outperforms classical sinkhorn algorithm practice
frank wolfe equilibrium computation consider frank wolfe method constrained convex optimization first order projection free procedure show algorithm recast different light emerging special case particular meta algorithm computing equilibria saddle points convex concave zero sum games equilibrium computation trick relies existence regret online learning generate sequence iterates also provide proof convergence vanishing regret show stated equivalence several nice properties particularly exhibits modularity gives rise various old new algorithms explore resulting methods provide experimental results demonstrate correctness efficiency
greedy algorithms cone constrained optimization convergence guarantees greedy optimization methods matching pursuit frank wolfe algorithms regained popularity recent years due simplicity effectiveness theoretical guarantees address optimization textit linear span textit convex hull set atoms respectively paper consider intermediate case optimization textit convex cone parametrized conic hull generic atom set leading first principled definitions non negative algorithms give explicit convergence rates demonstrate excellent empirical performance novel algorithms analysis tailored particular function atom set particular derive sublinear convergence general smooth convex objectives linear convergence strongly convex objectives cases general sets atoms furthermore establish clear correspondence algorithms known algorithms literature novel algorithms analyses target general atom sets general objective functions hence directly applicable large variety learning settings
cyclic coordinate descent beats randomized coordinate descent coordinate descent methods seen resurgence recent interest applicability machine learning well large scale data analysis superior empirical performance methods two variants cyclic coordinate descent ccd randomized coordinate descent rcd deterministic randomized versions methods light recent results literature common perception rcd always dominates ccd terms performance paper question perception provide examples generally problem classes ccd deterministic order faster rcd terms asymptotic worst case convergence furthermore provide lower upper bounds amount improvement rate deterministic relative rcd amount improvement depend deterministic order used also provide characterization best deterministic order leads maximum improvement convergence rate terms combinatorial properties hessian matrix objective function
linear convergence frank wolfe type algorithm trace norm balls propose rank variant classical frank wolfe algorithm solve convex minimization trace norm ball algorithm replaces top singular vector computation svd frank wolfe top singular vector computation svd done repeatedly applying svd times algorithm linear convergence rate objective function smooth strongly convex optimal solution rank improves convergence rate total complexity frank wolfe method variants
adaptive accelerated gradient converging method lderian error bound condition recent studies shown proximal gradient method accelerated gradient method apg restarting enjoy linear convergence weaker condition strong convexity namely quadratic growth condition qgc however faster convergence restarting apg method relies potentially unknown constant qgc appropriately restart apg restricts applicability address issue developing novel adaptive gradient converging methods leveraging magnitude proximal gradient criterion restart termination analysis extends much general condition beyond qgc namely lderian error bound heb condition key technique development novel synthesis adaptive regularization conditional restarting scheme extends previous work focusing strongly convex problems much broader family problems furthermore demonstrate results important implication applications machine learning objective function coercive semi algebraic convergence speed essentially total number iterations objective function consists huber norm regularization convex smooth piecewise quadratic loss square loss squared hinge loss huber loss proposed algorithm parameter free enjoys faster linear convergence without assumptions restricted eigen value condition notable linear convergence results aforementioned problems global instead local best knowledge improved results first shown work
searching dark practical svrg methods error bound conditions guarantee paper develops practical stochastic variance reduced gradient svrg methods error bound conditions theoretical guarantee error bound conditions inherent property optimization problem recently revived optimization developing fast algorithms improved global convergence without strong convexity particular condition interest quadratic error bound aka second order growth condition weaker strong convexity leveraged developing linear convergence many gradient proximal gradient methods several recent studies also derived linear convergence quadratic error bound condition stochastic variance reduced gradient method important milestone stochastic optimization solving machine learning problems however studies overlooked critical issue algorithmic dependence unknown parameter analogous strong convexity modulus error bound conditions usually difficult estimate therefore makes algorithm practical solving many interesting machine learning problems address issue propose novel techniques automatically search unknown parameter fly optimization maintaining almost convergence rate oracle setting assuming involved parameter given
geometric descent method convex composite minimization paper extend geometric descent method recently proposed bubeck lee singh tackle nonsmooth strongly convex composite problems prove proposed algorithm dubbed geometric proximal gradient method geopg converges linear rate
condition number problem numerical results linear regression logistic regression elastic net regularization show geopg compares favorably nesterov accelerated proximal gradient method especially problem ill conditioned
faster non ergodic stochastic alternating direction method multipliers study stochastic convex optimization subjected linear equality constraints traditional stochastic alternating direction method multipliers nesterov acceleration scheme achieve ergodic sqrt convergence rates number iteration introducing variance reduction techniques convergence rates improve ergodic paper propose new stochastic admm elaborately integrates nesterov extrapolation techniques nesterov extrapolation algorithm achieve non ergodic convergence rate optimal separable linearly constrained non smooth convex problems convergence rates based admm methods actually tight sqrt non ergodic sense best knowledge first work achieves truly accelerated stochastic convergence rate constrained convex problems experimental results demonstrate algorithm significantly faster existing state art stochastic admm methods
doubly accelerated stochastic variance reduced dual averaging method regularized empirical risk minimization develop new accelerated stochastic gradient method efficiently solving convex regularized empirical risk minimization problem mini batch settings use mini batches becoming golden standard machine learning community mini batch settings stabilize gradient estimate easily make good use parallel computing core proposed method incorporation new double acceleration technique variance reduction technique theoretically analyze proposed method show method much improves mini batch efficiencies previous accelerated stochastic methods essentially needs mini batches achieving optimal iteration complexities non strongly strongly convex objectives training set size show even non mini batch settings method surpasses best known convergence rate non strongly convex objectives achieves one strongly convex objectives
limitations variance reduction acceleration schemes finite sums optimization study conditions one able efficiently apply variance reduction acceleration schemes finite sums problems first show perhaps surprisingly finite sum structure sufficient obtaining complexity bound
smooth strongly convex finite sums one must also know exactly individual function referred oracle iteration next show broad class first order coordinate descent finite sums algorithms including sdca svrg sag possible get accelerated complexity bound unless strong convexity parameter given explicitly lastly show class algorithms used minimizing
smooth non strongly convex finite sums optimal complexity bound
nonlinear acceleration stochastic algorithms extrapolation methods use last iterates optimization algorithm produce better estimate optimum shown achieve optimal convergence rates deterministic setting using simple gradient iterates study extrapolation methods stochastic setting iterates produced either simple accelerated stochastic gradient algorithm first derive convergence bounds arbitrary potentially biased perturbations produce asymptotic bounds using ratio variance noise accuracy current point finally apply acceleration technique stochastic algorithms sgd saga svrg katyusha different settings show significant performance gains
acceleration averaging stochastic descent dynamics formulate study general family continuous time stochastic dynamics accelerated first order minimization smooth convex functions building averaging formulation accelerated mirror descent propose stochastic variant gradient contaminated noise study resulting stochastic differential equation prove bound rate change energy function associated problem use derive estimates convergence rates function values expectation persistent asymptotically vanishing noise discuss interaction parameters dynamics learning rate averaging weights variation noise process show particular asymptotic rate variation affects choice parameters ultimately convergence rate
multiscale semi markov dynamics intracortical brain computer interfaces intracortical brain computer interfaces allow people tetraplegia control computer cursor imagining motion paralyzed limbs standard decoders derived kalman filter assumes markov dynamics angle intended movement unimodal likelihood channel neural activity due errors made decoding noisy neural data user attempts move cursor goal angle cursor goal positions may change rapidly propose dynamic bayesian network includes screen goal position part latent state thus allows motion cues aggregated much longer history neural activity multiscale model explicitly captures relationship instantaneous angles motion long term goals incorporates semi markov dynamics motion trajectories also propose flexible likelihood model recordings neural populations offline experiments recorded neural data demonstrate significantly improved prediction motion directions compared kalman filter baselines derive efficient online inference algorithm enabling clinical trial participant tetraplegia control computer cursor neural activity real time
eeg graph factor graph based model capturing spatial temporal observational relationships electroencephalograms paper reports factor graph based model brain activity jointly describes instantaneous observation based temporal spatial dependencies factor functions represent dependencies defined manually based domain knowledge model validated using clinically collected intracranial electroencephalogram eeg data epilepsy patients application seizure onset localization results indicate model outperforms two conventional approaches devised using observational dependency alone better auc furthermore also show manual definitions factor functions allow solve graph inference exactly using graph cut algorithm experiments show proposed inference technique provides gain auc compared sampling based alternatives
asynchronous parallel coordinate minimization map inference finding maximum posteriori map assignment central task graphical models since modern applications give rise large problem instances increasing need efficient solvers work propose improve efficiency coordinate minimization based dual decomposition solvers running updates asynchronously parallel case message passing inference performed multiple processing units simultaneously without coordination reading writing shared memory analyze convergence properties resulting algorithms identify settings speedup gains expected numerical evaluations show approach indeed achieves significant speedups common computer vision tasks
speeding latent variable gaussian graphical model estimation via nonconvex optimization study estimation latent variable gaussian graphical model lvggm precision matrix superposition sparse matrix low rank matrix order speed estimation sparse plus low rank components propose sparsity constrained maximum likelihood estimator based matrix factorization efficient alternating gradient descent algorithm hard thresholding solve algorithm orders magnitude faster convex relaxation based methods lvggm addition prove algorithm guaranteed linearly converge unknown sparse low rank components optimal statistical precision experiments synthetic genomic data demonstrate superiority algorithm state art algorithms corroborate theory
expxorcist nonparametric graphical models via conditional exponential densities non parametric multivariate density estimation faces strong statistical computational bottlenecks practical approaches impose near parametric assumptions form density functions paper leverage recent developments propose class non parametric models attractive computational statistical properties approach relies simple function space assumption conditional distribution variable conditioned variables non parametric exponential family form
reducing reparameterization gradient variance optimization noisy gradients become ubiquitous statistics machine learning reparameterization gradients gradient estimates computed via reparameterization trick represent class noisy gradients often used monte carlo variational inference mcvi however gradient estimators noisy optimization procedure slow fail converge one way reduce noise use samples gradient estimate computationally expensive instead view noisy gradient random variable form inexpensive approximation generating procedure gradient sample approximation high correlation noisy gradient construction making useful control variate variance reduction demonstrate approach non conjugate multi level hierarchical models bayesian neural net observed gradient variance reductions multiple orders magnitude 000
robust conditional probabilities conditional probabilities core concept machine learning example optimal prediction label given input corresponds maximizing conditional probability common approach inference tasks learning model conditional probabilities however models often based strong assumptions log linear models hence estimate conditional probabilities robust highly dependent validity assumptions propose framework reasoning conditional probabilities without assuming anything underlying distributions except knowledge second order marginals estimated data show setting leads guaranteed bounds conditional probabilities calculated efficiently variety settings including structured prediction finally apply semi supervised deep learning obtaining results competitive variational autoencoders
stein variational gradient descent gradient flow stein variational gradient descent svgd deterministic sampling algorithm iteratively transports set particles approximate given distributions based efficient gradient based update guarantees optimally decrease divergence within function space paper develops first theoretical analysis svgd establish empirical measures svgd samples weakly converges target distribution show asymptotic behavior svgd characterized nonlinear fokker planck equation known vlasov equation physics develop geometric perspective views svgd gradient flow divergence functional new metric structure space distributions induced stein operator
parallel streaming wasserstein barycenters efficiently aggregating data different sources challenging problem particularly samples source distributed differently differences inherent inference task present reasons sensors sensor network may placed far apart affecting individual measurements conversely computationally advantageous split bayesian inference tasks across subsets data data need identically distributed across subsets one principled way fuse probability distributions via lens optimal transport wasserstein barycenter single distribution summarizes collection input measures respecting geometry however computing barycenter scales poorly requires discretization input distributions barycenter improving situation present scalable communication efficient parallel algorithm computing wasserstein barycenter arbitrary distributions algorithm operate directly continuous input distributions optimized streaming data method even robust nonstationary input distributions produces barycenter estimate tracks input measures time algorithm semi discrete needing discretize barycenter estimate best knowledge also provide first bounds quality approximate barycenter discretization becomes finer finally demonstrate practical effectiveness method tracking moving distributions sphere well large scale bayesian inference task
aide algorithm measuring accuracy probabilistic inference algorithms approximate probabilistic inference algorithms central many fields examples include sequential monte carlo inference robotics variational inference machine learning markov chain monte carlo inference statistics key problem faced practitioners measuring accuracy approximate inference algorithm specific dataset existing techniques measuring inference accuracy often brittle specialized one type inference algorithm paper introduces auxiliary inference divergence estimator aide algorithm measuring accuracy approximate inference algorithms aide based observation inference algorithms treated probabilistic models random variables used within inference algorithm viewed auxiliary variables view leads new estimator symmetric divergence output distributions two inference algorithms paper illustrates application aide algorithms inference regression hidden markov dirichlet process mixture models experiments show aide captures qualitative behavior broad class inference algorithms detect failure modes inference algorithms missed standard heuristics
deep dynamic poisson factorization model new model named deep dynamic poisson factorization model analyzing sequential count vectors proposed paper model based poisson factor analysis method captures dependence among time steps neural networks representing implicit distributions local complicated relationship obtained local implicit distribution deep latent structure exploited get long time dependence variational inference latent variables gradient descent based loss functions derived variational distribution performed inference synthetic dataset real world dataset applied proposed model results show good predicting fitting performance interpretable latent structure
model shrinkage effect gamma process edge partition models edge partition model epm fundamental bayesian nonparametric model extracting overlapping structure binary matrix epm adopts gamma proces prior automatically shrink number active atoms however empirically found model shrinkage epm typically work appropriately leads overfitted solution analysis expectation epm intensity function suggested gamma priors epm hyperparameters disturb model shrinkage effect internal order ensure model shrinkage effect epm works appropriate manner proposed two novel generative constructions epm cepm incorporating constrained gamma priors depm incorporating dirichlet priors instead gamma priors furthermore depm model parameters including infinite atoms prior could marginalized thus possible derive truly infinite depm idepm efficiently inferred using collapsed gibbs sampler experimentally confirmed model shrinkage proposed models works well idepm indicated state art performance generalization ability link prediction accuracy mixing efficiency convergence speed
model evidence nonequilibrium simulations marginal likelihood model evidence key quantity bayesian parameter estimation model comparison many probabilistic models computation marginal likelihood challenging involves sum integral enormous parameter space markov chain monte carlo mcmc powerful approach compute marginal likelihoods various mcmc algorithms evidence estimators proposed literature discuss use nonequilibrium techniques estimating marginal likelihood nonequilibrium estimators build recent developments statistical physics known annealed importance sampling ais reverse ais probabilistic machine learning introduce new estimators model evidence combine forward backward simulations show various challenging models new evidence estimators outperform forward reverse ais
nice adversarial training mcmc existing markov chain monte carlo mcmc methods either based general purpose domain agnostic schemes lead slow convergence require hand crafting problem specific proposals expert propose nice novel method train flexible parametric markov chain kernels produce samples desired properties first propose efficient likelihood free adversarial training method train markov chain mimic given data distribution leverage flexible volume preserving flows obtain parametric kernels mcmc using bootstrap approach show train efficient markov chains sample prescribed posterior distribution iteratively improving quality model samples nice provides first framework automatically design efficient domain specific mcmc proposals empirical results demonstrate nice combines strong guarantees mcmc expressiveness deep neural networks able significantly outperform competing methods hamiltonian monte carlo
identification gaussian process state space models gaussian process state space model gpssm non linear dynamical system unknown transition measurement mappings described gps research gpssms focussed state estimation problem however key challenge gpssms satisfactorily addressed yet system identification address challenge impose structured gaussian variational posterior distribution latent states parameterised recognition model form directional recurrent neural network inference structure allows recover posterior smoothed entire sequence data provide practical algorithm efficiently computing lower bound marginal likelihood using reparameterisation trick additionally allows arbitrary kernels used within gpssm demonstrate efficiently generate plausible future trajectories system seek model gpssm requiring small number interactions true system
streaming sparse gaussian process approximations sparse approximations gaussian process models provide suite methods enable models deployed large data regime enable analytic intractabilities sidestepped however field lacks principled method handle streaming data posterior distribution function values hyperparameters updated online fashion small number existing approaches either use suboptimal hand crafted heuristics hyperparameter learning suffer catastrophic forgetting slow updating new data arrive paper develops new principled framework deploying gaussian process probabilistic models streaming setting providing principled methods learning hyperparameters optimising pseudo input locations proposed framework experimentally validated using synthetic real world datasets
bayesian optimization gradients bayesian optimization shown success global optimization expensive evaluate multimodal objective functions however unlike optimization methods bayesian optimization typically use derivative information paper show bayesian optimization exploit derivative information find good solutions fewer objective function evaluations particular develop novel bayesian optimization algorithm derivative enabled knowledge gradient dkg one step bayes optimal asymptotically consistent provides greater one step value information derivative free setting dkg accommodates noisy incomplete derivative information comes sequential batch forms optionally reduce computational cost inference automatically selected retention single directional derivative also compute dkg acquisition function gradient using novel fast discretization free technique show dkg provides state art performance compared wide range optimization procedures without gradients benchmarks including logistic regression deep learning kernel learning nearest neighbors
variational inference gaussian process models linear complexity large scale gaussian process inference long faced practical challenges due time space complexity superlinear dataset size sparse variational gaussian process models capable learning large scale data standard strategies sparsifying model prevent approximation complex functions work propose novel variational gaussian process model decouples representation mean covariance functions reproducing kernel hilbert space show new parametrization generalizes previous models yields variational inference problem solved stochastic gradient ascent time space complexity linear number mean function parameters strategy makes adoption large scale expressive gaussian process models possible run several experiments regression tasks show decoupled approach greatly outperforms previous sparse variational gaussian process inference procedures
efficient modeling latent information supervised learning using gaussian processes often machine learning data collected combination multiple conditions voice recordings multiple persons labeled could build model captures latent information related conditions generalize new one data present new model called latent variable multiple output gaussian processes lvmogp allows jointly model multiple conditions regression generalize new condition data points test time lvmogp infers posteriors gaussian processes together latent space representing information different conditions derive efficient variational inference method lvmogp computational complexity low sparse gaussian processes show lvmogp significantly outperforms related gaussian process methods various tasks synthetic real data
non stationary spectral kernels propose non stationary spectral kernels gaussian process regression propose model spectral density non stationary kernel function mixture input dependent gaussian process frequency density surfaces solve generalised fourier transform model present family non stationary non monotonic kernels learn input dependent potentially long range non monotonic covariances inputs derive efficient inference using model whitening marginalized posterior show case studies kernels necessary modelling even rather simple time series image geospatial data non stationary characteristics
scalable log determinants gaussian process kernel learning applications varied bayesian neural networks determinantal point processes elliptical graphical models kernel learning gaussian processes gps one must compute log determinant positive definite matrix derivatives leading prohibitive computations propose novel approaches estimating quantities fast matrix vector multiplications mvms stochastic approximations based chebyshev lanczos surrogate models converge quickly even kernel matrices challenging spectra leverage approximations develop scalable gaussian process approach kernel learning find lanczos generally superior chebyshev kernel learning surrogate approach highly efficient accurate popular kernels
spectral mixture kernels multi output gaussian processes initially multiple output gaussian processes mogps models relied linear transformations independent latent single output gaussian processes gps resulted cross covariance functions limited parametric interpretation thus conflicting single output gps intuitive understanding lengthscales frequencies magnitudes name contrary current approaches mogp able better interpret relationship different channels directly modelling cross covariances spectral mixture kernel phase shift propose parametric family complex valued cross spectral densities build cramer theorem multivariate version bochner theorem provide principled approach design multivariate covariance functions constructed kernels able model delays among channels addition phase differences thus expressive previous methods also providing full parametric interpretation relationship across channels proposed method validated synthetic data compared existing mogp methods two real world examples
linearly constrained gaussian processes consider modification covariance function gaussian processes correctly account known linear constraints modelling target function transformation underlying function constraints explicitly incorporated model guaranteed fulfilled sample drawn prediction made also propose constructive procedure designing transformation operator illustrate result simulated real data examples
hindsight experience replay pieter abbeel wojciech zaremba
dealing sparse rewards one biggest challenges reinforcement learning present novel technique called hindsight experience replay allows sample efficient learning rewards sparse binary therefore avoid need complicated reward engineering combined arbitrary policy algorithm may seen form implicit curriculum demonstrate approach task manipulating objects robotic arm particular run experiments three different tasks pushing sliding pick place case using binary rewards indicating whether task completed ablation studies show hindsight experience replay crucial ingredient makes training possible challenging environments show policies trained physics simulation deployed physical robot successfully complete task video presenting experiments available https goo smrqni
log normality skewness estimated state action values reinforcement learning overestimation state action values harmful reinforcement learning agents paper show state action value estimated using bellman equation decomposed weighted sum path wise values follow log normal distributions since log normal distributions skewed distribution estimated values also skewed leading imbalanced likelihood overestimation degree imbalance vary greatly among actions policies within one problem instance making agent prone select actions policies inferior expected return higher likelihood overestimation present comprehensive analysis skewness examine factors impacts theoretical empirical results discuss possible ways reduce undesirable effect skewness
finite sample analysis gtd policy evaluation algorithms markov setting reinforcement learning key component policy evaluation aims estimate value function expected long term accumulated reward starting state given policy good policy evaluation method algorithms estimate value functions given policy accurately find better policy state space large continuous emph gradient based temporal difference gtd algorithms linear function approximation value function widely used considering collection evaluation data likely time reward consuming get clear understanding finite sample performance gtd algorithms important efficiency policy evaluation entire algorithms previous work converted gtd algorithms convex concave saddle point problem provided finite sample analysis gtd algorithms constant step size assumption data generated however know problems data generated markov processes rather step size set different ways paper realistic markov setting derive finite sample bounds expectation high probability general convex concave saddle point problem hence gtd algorithms bounds show markov setting variants step size gtd algorithms converge convergence rate determined step size related mixing time markov process explain experience reply trick effective since improve mixing property markov process best knowledge analysis first provide finite sample bounds gtd algorithms markov setting
inverse filtering hidden markov models paper considers three related inverse filtering problems hidden markov models hmms given sequence state posteriors system dynamics estimate corresponding sequence observations estimate observation likelihoods iii jointly estimate observation likelihoods observation sequence problems motivated challenges reverse engineering sensors including calibration diagnostics show avoid computationally expensive mixed integer linear program milp exploiting structure hmm filter provide conditions quantities uniquely recovered finally also consider case posteriors corrupted noise shown problem naturally posed clustering problem proposed algorithm evaluated real world polysomnographic data used automatic sleep staging
safe model based reinforcement learning stability guarantees reinforcement learning powerful paradigm learning optimal policies experimental data however find optimal policies reinforcement learning algorithms explore possible actions may harmful real world systems consequence learning algorithms rarely applied safety critical systems real world paper present learning algorithm explicitly considers safety terms stability guarantees specifically extend control theoretic results lyapunov stability verification show use statistical models dynamics obtain high performance control policies provable stability certificates moreover additional regularity assumptions terms gaussian process prior prove one effectively safely collect data order learn dynamics thus improve control performance expand safe region state space experiments show resulting algorithm safely optimize neural network policy simulated inverted pendulum without pendulum ever falling
data efficient reinforcement learning continuous state action gaussian pomdps present data efficient reinforcement learning method continuous state action systems significant observation noise data efficient solutions small noise exist pilco learns cartpole swing task 30s pilco evaluates policies planning state trajectories using dynamics model however pilco applies policies observed state therefore planning observation space extend pilco filtering instead plan belief space consistent partially observable markov decisions process pomdp planning enables data efficient learning significant observation noise outperforming naive methods post hoc application filter policies optimised original unfiltered pilco algorithm test method cartpole swing task involves nonlinear dynamics requires nonlinear control
linear regression without correspondence article considers algorithmic statistical aspects linear regression correspondence covariates responses unknown first fully polynomial time approximation scheme given natural least squares optimization problem constant dimension next average case noise free setting responses exactly correspond linear function draws standard multivariate normal distribution efficient algorithm based lattice basis reduction shown exactly recover unknown linear function arbitrary dimension finally lower bounds signal noise ratio established approximate recovery unknown linear function
complexity learning neural networks stunning empirical successes neural networks currently lack rigorous theoretical eplanation form would explanation take face existing complexity theoretic lower bounds first step might show data generated neural networks single hidden layer smooth activation functions benign input distributions learned efficiently demonstrate comprehensive lower bound ruling possibility wide class activation functions including currently used inputs drawn logconcave distribution family one hidden layer functions whose output sum gate hard learn precise sense statistical query algorithm includes known variants stochastic gradient descent loss function needs exponential number queries even using tolerance inversely proportional input dimensionality moreover hard family functions realizable small sublinear dimension number activation units single hidden layer lower bound also robust small perturbations true weights systematic experiments illustrate phase transition training error predicted analysis
near optimal sketching low rank tensor regression study least squares regression problem low rank tensor defined vectors rpd small compared denotes outer product vectors linear function problem motivated fact number parameters 1dpd significantly smaller 1dpd number parameters ordinary least squares regression consider decomposition model tensors well tucker decomposition models show apply data dimensionality reduction techniques based sparse random projections reduce problem much smaller problem min holds simultaneously obtain significantly smaller dimension sparsity randomized linear mapping possible ordinary least squares regression finally give number numerical simulations supporting theory
input sparsity time possible kernel low rank approximation low rank approximation common tool used accelerate kernel methods kernel matrix approximated via rank matrix stored much less space processed quickly work study limits computationally efficient low rank kernel approximation show broad class kernels including popular gaussian polynomial kernels computing relative error rank approximation least difficult multiplying input data matrix arbitrary matrix barring breakthrough fast matrix multiplication large requires nnz time nnz number non zeros lower bound matches many parameter regimes recent work subquadratic time algorithms low rank approximation general kernels mm16 mm17 demonstrating algorithms unlikely significantly improved particular nnz input sparsity runtimes time hope show first time nnz time approximation possible general radial basis function kernels gaussian kernel closely related problem low rank approximation kernelized dataset
higher order total variation classes grids minimax theory trend filtering methods consider problem estimating values function nodes dimensional grid graph equal side lengths smash noisy observations function assumed smooth allowed exhibit different amounts smoothness different regions grid heterogeneity eludes classical measures smoothness nonparametric statistics holder smoothness meanwhile total variation smoothness classes allow heterogeneity restrictive another sense constant functions counted perfectly smooth achieve zero move past consider two higher order classes based two ways compiling discrete derivatives parameter across nodes relate classes holder classes derive minimax error rates higher order classes analyze two naturally associated trend filtering methods seen optimal appropriate class
adaptive clustering semidefinite programming analyze clustering problem flexible probabilistic model aims identify optimal partition sample perform exact clustering high probability using convex semidefinite estimator interprets corrected relaxed version means estimator analyzed non asymptotic framework showed optimal near optimal recovering partition furthermore performances shown adaptive problem effective dimension well unknown number groups partition illustrate method performances comparison classical clustering algorithms numerical experiments simulated data
compressing gram matrix learning neural networks polynomial time consider problem learning function classes computed neural networks various activations relu sigmoid task believed intractable worst case major open problem understand minimal assumptions classes admit efficient algorithms work show natural distributional assumption eigenvalue decay gram matrix yields polynomial time algorithms non realizable setting expressive classes networks feed forward networks relus make assumptions network architecture labels given sufficiently strong polynomial eigenvalue decay obtain fully polynomial time algorithms parameters respect square loss milder decay also leads improved algorithms aware prior work assumption marginal distribution alone leads polynomial time algorithms networks relus even one hidden layer unlike prior assumptions marginal distribution gaussian eigenvalue decay observed practice common data sets algorithm applies function class embedded suitable rkhs main technical contribution new approach proving generalization bounds kernelized regression using compression schemes opposed rademacher bounds general known sample complexity bounds kernel methods must depend norm corresponding rkhs quickly become large depending kernel function employed sidestep worst case bounds sparsifying gram matrix using recent work recursive nystrom sampling due musco musco prove approximate sparse hypothesis admits compression scheme whose true error depends rate eigenvalue decay
learning average top loss work introduce average top atk loss new ensemble loss supervised learning atk loss provides natural generalization two widely used ensemble losses namely average loss maximum loss furthermore atk loss combines advantages alleviate corresponding drawbacks better adapt different data distributions show atk loss affords intuitive interpretation reduces penalty continuous convex individual losses correctly classified data atk loss lead convex optimization problems solved effectively conventional sub gradient based method study statistical learning theory matk establishing classification calibration statistical consistency matk provide useful insights practical choice parameter demonstrate applicability matk learning combined different individual loss functions binary multi class classification regression using synthetic real datasets
hierarchical clustering beyond worst case hiererachical clustering computing recursive partitioning dataset obtain clusters increasingly finer granularity fundamental problem data analysis although hierarchical clustering mostly studied procedures linkage algorithms top heuristics rather optimization problems recently dasgupta proposed objective function hierarchical clustering initiated line work developing algorithms explicitly optimize objective see also paper consider fairly general random graph model hierarchical clustering called hierarchical stochastic blockmodel hsbm show certain regimes svd approach mcsherry combined specific linkage methods results clustering give approximation dasgupta cost function also show approach based sdp relaxations balanced cuts based work makarychev combined recursive sparsest cut algorithm dasgupta yields approximation slightly larger regimes also semi random setting adversary may remove edges random graph generated according hsbm finally report empirical evaluation synthetic real world data showing proposed svd based method indeed achieve better cost widely used heurstics also results better classification accuracy underlying problem multi class classification
net trim convex pruning deep neural networks performance guarantee introduce analyze new technique model reduction deep neural networks large networks theoretically capable learning arbitrarily complex models overfitting model redundancy negatively affects prediction accuracy model variance net trim algorithm prunes sparsifies trained network layer wise removing connections layer solving convex optimization program program seeks sparse set weights layer keeps layer inputs outputs consistent originally trained model algorithms associated analysis applicable neural networks operating rectified linear unit relu nonlinear activation present parallel cascade versions algorithm latter achieve slightly simpler models generalization performance former computed distributed manner cases net trim significantly reduces number connections network also providing enough regularization slightly reduce generalization error also provide mathematical analysis consistency initial network retrained model analyze model sample complexity derive general sufficient conditions recovery sparse transform matrix single layer taking independent gaussian random vectors inputs show network response described using maximum number non zero weights per node weights learned slog samples
graph theoretic approach multitasking key feature neural network architectures ability support simultaneous interaction among large numbers units learning processing representations however richness interactions trades ability network simultaneously carry multiple independent processes salient limitation many domains human cognition remains largely unexplored paper use graph theoretic analysis network architecture address question tasks represented edges bipartite graph define new measure multitasking capacity networks based assumptions tasks emph need multitasked rely independent resources form matching tasks emph performed without interference form induced matching main result inherent tradeoff multitasking capacity average degree network holds emph regardless network architecture results also extended networks depth greater
positive side demonstrate networks random like locally sparse desirable multitasking properties results shed light parallel processing limitations neural systems provide insights may useful analysis design parallel architectures
information theoretic analysis generalization capability learning algorithms derive upper bounds generalization error learning algorithm terms mutual information input output upper bounds provide theoretical guidelines striking right balance data fit generalization controlling input output mutual information learning algorithm results also used analyze generalization capability learning algorithms adaptive composition bias accuracy tradeoffs adaptive data analytics work extends leads nontrivial improvements recent results russo zou
independence clustering without matrix independence clustering problem considered following formulation given set random variables required find finest partitioning clusters clusters mutually independent since mutual independence target pairwise similarity measurements use thus traditional clustering algorithms inapplicable distribution random variables general unknown sample available thus problem cast terms time series two forms sampling considered stationary time series main emphasis latter general case consistent computationally tractable algorithm settings proposed number fascinating open directions research outlined
polynomial codes optimal design high dimensional coded matrix multiplication consider large scale matrix multiplication problem computation carried using distributed system master node multiple worker nodes worker store parts input matrices propose computation strategy leverages ideas coding theory design intermediate computations worker nodes order efficiently deal straggling workers proposed strategy named emph polynomial codes achieves optimum recovery threshold defined minimum number workers master needs wait order compute output furthermore leveraging algebraic structure polynomial codes map reconstruction problem final output polynomial interpolation problem solved efficiently polynomial codes provide order wise improvement state art terms recovery threshold also optimal terms several metrics furthermore extend code distributed convolution show order wise optimality
estimating mutual information discrete continuous mixtures estimation mutual information observed samples basic primitive machine learning useful several learning tasks including correlation mining information bottleneck chow liu tree conditional independence testing causal graphical models mutual information quantity well defined general probability spaces estimators developed special case discrete continuous pairs random variables estimators operate using principle calculating three differential entropies pair however general mixture spaces individual entropies well defined even though mutual information paper develop novel estimator estimating mutual information discrete continuous mixtures prove consistency estimator theoretically well demonstrate excellent empirical performance problem relevant wide array applications variables discrete continuous others mixture continuous discrete components
best response regression regression task predictor given set instances along real value point subsequently identify value new instance accurately possible work initiate study strategic predictions machine learning consider regression task tackled two players payoff player proportion points predicts accurately player first revise probably approximately correct learning framework deal case duel two predictors devise algorithm finds linear regression predictor best response necessarily linear regression algorithm show linearithmic sample complexity polynomial time complexity dimension instances domain fixed also test approach high dimensional setting show significantly defeats classical regression algorithms prediction duel together work introduces novel machine learning task lends well current competitive online settings provides theoretical foundations illustrates applicability
statistical cost sharing study cost sharing problem cooperative games situations cost function available via oracle queries must instead learned samples drawn distribution represented tuples different subsets players formalize approach call statistical cost sharing consider computation core shapley value expanding work balcan 2015 give precise sample complexity bounds computing cost shares satisfy core property high probability function non empty core shapley value never studied setting show submodular cost functions curvature bounded curvature approximated samples uniform distribution factor bound tight define statistical analogues shapley axioms derive notion statistical shapley value approximated arbitrarily well samples distribution function
sample complexity measure applications learning optimal auctions introduce new sample complexity measure refer split sample growth rate hypothesis sample size split sample growth rate counts many different hypotheses empirical risk minimization output sub sample size show expected generalization error upper bounded log result enabled strengthening rademacher complexity analysis expected generalization error show sample complexity measure greatly simplifies analysis sample complexity optimal auction design many auction classes studied literature sample complexity derived solely noticing auction classes erm sample sub sample pick parameters equal one points sample
multiplicative weights update constant step size congestion games convergence limit cycles chaos multiplicative weights update mwu method ubiquitous meta algorithm works follows distribution maintained certain set step probability assigned action multiplied cost action rescaled ensure new values form distribution analyze mwu congestion games agents use textit arbitrary admissible constants learning rates prove convergence textit exact nash equilibria interestingly convergence result carry nearly homologous mwu variant step probability assigned action multiplied even innocuous case two agent two strategy load balancing games dynamics provably lead limit cycles even chaotic behavior
efficiency guarantees data analysis efficiency outcomes game theoretic settings main item study intersection economics computer science notion price anarchy takes worst case stance efficiency analysis considering instance independent guarantees efficiency propose data dependent analog price anarchy refines worst case assuming access samples strategic behavior focus auction settings latter non trivial due private information held participants approach bounding efficiency data robust statistical errors mis specification unlike traditional econometrics seek learn private information players observed behavior analyze properties outcome directly quantify inefficiency without going private information apply approach datasets sponsored search auction system find empirical results significant improvement bounds worst case analysis
safe nested subgame solving imperfect information games unlike perfect information games imperfect information games cannot solved decomposing game subgames solved independently thus computationally intensive equilibrium finding techniques used decisions must consider strategy game whole possible solve imperfect information game exactly decomposition possible approximate solutions improve existing solutions solving disjoint subgames process referred subgame solving introduce subgame solving techniques outperform prior methods theory practice also show adapt past subgame solving techniques respond opponent actions outside original action abstraction significantly outperforms prior state art approach action translation finally show subgame solving repeated game progresses tree leading significantly lower exploitability applied techniques develop first defeat top humans heads limit texas hold poker
primer optimal transport optimal transport provides powerful flexible way compare probability measures discrete continuous includes therefore point clouds histograms datasets parametric generative models originally proposed eighteenth century theory later led nobel prizes koopmans kantorovich well villani fields medal 2010 recently reached machine learning community tackle challenging learning scenarios including dimensionality reduction structured prediction problems involve histogram outputs estimation generative models gans highly degenerate high dimensional problems despite recent successes bringing theory practice remains challenging machine learning community mathematical formality tutorial introduce approachable way crucial theoretical computational algorithmic practical aspects needed machine learning applications
fast black box variational inference stochastic trust region optimization introduce trustvi fast second order algorithm black box variational inference based trust region optimization reparameterization trick iteration trustvi proposes assesses step based minibatches draws variational distribution algorithm provably converges stationary point implement trustvi stan framework compare advi trustvi typically converges tens iterations solution least good one advi reaches thousands iterations trustvi iterations computationally expensive total computation typically order magnitude less experiments
optimal transport machine learning optimal transport gradually establishing powerful essential tool compare probability measures machine learning take form point clouds histograms bags features generally datasets compared probability densities generative models traced back early work monge later kantorovich dantzig birth linear programming mathematical theory produced several important developments since crowned dric villani fields medal 2010 transitioning applied spheres including recent applications machine learning tackle challenging learning scenarios including dimensionality reduction structured prediction problems involve histograms estimation generative models highly degenerate high dimensional problems workshop follow organized years ago nips 2014 seek amplify trend provide audience update recent successes brought forward efficient solvers innovative applications long list invited talks add contributed presentations oral needed posters finally panel invited speakers take questions audience formulate nuanced opinions nascent field
bayesian optimization science engineering ruben martinez cantin jose miguel hern ndez lobato javier gonzalez
bayesian optimization recent subfield machine learning comprising collection methodologies efficient optimization expensive black box functions techniques work fitting model black box function data using model predictions decide collect data next optimization problem solved using small number function evaluations resulting methods characterized high sample efficiency compared alternative black box optimization algorithms enabling solution new challenging problems example recent years become popular tool machine learning community excellent performance attained problem hyperparameter tuning important results academia industry success made crucial player current trend automatic machine learning new methods developed area applicability continuously expanding problem hyperparameter tuning permeates disciplines field moved towards specific problems science engineering requiring new advanced methodology today bayesian optimization promising approach accelerating automating science engineering therefore chosen year theme workshop bayesian optimization science engineering
opt 2017 optimization machine learning year marks major milestone history opt 10th anniversary edition long running nips workshop
previous opt workshops enjoyed packed overpacked attendance huge interest surprise optimization 2nd largest topic nips indeed foundational wider community
looking back past decade strong trend apparent intersection opt grown monotonically point several cutting edge advances optimization arise community distinctive feature optimization within departure textbook approaches particular different set goals driven big data models practical implementation crucial
revenue optimization approximate bid predictions context advertising auctions finding good reserve prices notoriously challenging learning problem due heterogeneity opportunity types non convexity objective function work show reduce reserve price optimization standard setting prediction squared loss well understood problem learning community bound gap expected bid revenue terms average loss predictor first result formally relates revenue gained quality standard machine learned model
multi information source optimization consider bayesian methods multi information source optimization miso seek optimize expensive evaluate black box objective function also accessing cheaper biased noisy approximations information sources present novel algorithm outperforms state art problem using joint statistical model information sources better suited miso used previous approaches novel acquisition function based one step optimality analysis supported efficient parallelization provide guarantee asymptotic quality solution provided algorithm experimental evaluations demonstrate algorithm consistently finds designs higher value less cost previous approaches
fast black box variational inference stochastic trust region optimization introduce trustvi fast second order algorithm black box variational inference based trust region optimization reparameterization trick iteration trustvi proposes assesses step based minibatches draws variational distribution algorithm provably converges stationary point implement trustvi stan framework compare advi trustvi typically converges tens iterations solution least good one advi reaches thousands iterations trustvi iterations computationally expensive total computation typically order magnitude less experiments
stochastic optimization variance reduction infinite datasets finite sum structure stochastic optimization algorithms variance reduction proven successful minimizing large finite sums functions unfortunately techniques unable deal stochastic perturbations input data induced example data augmentation cases objective longer finite sum main candidate optimization stochastic gradient descent method sgd paper introduce variance reduction approach settings objective composite strongly convex convergence rate outperforms sgd typically much smaller constant factor depends variance gradient estimates due perturbations single example
straggler mitigation distributed optimization data encoding slow running straggler tasks significantly reduce computation speed distributed computation recently coding theory inspired approaches applied mitigate effect straggling embedding redundancy certain linear computational steps optimization algorithm thus completing computation without waiting stragglers paper propose alternate approach embed redundancy data instead computation allow nodes operate completely oblivious encoding propose several encoding schemes demonstrate popular batch algorithms gradient descent bfgs applied coding oblivious manner deterministically achieve sample path linear convergence approximate solution original problem using arbitrarily varying subset nodes iteration moreover approximation controlled choice encoding matrix number nodes used iteration provide experimental results demonstrating advantage approach uncoded replication strategies
beyond worst case probabilistic analysis affine policies dynamic optimization affine policies control widely used solution approach dynamic optimization computing optimal adjustable solution usually intractable worst case performance affine policies significantly bad empirical performance observed near optimal large class problem instances instance two stage dynamic robust optimization problem linear covering constraints uncertain right hand side worst case approximation bound affine policies also tight see bertsimas goyal 2012 whereas observed empirical performance near optimal paper aim address stark contrast worst case empirical performance affine policies particular show affine policies give good approximation two stage adjustable robust optimization problem high probability random instances constraint coefficients generated large class distributions thereby providing theoretical justification observed empirical performance hand also present distribution performance bound affine policies instances generated according distribution high probability however constraint coefficients demonstrates empirical performance affine policies depend generative model instances
breaking nonsmooth barrier scalable parallel method composite optimization due simplicity excellent performance parallel asynchronous variants stochastic gradient descent become popular methods solve wide range large scale optimization problems multi core architectures yet despite practical success support nonsmooth objectives still lacking making unsuitable many problems interest machine learning lasso group lasso empirical risk minimization box constraints key technical issues explain paucity design algorithms asynchronous analysis work propose analyze proxasaga fully asynchronous sparse method inspired saga variance reduced incremental gradient algorithm proposed method easy implement significantly outperforms state art several nonsmooth large scale problems prove method achieves theoretical linear speedup respect sequential version assumptions sparsity gradients block separability proximal term empirical benchmarks multi core architecture illustrate practical speedups 13x core machine
structured prediction theory calibrated convex surrogate losses provide novel theoretical insights structured prediction context efficient convex surrogate loss minimization consistency guarantees task loss construct convex surrogate optimized via stochastic gradient descent prove tight bounds called calibration function relating excess surrogate risk actual risk contrast prior related work carefully monitor effect exponential number classes learning guarantees well optimization complexity interesting consequence formalize intuition task losses make learning harder others classical loss ill suited structured prediction
terngrad ternary gradients reduce communication distributed deep learning high network communication cost synchronizing gradients parameters well known bottleneck distributed training work propose terngrad uses ternary gradients accelerate distributed deep learning data parallelism approach requires three numerical levels aggressively reduce communication time mathematically prove convergence terngrad assumption bound gradients guided bound propose layer wise ternarizing gradient clipping improve convergence experiments show applying terngrad alexnet incur accuracy loss even improve accuracy accuracy loss googlenet induced terngrad less average finally performance model proposed study scalability terngrad experiments show significant speed gains various deep neural networks
rebar low variance unbiased gradient estimates discrete latent variable models learning models discrete latent variables challenging due high variance gradient estimators generally approaches relied control variates reduce variance reinforce estimator recent work citep jang2016categorical maddison2016concrete taken different approach introducing continuous relaxation discrete variables produce low variance biased gradient estimates work combine two approaches novel control variate produces low variance emph unbiased gradient estimates introduce novel continuous relaxation show tightness relaxation adapted online removing hyperparameter show state art variance reduction several benchmark generative modeling tasks generally leading faster convergence better final log likelihood
train longer generalize better closing generalization gap large batch training neural networks background deep learning models typically trained using stochastic gradient descent one variants methods update weights using gradient estimated small fraction training data observed using large batch sizes persistent degradation generalization performance known generalization gap phenomena identifying origin gap closing remained open problem contributions examine initial high learning rate training phase find weight distance initialization grows logarithmicaly number weight updates therefore propose random walk random landscape statistical model known exhibit similar ultra slow diffusion behavior following hypothesis conducted experiments show empirically generalization gap stems relatively small number updates rather batch size completely eliminated adapting training regime used investigate different techniques train models large batch regime present novel algorithm named ghost batch normalization enables significant decrease generalization gap without increasing number updates validate findings conduct several additional experiments mnist cifar cifar 100 imagenet finally reassess common practices beliefs concerning training deep models suggest may optimal achieve good generalization
unsupervised image image translation networks existing image image translation frameworks mapping image one domain corresponding image another based supervised learning pairs corresponding images two domains required learning translation function largely limits applications capturing corresponding images two different domains often difficult task address issue propose unsupervised image image translation unit framework proposed framework based variational autoencoders generative adversarial networks learn translation function without corresponding images show learning capability enabled combining weight sharing constraint adversarial objective verify effectiveness proposed framework extensive experiment results
bayesian gans generative adversarial networks gans implicitly learn rich distributions images audio data hard model explicit likelihood present practical bayesian formulation unsupervised semi supervised learning gans use stochastic gradient hamiltonian monte carlo marginalize weights generator discriminator networks resulting approach straightforward obtains good performance without standard interventions feature matching mini batch discrimination exploring expressive posterior parameters generator bayesian gan avoids mode collapse produces interpretable candidate samples notable variability particular provides state art quantitative results semi supervised learning benchmarks including svhn celeba cifar outperforming dcgan wasserstein gans dcgan ensembles
imagination augmented agents deep reinforcement learning
reinforcement learning deep learning introduce imagination augmented agents i2as novel architecture deep reinforcement learning combining model free model based aspects contrast existing model based reinforcement learning planning methods prescribe model used arrive policy i2as learn interpret predictions trained environment model construct implicit plans arbitrary ways using predictions additional context deep policy networks i2as show improved data efficiency performance robustness model misspecification compared several strong baselines
multi information source optimization consider bayesian methods multi information source optimization miso seek optimize expensive evaluate black box objective function also accessing cheaper biased noisy approximations information sources present novel algorithm outperforms state art problem using joint statistical model information sources better suited miso used previous approaches novel acquisition function based one step optimality analysis supported efficient parallelization provide guarantee asymptotic quality solution provided algorithm experimental evaluations demonstrate algorithm consistently finds designs higher value less cost previous approaches

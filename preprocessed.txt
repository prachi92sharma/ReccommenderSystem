learn activ learn data paper suggest novel data driven approach activ learn key idea train regressor predict expect error reduct candid sampl particular learn state formul queri select procedur regress problem restrict work exist heurist instead learn strategi base experi previous outcom show strategi learnt either simpl synthet dataset subset domain specif data method yield strategi work well real data wide rang domain
scalabl variat infer dynam system gradient match promis tool learn paramet state dynam ordinari differenti equat grid free infer approach fulli observ system time competit numer integr howev mani real world applic spars observ avail even unobserv variabl includ model descript case gradient match method difficult appli simpli provid satisfactori result despit high comput cost numer integr still gold standard mani applic use exist gradient match approach propos scalabl variat infer framework infer state paramet simultan offer comput speedup improv accuraci work well even model misspecif partial observ system
activ learn peer paper address challeng learn peer onlin multitask set instead alway request label human oracl propos method first determin learner task acquir label suffici confid peer either task similar weight sum singl similar task save oracl queri later use difficult case queri human oracl paper develop new algorithm exhibit behavior prove theoret mistak bound method compar best linear predictor hindsight experi multitask learn benchmark dataset show clear superior perform baselin assum task independ learn oracl learn peer task
gradient episod memori continuum learn major obstacl toward artifici intellig poor abil current model reus knowledg acquir past quick learn new task forget previous learn work formal emph continuum learn set train exampl emph iid generat continu stream task unknown relationship first propos new set metric continuum learn character learn system term averag accuraci also term abil transfer knowledg previous futur task second propos model continuum learn term gradient episod memori gem reduc forget allow potenti improv perform previous task experi variant mnist cifar100 dataset demonstr strong perform model compar varieti state art contend
consist multitask learn nonlinear output relat key multitask learn exploit relationship differ task improv predict perform relat linear regular approach use success howev practic assum task linear relat might restrict allow nonlinear structur challeng paper tackl issu cast problem within framework structur predict main contribut novel algorithm learn multipl task relat system nonlinear equat joint output need satisfi show algorithm consist effici implement experiment result show potenti propos method
joint distribut optim transport domain adapt paper deal unsupervis domain adapt problem want estim predict function
given target domain without label sampl exploit knowledg avail sourc domain label known work make follow assumpt exist non linear transform joint featur label space distribut domain propos solut problem optim transport allow recov estim target ptf optim simultan optim coupl show method correspond minim bound target error provid effici algorithm solut converg prove versatil approach term class hypothesi loss function demonstr real world classif regress problem reach surpass state art result
learn multipl task deep relationship network deep network train larg scale data learn transfer featur promot learn multipl task deep featur eventu transit general specif along deep network fundament problem exploit relationship across differ task improv featur transfer task specif layer paper propos deep relationship network drn discov task relationship base novel tensor normal prior paramet tensor multipl task specif layer deep convolut network joint learn transfer featur task relationship drn abl allevi dilemma negat transfer featur layer transfer classifi layer extens experi show drn yield state art result standard multi task learn benchmark
label effici learn transfer represent acrosss domain task propos framework learn represent transfer across differ domain task data effici manner approach battl domain shift domain adversari loss general embed novel task use metric learn base approach model simultan optim label sourc data unlabel spars label data target domain method show compel result novel class within new domain even label exampl per class avail outperform preval fine tune approach addit demonstr effect framework transfer learn task imag object recognit video action recognit
match neural path transfer recognit correspond search mani machin learn task requir find per part correspond object work focus low level correspond high ambigu match problem propos use hierarch semant represent object come convolut neural network solv ambigu train low level correspond predict direct might option domain ground truth correspond hard obtain show transfer recognit use avoid train idea mark part match featur close level convolut featur hierarchi neural path although overal number path exponenti number layer propos polynomi algorithm aggreg singl backward pass empir valid done task stereo correspond demonstr achiev competit result among method use label target domain data
deep neural network suffer crowd crowd visual effect suffer human object recogn isol longer recogn object call clutter place close work studi effect crowd artifici deep neural network dnns object recognit analyz deep convolut neural network dcnns well extens dcnns multi scale chang recept field size convolut filter posit imag call eccentr depend model latter network recent propos model feedforward path primat visual cortex result reveal incorpor clutter imag train set learn dnns lead robust clutter seen train also dnns train object isol find recognit accuraci dnns fall closer clutter target object clutter find visual similar target clutter also play role pool earli layer dnn lead crowd final show eccentr depend model train object isol recogn target object clutter object near center imag wherea dcnn cannot
svcca singular vector canon correl analysi deep understand improv continu empir success deep network becom increas import develop better method understand train model represent learn within paper propos singular valu canon correl analysi svcca tool quick compar represent way invari affin transform allow comparison differ layer network fast comput allow comparison calcul previous method deploy tool measur intrins dimension layer show case needless parameter probe learn dynam throughout train find network converg final represent bottom show class specif inform network form suggest new train regim simultan save comput overfit less
neural expect maxim mani real world task reason physic interact requir iden tific manipul conceptu entiti first step toward solv task autom discoveri symbol like represent distribut disentangl paper explicit formal problem infer spatial mixtur model compon parametr neural network base expect maxim framework deriv differenti cluster method simultan learn group repres individu entiti evalu method sequenti perceptu group task find accur abl recov constitu object demonstr learn represent use predict code
pointnet deep hierarch featur learn point set metric space prior work studi deep learn point set pointnet pioneer direct howev design pointnet captur local structur induc metric space point live limit abil recogn fine grain pattern generaliz complex scene work introduc hierarch neural network appli pointnet recurs nest partit input point set exploit metric space distanc network abl learn local featur increas contextu scale observ point set usual sampl vari densiti result great decreas perform network train uniform densiti propos novel set learn layer adapt combin featur multipl scale experi show network call pointnet abl learn deep point set featur effici robust particular result signific better state art obtain challeng benchmark point cloud
preserv proxim global rank node embed investig unsupervis generat approach network embed multi task siames neural network structur formul connect embed vector object preserv global node rank local proxim node provid deeper analysi connect propos proxim object link predict communiti detect network show model satisfi follow design properti scalabl asymmetri uniti simplic experi result verifi design properti also demonstr superior perform learn rank classif regress link predict task
unsupervis transform learn via convex relax goal extract meaning transform data thick line handwrit light portrait raw imag work propos unsupervis approach learn transform base reconstruct nearest neighbor use linear combin transform deriv new algorithm unsupervis linear transform learn handwritten digit celebr portrait dataset show even linear transform method extract meaning transform generat visual high qualiti transform output moreov method semiparametr model data distribut allow learn transform extrapol train data work new type imag
hunt uniqu stabl spars fast featur learn graph purpos learn graph hunt graph represent exhibit certain uniqu stabil sparsiti properti also amen fast comput lead graph represent base discoveri famili graph spectral distanc denot fgsd prove possess desir properti evalu qualiti graph featur produc fgsd demonstr util appli graph classif problem extens experi show simpl svm base classif algorithm driven power fgsd base graph featur signific outperform sophist state art algorithm unlabel node dataset term accuraci speed also yield competit result label dataset despit fact util node label inform
deep subspac cluster network present novel deep neural network architectur unsupervis subspac cluster architectur built upon deep auto encod non linear map input data latent space key idea introduc novel self express layer encod decod mimic self express properti proven effect tradit subspac cluster differenti new self express layer provid simpl effect way learn pairwis affin data point standard back propag procedur nonlinear neural network base method abl cluster data point complex often nonlinear structur propos pre train fine tune strategi let effect learn paramet subspac cluster network experi show propos method signific outperform state art unsupervis subspac cluster method
learn graph embed embed propag propos embed propag unsupervis learn framework graph structur data learn vector represent graph pass type messag neighbor node forward messag consist label represent represent word featur associ node backward messag consist gradient result aggreg represent appli reconstruct loss node represent final comput represent label signific fewer paramet hyperparamet instanc competit often outperform state art unsupervis learn method rang benchmark data set
unsupervis sequenc classif use sequenti output statist consid learn sequenc classifi without label data use sequenti output statist problem high valuabl sinc obtain label train data often cost sequenti output statist languag model could obtain independ input data thus low cost address problem propos unsupervis learn cost function studi properti show compar earlier work less inclin stuck trivial solut avoid need strong generat model although harder optim function form stochast primal dual gradient method develop effect solv problem experi result real world dataset demonstr new unsupervis learn method give drastic lower error baselin method specif reach test error twice obtain fulli supervis learn
context select embed model word embed effect tool analyz languag recent extend model type data beyond text item recommend system embed model consid probabl target observ word item condit element context word item paper show condit element context optim instead improv predict qualiti embed represent model probabl target condit subset element context develop model account use amort variat infer automat choos subset experi demonstr model outperform standard embed method dataset differ domain term held predict qualiti embed represent
probabilist rule realize select abstract realize bilater process key deriv intellig creativ mani domain process approach emph rule high level principl reveal invari within similar yet divers exampl probabilist set discret input space focus rule realize problem generat input sampl distribut follow given rule ambiti beyond mechan realize take whatev given instead ask proactiv select reason rule realiz goal demand practic sinc initi rule set alway consist thus intellig compromis need formul rule realize select strong connect compon within singl symmetr convex problem deriv effici algorithm work larg scale take music composit rule main exampl throughout paper demonstr model effici music realize composit also music interpret understand analysi
trim densiti ratio estim densiti ratio estim becom versatil tool machin learn communiti recent howev due unbound natur densiti ratio estim vulner corrupt data point often push estim ratio toward infin paper present robust estim automat identifi trim outlier propos estim convex formul global optimum obtain via subgradi descent analyz paramet estim error estim high dimension set experi conduct verifi effect estim
minimax optim algorithm crowdsourc consid problem accur estim reliabl worker base noisi label provid fundament question crowdsourc propos novel lower bound minimax estim error appli estim procedur propos triangular estim algorithm estim reliabl worker low complex implement stream set label provid worker real time reli iter procedur prove minimax optim match lower bound conclud assess perform state art algorithm synthet real world data
introspect classif convolut net propos introspect convolut network icn emphas import convolut neural network empow generat capabl employ reclassif synthesi algorithm perform train use formul stem bay theori icn tri iter synthes pseudo negat sampl enhanc improv classif singl cnn classifi learn time generat abl direct synthes new sampl within discrimin model conduct experi benchmark dataset includ mnist cifar svhn use state art cnn architectur observ improv classif result
adapt classif predict budget propos novel adapt approxim approach test time resourc constrain predict given input instanc test time gate function identifi predict model input among collect model object minim overal averag cost without sacrif accuraci learn gate predict model fulli label train data mean bottom strategi novel bottom method first train high accuraci complex model low complex gate predict model subsequ learnt adapt approxim high accuraci model region low cost model capabl make high accur predict pose empir loss minim problem cost constraint joint train gate predict model number benchmark dataset method outperform state art achiev higher accuraci cost
learn featur evolv stream learn stream data attract much attent past year though studi consid data stream fix featur real practic featur evolv exampl featur data gather limit lifespan sensor chang sensor substitut new one paper propos novel learn paradigm featur evolv stream learn old featur would vanish new featur occur rather reli current featur attempt recov vanish featur exploit improv perform specif learn model recov featur current featur respect benefit recov featur develop ensembl method first method combin predict model theoret show assist old featur perform new featur improv second approach dynam select best singl predict establish better perform guarante best model switch experi synthet real data valid effect propos
aggress sampl multi class binari reduct applic text classif address problem multi class classif case number class larg propos doubl sampl strategi top multi class binari reduct strategi transform origin multi class problem binari classif problem pair exampl aim sampl strategi overcom curs long tail class distribut exhibit major larg scale multi class classif problem reduc number pair exampl expand data show strategi alter consist empir risk minim principl defin doubl sampl reduct experi carri dmoz wikipedia collect 000 100 000 class show effici propos approach term train predict time memori consumpt predict perform respect state art approach
adversari surrog loss ordin regress ordin regress seek class label predict penalti incur mistak increas accord order label absolut error canon exampl mani exist method task reduc binari classif problem employ surrog loss hing loss instead deriv uniqu defin surrog ordin regress loss function seek predictor robust worst case approxim train data label subject match certain provid train data statist demonstr advantag approach surrog loss base hing loss approxim use uci ordin predict task
formal guarante robust classifi adversari manipul recent work shown state art classifi quit brittl sens small adversari chang origin high confid correct classifi input lead wrong classif high confid rais concern classifi vulner attack call question usag safeti critic system show paper first time formal guarante robust classifi give instanc specif emph lower bound norm input manipul requir chang classifi decis base analysi propos cross lipschitz regular function show use form regular kernel method resp neural network improv robust classifi without loss predict perform
cost effici gradient boost mani applic requir learn classifi regressor accur cheap evalu predict cost drastic reduc learn predictor construct major input use cheap featur fast evalu main challeng littl loss accuraci work propos budget awar strategi base deep boost regress tree contrast previous approach learn cost penalti method grow deep tree averag nonetheless cheap comput evalu method number dataset find outperform current state art larg margin algorithm easi implement learn time compar origin gradient boost sourc code made avail accept
high effici gradient boost decis tree gradient boost decis tree gbdt popular machin learn algorithm quit effect implement xgboost pgbrt although mani engin optim adopt implement effici scalabl still unsatisfactori featur dimens high data size larg major reason featur need scan data instanc estim inform gain possibl split point time consum tackl problem propos novel techniqu emph gradient base side sampl goss emph exclus featur bundl efb goss exclud signific proport data instanc small gradient use rest estim inform gain prove sinc data instanc larger gradient play import role comput inform gain goss obtain quit accur estim inform gain much smaller data size efb bundl mutual exclus featur rare take nonzero valu simultan reduc number featur prove find optim bundl exclus featur hard greedi algorithm achiev quit good approxim ratio thus effect reduc number featur without hurt accuraci split point determin much call new gbdt implement goss efb emph lightgbm experi multipl public dataset show lightgbm speed train process convent gbdt time achiev almost accuraci
estim accuraci unlabel data probabilist logic approach propos effici method estim accuraci classifi use unlabel data consid set multipl classif problem target class tie togeth logic constraint exampl set class mutual exclus mean data instanc belong propos method base intuit classifi agre like correct classifi make predict violat constraint least classifi must make error experi real world data set produc accuraci estim within percent true accuraci use sole unlabel data model also outperform exist state art solut estim accuraci combin multipl classifi output result emphas util logic constraint estim accuraci thus valid intuit
infer generat model structur static analysi obtain enough label train data complex discrimin model major bottleneck machin learn pipelin popular solut combin multipl sourc weak supervis use generat model structur model affect qualiti train label difficult learn without ground truth label instead reli weak supervis sourc structur virtu encod programmat present coral paradigm infer generat model structur static analyz code heurist thus reduc data requir learn structur signific prove coral sampl complex scale quasilinear number heurist number relat found improv standard sampl complex exponenti identifi degre relat experiment coral match outperform tradit structur learn approach point use coral model depend instead assum independ result perform better fulli supervis model accuraci point heurist use label radiolog data without ground truth label
scalabl model select belief network propos scalabl algorithm model select sigmoid belief network sbns base factor asymptot bayesian fab framework deriv correspond general factor inform criterion gfic sbn proven statist consist margin log likelihood captur depend within hidden variabl sbns recognit network employ model variat distribut result algorithm call fabia simultan execut model select infer maxim lower bound gfic synthet real data experi suggest fabia compar state art algorithm learn sbns
produc concis model thus enabl faster test improv predict perform iii acceler converg prevent overfit
time depend spatial vari graphic model applic brain fmri data analysi spatio tempor data often exhibit nonstationari chang spatial structur often mask strong tempor depend nonsepar work present addit model split data tempor correl signal spatial correl nois model spatial correl portion use time vari gaussian graphic model assumpt smooth chang graphic model structur deriv strong singl sampl converg result confirm abil estim track meaning graphic model evolv time appli methodolog discoveri time vari spatial structur human brain fmri signal
bayesian data augment approach learn deep model data augment essenti part train process appli deep learn model motiv robust train process deep learn model depend larg annot dataset expens acquir store process therefor reason altern abl automat generat new annot train sampl use process known data augment domin data augment approach field assum new train sampl obtain via random geometr appear transform appli annot train sampl strong assumpt unclear reliabl generat model produc new train sampl paper provid novel bayesian formul data augment allow introduc theoret sound algorithm base extens generat adversari network gan new annot train point treat miss variabl generat base distribut learn train set generalis mont carlo expect maximis process classif result mnist cifar cifar 100 show better perform propos method compar current domin data augment approach
union intersect uoi interpret data driven discoveri predict increas size complex scientif data could dramat enhanc discoveri predict basic scientif applic neurosci genet system biolog etc realiz potenti howev requir novel statist analysi method interpret predict introduc union intersect uoi method flexibl modular scalabl framework enhanc model select estim method perform model select model estim intersect union oper respect show uoi satisfi criteria low varianc near unbias estim small number interpret featur maintain high qualiti predict accuraci perform extens numer investig evalu uoi algorithm uoilasso synthet real data demonstr extract interpret function network human electrophysiolog record well accur predict ofphenotyp genotyp phenotyp data reduc featur also show uoil1logist uoicur variant basic framework improv predict parsimoni classif matrix factor sever benchmark biomed data set result suggest method base uoi framework could improv interpret predict data driven discoveri across scientif field
deep learn topolog signatur infer topolog geometr inform data offer altern perspect machin learn problem method topolog data analysi persist homolog enabl obtain inform typic form summari represent topolog featur howev topolog signatur often come unusu structur multiset interv high impract machin learn techniqu mani strategi propos map topolog signatur machin learn compat represent suffer agnost target learn task contrast propos techniqu enabl input topolog signatur deep neural network learn task optim represent train approach realiz novel input layer favor theoret properti classif experi object shape social network graph demonstr versatil approach case latter even outperform state art larg margin
practic hash function similar estim dimension reduct hash basic tool dimension reduct employ sever aspect machin learn howev perfom analysi often carri abstract assumpt truli random unit cost hash function use without concern concret hash function employ concret hash function work fine suffici random input question trust real world face structur input paper focus promin applic hash name similar estim permut hash oph scheme nip featur hash weinberg icml found numer applic approxim near neighbour search lsh classif svm consid recent mix tabul hash function dahlgaard foc prove theoret perform like truli random hash function mani applic includ oph first show improv concentr bound truli random hash argu mix tabul perform similar input vector dens main contribut howev experiment comparison differ hash scheme insid applic find mix tabul hash almost fast classic multipli mod prime scheme mod guarante work well suffici random data demonstr applic lead bias poor concentr real world synthet data also compar popular murmurhash3 proven guarante mix tabul murmurhash3 perform similar truli random hash experi howev mix tabul faster murmurhash3 proven guarante good perform possibl input make reliabl
max rank assumpt pac maximum maximum select max rank element via random pairwis comparison divers applic studi mani model assumpt simpl natur assumpt strong stochast transit show max perform linear mani comparison yet rank requir quadrat mani comparison assumpt show borda score metric maximum select perform linear mani comparison rank perform nlog comparison
kernel function base triplet comparison propos way defin kernel function data set avail inform data set consist similar triplet form object similar object object machin learn problem base restrict inform becom popular recent year previous approach construct low dimension euclidean embed data set reflect given similar triplet aim defin kernel function correspond high dimension embed kernel function subsequ use appli kernel method data set
learn structur optim bipartit graph cluster cluster method wide appli document cluster gene express analysi method make use dualiti featur sampl occur structur sampl featur cluster extract graph base cluster method bipartit graph construct depict relat featur sampl exist cluster method conduct cluster graph achiev origin data matrix explicit cluster structur thus requir post process step obtain cluster result paper propos novel cluster method learn bipartit graph exact connect compon number cluster new bipartit graph learn model approxim origin graph maintain explicit cluster structur immedi get cluster result without post process extens empir result present verifi effect robust model
multi way interact regress via factor machin propos bayesian regress method account multi way interact arbitrari order among predictor variabl model make use factor mechan repres regress coeffici interact among predictor interact select guid prior distribut random hypergraph construct general finit featur model present posterior infer algorithm base gibb sampl establish posterior consist regress model method evalu extens experi simul data demonstr abl identifi meaning interact sever applic genet retail demand forecast
maximum margin interv tree learn regress function use censor interv valu output data import problem field genom medicin goal learn real valu predict function train output label indic interv possibl valu wherea exist algorithm task linear model paper investig learn nonlinear tree model propos learn tree minim margin base discrimin object function provid dynam program algorithm comput optim solut log linear time show empir algorithm achiev state art speed predict accuraci benchmark sever data set
kernel featur select via condit covari minim propos framework featur select employ kernel base measur independ find subset covari maxim predict respons build past work kernel dimens reduct formul approach constrain optim problem involv trace condit covari oper
improv graph laplacian via geometr self consist address problem set kernel bandwidth epp use manifold learn algorithm construct graph laplacian exploit connect manifold geometri repres riemannian metric laplac beltrami oper set epp optim laplacian abil preserv geometri data experi show principl approach effect robust
mixtur rank matrix approxim collabor filter low rank matrix approxim lrma method achiev excel accuraci among today collabor filter method exist lrma method rank user item featur matric typic fix rank adopt describ user item howev studi show submatric differ rank could coexist user item rate matrix approxim fix rank cannot perfect describ intern structur rate matrix therefor lead inferior recommend accuraci paper mixtur rank matrix approxim mrma method propos user item rate character mixtur lrma model differ rank meanwhil learn algorithm capit iter condit mode propos tackl non convex optim problem pertain mrma experiment studi movielen netflix dataset demonstr mrma outperform state art lrma base method term recommend accuraci
predict state recurr neural network present new model call predict state recurr neural network psrnns filter predict dynam system psrnns draw insight recurr neural network rnns predict state represent psrs inherit advantag type model like mani success rnn architectur psrnns use potenti deepli compos bilinear transfer function combin inform multipl sourc sourc act gate anoth bilinear function aris natur connect state updat bay filter like psrs observ view gate belief state show psrnns learn effect combin backpropog time bptt initi base statist consist learn algorithm psrs call stage regress 2sr also show psrnns factor use tensor decomposit reduc model size suggest interest theoret connect exist multipl architectur lstms appli psrnns dataset show outperform sever popular altern approach model dynam system case
hierarch method moment spectral method moment provid power tool learn paramet latent variabl model despit theoret appeal applic method real data still limit due lack robust model misspecif paper present hierarch approach method moment circumv limit method base replac tensor decomposit step use previous algorithm approxim joint diagon experi topic model show method outperform previous tensor decomposit method term speed model qualiti
multitask spectral learn weight automata consid problem estim multipl relat function comput weight automata wfa first present natur notion related wfas consid extent sever wfas share common under represent introduc model vector valu wfa conveni help formal notion related final propos spectral learn algorithm vector valu wfas tackl multitask learn problem joint learn multipl task form vector valu wfa algorithm enforc discoveri represent space share task benefit propos multitask approach theoret motiv showcas experi synthet real world dataset
generat local metric learn kernel regress paper show metric learn use nadaraya watson kernel regress compar standard approach bandwidth select show metric learn signific reduc mean squar error mse kernel regress particular high dimension data propos method effici learn good metric function base upon analyz perform estim gaussian distribut data key featur approach estim learn metric use inform global local structur train data theoret empir result confirm learn metric consider reduc bias mse kernel regress
principl riemannian geometri neural network studi deal neural network sens differenti transform system differenti equat form part attempt construct formal general theori neural network branch riemannian geometri perspect follow theoret result develop proven feedforward network limit number network layer goe infin first shown residu neural network dynam system first order differenti equat oppos ordinari network static impli network learn system differenti equat organ data second shown limit metric tensor residu network converg smooth thus defin riemannian manifold third shown limit backpropag graph converg differenti tensor field result suggest analog einstein general relat particl trajectori geodes curv space time manifold neural network learn curv space layer manifold determin trajectori data move network
subset select sequenti data subset select task find small subset inform item larg ground set find numer applic differ area sequenti data includ time seri order data contain import structur relationship among item impos under dynam model data play vital role select repres howev near exist subset select techniqu ignor under dynam data treat item independ lead incompat set repres paper develop new framework sequenti subset select take advantag under dynam model data promot select set repres high qualiti divers also compat accord under dynam model equip item transit dynam model pose problem integ binari optim assign sequenti item repres lead high encod divers transit potenti propos formul non convex deriv max sum messag pass algorithm solv problem effici experi synthet real data includ instruct video summar motion captur segment show sequenti subset select framework achiev better encod divers state art also success incorpor dynam data lead compat repres
quadrat converg proxim newton algorithm nonconvex spars learn propos proxim newton algorithm solv nonconvex regular spars learn problem high dimens propos algorithm integr proxim newton algorithm multi stage convex relax base differ convex program enjoy strong comput statist guarante specif leverag sophist character spars model structur assumpt local restrict strong convex hessian smooth prove within stage convex relax propos algorithm achiev local quadrat converg eventu obtain spars approxim local optimum optim statist properti convex relax numer experi provid support theori
fast sampl effici algorithm structur phase retriev consid problem recov signal magnitud measur also known phase retriev problem fundament challeng nano bio astronom imag system astronom imag speech process problem ill pose therefor addit assumpt signal measur necessari paper first studi case under signal spars develop novel recoveri algorithm call compress phase retriev altern minim copram algorithm simpl obtain via natur combin classic altern minim approach phase retriev cosamp algorithm spars recoveri despit simplic prove algorithm achiev sampl complex log gaussian sampl match best known exist result also demonstr linear converg theori practic requir extra tune paramet signal sparsiti level consid case under signal aris structur sparsiti model specif examin case block spars signal uniform block size block sparsiti problem design recoveri algorithm call block copram reduc sampl complex log suffici larg block length theta bound equat log knowledg constitut first end end linear converg algorithm phase retriev gaussian sampl complex sub quadrat depend sparsiti level signal
support order weight sparsiti overlap group hard algorithm support owl norm general norm provid better predict accuraci better handl correl variabl studi norm obtain extend support norm owl norm set overlap group result norm general hard comput tractabl certain collect group demonstr fact develop dynam program problem project onto set vector support fix number group dynam program util tree decomposit complex scale treewidth program convert extend formul associ group structur model group support norm overlap group variant order weight norm numer result demonstr efficaci new penalti
parametr simplex method spars learn high dimension spars learn impos great comput challeng larg scale data analysi paper investiag broad class spars learn approach formul linear program parametr regular factor solv parametr simplex method psm psm offer signific advantag compet method psm natur obtain complet solut path valu regular paramet psm provid high precis dual certif stop criterion psm yield spars solut iter solut sparsiti signific reduc comput cost per iter particular demonstr superior psm various spars learn approach includ dantzig selector spars linear regress spars support vector machin spars linear classif spars differenti network estim provid suffici condit psm alway output spars solut comput perform signific boost thorough numer experi provid demonstr outstand perform psm method
learn amp principl neural network base compress imag recoveri compress imag recoveri challeng problem requir fast accur algorithm recent neural network appli problem promis result exploit massiv parallel gpu process architectur oodl train data abl run order magnitud faster exist techniqu unfortun method difficult train often time specif singl measur matrix larg unprincipl blackbox recent demonstr iter spars signal recoveri algorithm unrol form interpret deep neural network take inspir work develop novel neural network architectur mimic behavior denois base approxim messag pass amp algorithm call new network learn amp ldamp ldamp network easi train appli varieti differ measur matric come state evolut heurist accur predict perform import network outperform state art bm3d amp nlr algorithm term accuraci runtim high resolut use matric fast matrix multipli implement ldamp run faster bm3d amp hundr time faster nlr
falkon optim larg scale kernel method kernel method provid principl way perform non linear nonparametr learn reli solid function analyt foundat enjoy optim statist properti howev least basic form limit applic larg scale scenario stringent comput requir term time especi memori paper take substanti step scale kernel method propos falkon novel algorithm allow effici process million point falkon deriv combin sever algorithm principl name stochast subsampl iter solver precondit theoret analysi show optim statist accuraci achiev requir essenti
memori time extens experi show state art result avail larg scale dataset achiev even singl machin
recurs sampl nystrom method give first algorithm kernel nystrom approxim run linear time number train point provabl accur kernel matric without depend regular incoher condit algorithm project kernel onto set landmark point sampl ridg leverag score requir kernel evalu addit runtim leverag score sampl long known give strong theoret guarante nystrom approxim employ fast recurs sampl scheme algorithm first make approach scalabl empir show find accur kernel approxim less time popular techniqu classic nystrom approxim random fourier featur method
effici approxim algorithm string kernel base sequenc classif sequenc classif algorithm svm requir definit distanc similar measur sequenc common use notion similar number match mer length subsequ sequenc extend definit consid mer match distanc yield better classif perform howev make problem comput much complex known algorithm comput similar comput complex render applic small valu work develop novel techniqu effici accur estim pairwis similar score enabl use much larger valu get higher predict accuraci open broad avenu appli classif approach audio imag text sequenc algorithm achiev excel approxim perform theoret guarante process solv open combinatori problem pose major hindranc scalabl exist solut give analyt bound qualiti runtim algorithm report empir perform real world biolog music sequenc dataset
robust hypothesi test function effect gaussian process work construct hypothesi test detect whether data generat function realp real belong specif reproduc kernel hilbert space structur partial known util theori reproduc kernel reduc hypothesi simpl side score test scalar paramet develop test procedur robust mis specif kernel function also propos ensembl base estim null model guarante test perform small sampl demonstr util propos method appli test problem detect nonlinear interact group continu featur evalu finit sampl perform test differ data generat function estim strategi null model result reveal interest connect notion machin learn model underfit overfit statist infer type error power hypothesi test also highlight unexpect consequ common model estim strategi estim kernel hyperparamet use maximum likelihood estim model infer
invari stabil deep convolut represent paper studi deep signal represent near invari group transform stabl action diffeomorph without lose signal inform achiev general multilay kernel introduc context convolut kernel network studi geometri correspond reproduc kernel hilbert space show signal represent stabl model function space larg class convolut neural network enjoy stabil
test learn distribut symmetr nois invari kernel embed distribut maximum mean discrep mmd result distanc distribut use tool fulli nonparametr sampl test learn distribut howev rare possibl differ sampl interest discov differ due differ type measur nois data collect artefact irrelev sourc variabl propos distanc distribut encod invari addit symmetr nois aim test whether assum true under process differ moreov construct invari featur distribut lead learn algorithm robust impair input distribut symmetr addit nois
empir studi properti random base kernel method kernel machin neural network possess univers function approxim properti nevertheless practic way choos appropri function class differ thus limit usag emerg specif neural network learn represent adapt basi function data task kernel method typic use kernel adapt width rbf kernel chang anymor contribut work contrast neural network kernel method empir studi analysi reveal random adapt base affect qualiti learn furthermor present kernel basi adapt scheme make effici usag featur retain univers properti
max margin invari featur transform unlabel data studi represent invari common transform data import learn techniqu focus local approxim invari implement within expens optim framework lack explicit theoret guarante paper studi kernel invari unitari group theoret guarante address import practic issu unavail transform version label data problem call unlabel transform problem special form semi supervis learn shot learn present theoret motiv altern approach invari kernel svm base propos max margin invari featur mmif solv problem illustr design framework face recognit demonstr efficaci approach larg scale semi synthet dataset 153 000 imag new challeng protocol label face wild lfw perform strong baselin
safetynet verifi execut deep neural network untrust cloud infer use deep neural network often outsourc cloud sinc comput demand task howev rais fundament issu trust client sure cloud perform infer correct lazi cloud provid might use simpler less accur model reduc comput load wors malici modifi infer result sent client propos safetynet framework enabl untrust server cloud provid client short mathemat proof correct infer task perform behalf client specif safetynet develop implement special interact proof protocol verifi execut class deep neural network repres arithmet circuit empir result layer deep neural network demonstr run time cost safetynet client server low safetynet detect incorrect comput neural network untrust server high probabl achiev state art accuraci mnist digit recognit timit speech recognit task
multi output polynomi network factor machin factor machin polynomi network supervis polynomi model base effici low rank decomposit extend model multi output set learn vector valu function applic multi class multi task problem cast problem learn way tensor whose slice share common decomposit propos convex formul problem develop effici condit gradient algorithm prove global converg despit fact involv non convex hidden unit select step classif task show algorithm achiev excel accuraci much sparser model exist method recommend system task show combin algorithm reduct ordin regress multi output classif show result algorithm outperform exist baselin term rank accuraci
neural hawk process neural self modul multivari point process mani event occur world event type stochast excit inhibit sens probabl elev decreas pattern sequenc previous event discov pattern help predict type event happen next propos model stream discret event continu time construct neural self modul multivari point process intens multipl event type evolv accord novel continu time lstm generat model allow past event influenc futur complex realist way condit futur event intens hidden state recurr neural network consum stream past event model desir qualit properti achiev competit likelihood predict accuraci real synthet dataset includ miss data condit
maxim spread influenc train data consid canon problem influenc maxim social network sinc semin work kempt kleinberg tardo larg disjoint effort problem first studi problem associ learn generat model produc cascad second focus algorithm challeng identifi set influenc assum generat model known recent result learn optim impli general generat model known rather learn train data algorithm influenc maxim yield constant factor approxim guarante use polynomi mani sampl drawn distribut paper describ simpl algorithm maxim influenc train data main idea behind algorithm leverag strong communiti structur social network identifi set individu influenti whose communiti littl overlap although general approxim guarante algorithm unbound show algorithm perform well experiment analyz perform prove algorithm obtain constant factor approxim guarante graph generat stochast block model tradit use model network communiti structur
induct represent learn larg graph low dimension embed node larg graph prove extrem use varieti predict task content recommend identifi protein function howev exist approach requir node graph present train embed previous approach inher transduct natur general unseen node present graphsag general induct framework leverag node featur inform text attribut effici generat node embed instead train individu embed node learn function generat embed sampl aggreg featur node local neighborhood algorithm outperform strong baselin induct node classif benchmark classifi categori unseen node evolv inform graph base citat reddit post data show algorithm general complet unseen graph use multi graph dataset protein protein interact
meta learn perspect cold start recommend item matrix factor popular techniqu product recommend known suffer serious cold start problem item cold start problem particular acut set tweet recommend new item arriv continu paper present meta learn strategi address item cold start new item arriv continu propos deep neural network architectur implement meta learn strategi first architectur learn linear classifi whose weight determin item histori second architectur learn neural network whose bias instead adapt base item histori evalu techniqu real world problem tweet recommend product data twitter demonstr propos techniqu signific beat baselin lookup tabl base user embed also outperform state art product model tweet recommend
dropoutnet address cold start recommend system latent model becom default choic recommend system due perform scalabl howev research area primarili focus model user item interact latent model develop cold start deep learn recent achiev remark success show excel result divers input type inspir result propos neural network base latent model handl cold start recommend system unlik exist approach incorpor addit content base object term instead focus learn show neural network model explicit train handl cold start dropout model train top exist latent model effect provid cold start capabl full power deep architectur empir demonstr state art accuraci public avail benchmark
feder multi task learn feder learn pose new statist system challeng train machin learn model distribut network devic work show multi task learn natur suit handl statist challeng set propos novel system awar optim method mocha robust practic system issu method theori first time consid issu high communic cost straggler fault toler distribut multi task learn result method achiev signific speedup compar altern feder set demonstr extens simul real world feder dataset
flexpoint adapt numer format effici train deep neural network deep neural network common develop train bit float point format signific gain perform energi effici could realiz train infer numer format optim deep learn despit substanti advanc limit precis infer recent year train neural network low bit width remain challeng problem present flexpoint data format aim complet replac bit float point format train infer design support deep network topolog without modif flexpoint tensor share expon dynam adjust minim overflow maxim avail dynam rang valid flexpoint train alexnet deep residu network generat adversari network use simul implement emph neon deep learn framework demonstr bit flexpoint close match bit float point train model without need tune model hyper paramet result suggest flexpoint promis numer format futur hardwar train infer
bayesian infer individu treatment effect use multi task gaussian process predic increas abund electron health record investig problem infer individu treatment effect use observ data stem potenti outcom model propos novel multi task learn framework factual counterfactu outcom model output function vector valu reproduc kernel hilbert space vvrkhs develop nonparametr bayesian method learn treatment effect use multi task gaussian process linear coregion kernel prior vvrkhs bayesian approach allow comput individu measur confid estim via pointwis credibl interv crucial realiz full potenti precis medicin impact select bias allevi via risk base empir bay method adapt multi task prior joint minim empir error factual outcom uncertainti unobserv counterfactu outcom conduct experi observ dataset intervent social program appli prematur infant left ventricular assist devic appli cardiac patient wait list heart transplant experi show method signific outperform state art
tomographi london underground scalabl model origin destin data paper address classic network tomographi problem infer local traffic given origin destin observ focuss larg complex public transport system build scalabl model exploit input output inform estim unobserv link station load user path prefer base reconstruct user travel time distribut model flexibl enough captur possibl differ path choic strategi correl user travel similar path similar time correspond likelihood function intract medium larg scale network propos distinct strategi name exact maximum likelihood infer approxim tractabl model variat infer origin intract model applic approach consid emblemat case london underground network tap tap system track start exit time locat journey day set synthet simul real data provid transport london use valid test model predict observ unobserv quantiti
match balanc nonlinear represent treatment effect estim estim treatment effect observ data challeng problem due miss counterfactu match effect strategi tackl problem wide use match estim nearest neighbor match nnm pair treat unit similar control unit term covari estim treatment effect accord howev exist match estim poor perform distribut control treatment group unbalanc moreov theoret analysi suggest bias causal effect estim would increas dimens covari paper aim address problem learn low dimension balanc nonlinear represent bnr observ data particular convert counterfactu predict classif problem develop kernel learn model domain adapt constraint design novel match estim dimens covari signific reduc project data low dimension subspac experi sever synthet real world dataset demonstr effect approach
moleculenet continu filter convolut neural network model quantum interact deep learn potenti revolution quantum chemistri ideal suit learn represent structur data speed explor chemic space convolut neural network proven first choic imag audio video data atom molecul restrict grid instead precis locat contain essenti physic inform would get lost discret thus propos use textit continu filter convolut layer abl model local correl without requir data lie grid appli layer moleculenet novel deep learn architectur model quantum interact molecul obtain joint model total energi interatom forc follow fundament quantum chemic principl includ rotate invari energi predict smooth differenti potenti energi surfac architectur achiev state art perform benchmark equilibrium molecul molecular dynam trajectori final introduc challeng benchmark chemic structur variat suggest path work
hide imag plain sight deep steganographi steganographi practic conceal secret messag within anoth ordinari messag common steganographi use unobtrus hide small messag within noisi region larger imag studi attempt place full size color imag within anoth imag size deep neural network simultan train creat hide reveal process design specif work pair system train imag drawn random imagenet databas work well natur imag wide varieti sourc beyond demonstr success applic deep learn hide imag care examin result achiev explor extens unlik mani popular steganograph method encod secret messag within least signific bit carrier imag approach compress distribut secret imag represent across avail bit
univers style transfer via featur transform univers style transfer aim transfer arbitrari visual style content imag exist feed forward base method enjoy infer effici main limit inabl general unseen style compromis visual qualiti paper present simpl yet effect method tackl limit without train pre defin style key ingredi method pair featur transform whiten color embed imag reconstruct network whiten color transform reflect direct match featur covari content imag given style imag share similar spirit optim gram matrix base cost neural style transfer demonstr effect algorithm generat high qualiti styliz imag comparison number recent method also analyz method visual whiten featur synthes textur simpl featur color
attend predict understand gene regul select attent chromatin past decad seen revolut genom technolog enabl flood genom wide profil chromatin mark recent literatur tri understand gene regul predict gene express larg scale chromatin measur fundament challeng exist learn task genom wide chromatin signal spatial structur high dimension high modular core aim understand relev factor work togeth previous studi either fail model complex depend among input signal reli separ featur analysi explain decis paper present attent base deep learn approach call chromattent use unifi architectur model interpret depend among chromatin factor control gene regul chromattent use hierarchi multipl long short term memori lstm modul encod input signal model various chromatin mark cooper automat chromattent train level attent joint target predict enabl attend differenti relev mark locat import posit per mark evalu model across differ cell type task human propos architectur accur attent score also provid better interpret state art featur visual method salienc map
unbound cach model onlin languag model open vocabulari propos extens recurr network languag model adapt predict chang data distribut associ non parametr larg scale memori compon store hidden activ seen past approach seen unbound continu cach make use modern approxim search quantize algorithm store million represent search effici show approach help adapt pretrain neural network novel data distribut tackl call rare word problem
deconvolut paragraph represent learn learn latent represent long text sequenc import first step mani natur languag process applic recurr neural network rnns becom cornerston challeng task howev qualiti sentenc rnn base decod reconstruct decreas length text propos sequenc sequenc pure convolut deconvolut autoencod framework free issu also comput effici propos method simpl easi implement leverag build block mani applic show empir compar rnns framework better reconstruct correct long paragraph quantit evalu semi supervis text classif summar task demonstr potenti better util long unlabel text data
analyz hidden represent end end automat speech recognit system neural model becom ubiquit automat speech recognit system neural network typic use acoust model complex system recent studi explor end end speech recognit system base neural network train direct predict text input acoust featur although system conceptu eleg simpler tradit system less obvious interpret train model work analyz speech represent learn deep end end model base convolut recurr layer train connectionist tempor classif ctc loss use pre train model generat frame level featur given classifi train frame classif phone evalu represent differ layer deep model compar qualiti predict phone label experi shed light import aspect end end model layer depth model complex design choic
best world transfer knowledg discrimin learn generat visual dialog model present novel train framework neural sequenc model particular ground dialog generat standard train paradigm model maximum likelihood estim mle minim cross entropi human respons across varieti domain recur problem mle train generat neural dialog model tend produc safe generic respons like know tell contrast discrimin dialog model train rank list candid human respons outperform generat counterpart term automat metric divers inform respons howev use practic sinc deploy real convers user work aim achiev best world practic use strong perform via knowledg transfer primari contribut end end trainabl generat visual dialog model receiv gradient perceptu adversari loss sequenc sampl leverag recent propos gumbel softmax approxim discret distribut specif rnn augment sequenc sampler coupl straight gradient estim enabl end end differenti also introduc stronger encod visual dialog employ self attent mechan answer encod along metric learn loss aid better captur semant similar answer respons overal propos model outperform state art visdial dataset signific margin recal
teach machin describ imag natur languag feedback robot eventu part everi household thus critic enabl algorithm learn guid non expert user paper bring human loop enabl human teacher give feedback learn agent form natur languag descript sentenc provid stronger learn signal numer reward easili point mistak correct focus problem imag caption qualiti output easili judg non expert propos phrase base caption model train polici gradient design critic provid reward learner condit human provid feedback show exploit descript feedback model learn perform better given independ written human caption
high order attent model visual question answer quest algorithm enabl cognit abil import part machin learn common trait recent cognit like task take account differ data modal visual lingual paper propos novel general applic form attent mechan learn high order correl various data modal show high order correl effect direct appropri attent relev element differ data modal requir solv joint task demonstr effect high order attent mechan task visual question answer vqa achiev state art perform standard vqa dataset
visual refer resolut use attent memori visual dialog visual dialog task answer seri inter depend question given input imag often requir resolv visual refer among question problem differ visual question answer vqa reli spatial attent visual ground estim imag question pair propos novel attent mechan exploit visual attent past resolv current refer visual dialog scenario propos model equip associ attent memori store sequenc previous attent key pair memori model retriev previous attent take account recenc relev current question order resolv potenti ambigu refer model merg retriev attent tentat obtain final attent current question specif use dynam paramet predict combin attent condit question extens experi new synthet visual dialog dataset show model signific outperform state art point situat visual refer resolut play import role moreov propos model present superior perform point improv visual dialog dataset despit signific fewer paramet baselin
semi supervis learn optic flow generat adversari network convolut neural network cnns recent appli optic flow estim problem train cnns requir suffici larg ground truth train data exist approach resort synthet unrealist dataset hand unsupervis method capabl leverag real world video train ground truth flow field avail method howev reli fundament assumpt bright constanc spatial smooth prior hold near motion boundari paper propos exploit unlabel video semi supervis learn optic flow generat adversari network key insight adversari loss captur structur pattern flow warp error without make explicit assumpt extens experi benchmark dataset demonstr propos semi supervis algorithm perform favor pure supervis semi supervis learn scheme
associ embed end end learn joint detect group introduc associ embed novel method supervis convolut neural network task detect group number comput vision problem frame manner includ multi person pose estim instanc segment multi object track usual group detect achiev multi stage pipelin instead propos approach teach network simultan output detect group assign techniqu easili integr state art network architectur produc pixel wise predict show appli method multi person pose estim report state art perform multi person pose mpii dataset coco dataset
learn deep structur multi scale featur use attent gate crfs contour predict recent work shown exploit multi scale represent deepli learn via convolut neural network cnn tremend import accur contour detect paper present novel approach predict contour advanc state art fundament aspect multi scale featur generat fusion differ previous work direct consid multi scale featur map obtain inner layer primari cnn architectur introduc hierarch deep model produc rich complementari represent furthermor refin robust fuse represent learn differ scale novel attent gate condit random field crfs propos experi ran public avail dataset bsds500 nyudv2 demonstr effect latent crf model overal hierarch framework
incorpor side inform adapt convolut comput vision task often side inform avail help solv task exampl crowd count camera perspect camera angl height give clue appear scale peopl scene side inform shown use count system use tradit hand craft featur fulli util count system base deep learn order incorpor avail side inform propos adapt convolut neural network acnn convolut filter weight adapt current scene context via side inform particular model filter weight low dimension manifold within high dimension space filter weight filter weight generat use learn filter manifold sub network whose input side inform help side inform adapt weight acnn disentangl variat relat side inform extract discrimin featur relat current context camera perspect nois level blur kernel paramet demonstr effect acnn incorpor side inform task crowd count corrupt digit recognit imag deblur experi show acnn improv perform compar plain cnn similar number paramet sinc exist crowd count dataset contain ground truth side inform collect new dataset ground truth camera angl height side inform
learn multi view stereo machin show learn multi view stereopsi system contrast recent learn base method reconstruct leverag under geometri problem featur project unproject along view ray formul oper differenti manner abl learn system end end task metric reconstruct end end learn allow util prior object shape enabl reconstruct object much fewer imag even singl imag requir classic approach well complet unseen surfac thorough evalu approach shapenet dataset demonstr benefit classic approach recent learn base method
pose guid person imag generat paper propos novel pose guid person generat network allow synthes person imag arbitrari pose base imag person novel pose generat framework util pose inform explicit consist key stage coars structur generat detail appear refin first stage condit imag target pose fed net like network generat initi coars imag person target pose second stage refin initi blurri result base autoencod conjunct discrimin adversari way extens experiment result 12864 identif imag 256256 fashion photo show model generat high qualiti person imag convinc detail
work hard know neighbor margin local descriptor learn loss introduc novel loss learn local featur descriptor inspir sift match scheme show propos loss reli maxim distanc closest posit closest negat patch could replac complex regular method use local descriptor learn work well shallow deep convolut network architectur result descriptor compact dimension sift 128 show state art perform match patch verif retriev benchmark fast comput gpu
multimod imag imag translat enforc cycl consist mani imag imag translat problem ambigu singl input imag correspond multipl possibl output work aim model distribut possibl output condit generat model set ambigu map encod low dimension latent vector random sampl test time generat learn map input along latent code output explicit enforc cycl consist latent code output encourag invert help prevent mani map latent code output train also known problem mode collaps help produc divers result evalu relationship perceptu realism divers imag generat method test varieti domain
deep supervis discret hash rapid growth imag video data web hash extens studi imag video search recent year benefit recent advanc deep learn deep hash method achiev promis result imag retriev howev limit previous deep hash method semant inform fulli exploit paper develop deep supervis discret hash algorithm base assumpt learn binari code ideal classif pairwis label inform classif inform use learn hash code within stream framework constrain output last layer binari code direct rare investig deep hash algorithm discret natur hash code altern minim method use optim object function experiment result shown method outperform current state art method benchmark dataset
svd softmax fast softmax approxim larg vocabulari neural network propos fast approxim method softmax function larg vocabulari use singular valu decomposit svd svd softmax target fast accur probabl estim topmost probabl word infer recurr neural network languag model propos method transform weight matrix use calcul logit use svd approxim probabl word estim fraction svd transform matrix appli techniqu languag model neural machin translat present guidelin good approxim algorithm requir arithmet oper 800k vocabulari case show speedup gpu
hash embed effici word represent present hash embed effici method repres word continu vector form hash embed seen interpol standard word embed word embed creat use random hash function hash trick hash embed token repres dimension embed vector dimension weight vector final dimension represent token product rather fit embed vector token select hash trick share pool embed vector experi show hash embed easili deal huge vocabulari consist million token use hash embed need creat dictionari train perform kind vocabulari prune train show model train use hash embed exhibit least level perform model train use regular embed across wide rang task furthermor number paramet need embed fraction requir regular embed sinc standard embed embed construct use hash trick actual special case hash embed hash embed consid extens improv exist regular embed type
regular framework spars structur neural attent modern neural network often augment attent mechan tell network focus within input propos paper new framework spars structur attent build upon max oper regular strong convex function show oper differenti gradient defin map real valu probabl suitabl attent mechan framework includ softmax slight general recent propos sparsemax special case howev also show framework incorpor modern structur penalti result new attent mechan focus entir segment group input encourag parsimoni interpret deriv effici algorithm comput forward backward pass attent mechan enabl use neural network train backpropag showcas potenti drop replac exist attent mechan evalu larg scale task textual entail machin translat sentenc summar attent mechan improv interpret without sacrif perform notabl textual entail summar outperform exist attent mechan base softmax sparsemax
attent pool action recognit introduc simpl yet surpris power model incorpor attent action recognit human object interact task propos attent modul train without extra supervis give sizabl boost accuraci keep network size comput cost near lead signific improv state art base architectur standard action recognit benchmark across still imag video establish new state art mpii relat improv hmdb rgb dataset also perform extens analysi attent modul empir analyt term latter introduc novel deriv bottom top attent low rank approxim bilinear pool method typic use fine grain classif perspect attent formul suggest novel character action recognit fine grain recognit problem
plan attend generat plan sequenc sequenc model investig integr plan mechan encod decod architectur attent present model plan ahead comput align input output sequenc construct matrix propos futur align commit vector govern whether follow recomput plan mechan inspir strateg attent reader writer straw model propos model end end trainabl fulli differenti oper show outperform strong baselin charact level translat task wmt algorithm task find eulerian circuit graph among other analysi demonstr model comput qualit intuit align converg faster baselin achiev superior perform fewer paramet
dilat recurr neural network notori learn recurr neural network rnns long sequenc difficult task major challeng extract complex depend vanish explod gradient effici parallel paper introduc simpl yet effect rnn connect structur dilatedrnn simultan tackl challeng propos architectur character multi resolut dilat recurr skip connect combin flexibl differ rnn cell moreov dilatedrnn reduc number paramet enhanc train effici signific match state art perform even vanilla rnn cell task involv long term depend provid theori base quantif architectur advantag introduc memori capac measur mean recurr length suitabl rnns long skip connect exist measur rigor prove advantag dilatedrnn recurr neural architectur
thalamus gate recurr modul propos deep learn model inspir neurosci theori communic within neocortex model consist recurr modul send featur via rout center endow neural modul flexibl share featur multipl time step show model learn rout inform hierarch process input data chain modul observ common architectur feed forward neural network skip connect emerg special case architectur novel connect pattern learn text8 compress task model outperform multi layer recurr network sequenti task
wasserstein learn deep generat point process model point process becom popular model asynchron sequenti data due sound mathemat foundat strength model varieti real world phenomena current often character via intens function limit model express due unrealist assumpt parametr form use practic furthermor learn via maximum likelihood approach prone failur multi modal distribut sequenc paper propos intens free approach point process model transform nuisanc process target furthermor train model use likelihood free leverag wasserstein distanc point process experi various synthet real world data substanti superior propos point process model convent one
stabil train generat adversari network regular deep generat model base generat adversari network gan demonstr impress sampl qualiti order work requir care choic architectur paramet initi select hyper paramet fragil part due dimension mismatch model distribut true distribut caus densiti ratio associ diverg undefin overcom fundament limit propos new regular approach low comput cost yield stabl gan train procedur demonstr effect approach sever dataset includ common benchmark imag generat task approach turn gan model reliabl build block deep learn
neural variat infer learn undirect graphic model mani problem machin learn natur express languag undirect graphic model propos learn infer algorithm undirect model optim variat approxim log likelihood model central approach upper bound log partit function parametr function express flexibl neural network bound enabl accur track partit function learn speed sampl train broad class power hybrid direct undirect model via unifi variat infer framework empir demonstr effect method sever popular generat model dataset
adversari symmetr variat autoencod new form variat autoencod vae develop joint distribut data code consid symmetr form observ data fed encod yield code latent code drawn simpl prior propag decod manifest data lower bound learn margin log likelihood fit observ data latent code learn variat bound seek minim symmetr kullback leibler diverg joint densiti function simultan seek maxim margin log likelihood facilit learn new form adversari train develop extens set experi perform demonstr state art data reconstruct generat sever imag benchmark dataset
divers accur imag descript use variat auto encod addit gaussian encod space paper propos method generat imag descript use condit variat auto encod cvae data depend gaussian prior encod space standard cvae fix gaussian prior easili collaps generat descript littl variabl approach address problem linear combin multipl gaussian prior base semant content imag increas flexibl represent power generat model evalu addit gaussian cvae cvae approach mscoco dataset show produc caption divers accur strong lstm baselin cvae variant
forc train stochast recurr network mani effort devot incorpor stochast latent variabl sequenti neural model recurr neural network rnns rnns latent variabl success captur variabl observ natur structur data speech work propos novel recurr latent variabl model unifi success idea recent propos architectur model step sequenc associ latent variabl use condit recurr dynam futur step model train amortis variat infer infer network augment rnn run backward sequenc addit next step predict add auxiliari cost latent variabl forc reconstruct state backward recurr network provid latent variabl task independ object enhanc perform overal model although conceptu simpl model achiev state art result standard speech benchmark timit blizzard final appli model languag model imdb dataset auxiliari cost crucial learn interpret latent variabl set show regular evid lower bound signific underestim log likelihood model thus encourag futur work compar likelihood method use tighter bound
shot imit learn imit learn common appli solv differ task isol usual requir either care featur engin signific number sampl far desir ideal robot abl learn demonstr given task instant general new situat task without requir task specif engin paper propos meta learn framework achiev capabl call shot imit learn specif consid set larg mayb infinit set task task mani instanti exampl task could stack block tabl singl tower anoth task could place block tabl block tower etc case differ instanc task would consist differ set block differ initi state train time algorithm present pair demonstr subset task neural net train take input demonstr current state initi initi state demonstr pair output action goal result sequenc state action match close possibl second demonstr test time demonstr singl instanc new task present neural net expect perform well new instanc new task experi show use soft attent allow model general condit task unseen train data anticip train model much greater varieti task set obtain general system turn demonstr robust polici accomplish overwhelm varieti task
reconstruct crush network articl introduc energi base model adversari regard data minim energi given data distribut posit sampl maxim energi anoth given data distribut negat unlabel sampl model especi instanti autoencod energi repres reconstruct error provid general distanc measur unknown data result neural network thus learn reconstruct data first distribut crush data second distribut solut handl differ problem posit unlabel learn covari shift especi imbalanc data use autoencod allow handl larg varieti data imag text even dialogu experi show flexibl propos approach deal differ type data differ set imag cifar cifar 100 train set text amazon review learn dialogu facebook babi next respons classif dialogu complet
fader network generat imag variat slide attribut valu paper introduc new encod decod architectur train reconstruct imag disentangl salient inform imag valu attribut direct latent space result train model generat differ realist version input imag vari attribut valu use continu attribut valu choos much specif attribut perceiv generat imag properti could allow applic user modifi imag use slide knob like fader mix consol chang facial express portrait updat color object compar state art most reli train adversari network pixel space alter attribut valu train time approach result much simpler train scheme nice scale multipl attribut present evid model signific chang perceiv valu attribut preserv natur imag
predrnn recurr neural network video predict use spatiotempor lstms predict learn video sequenc aim generat futur imag learn histor frame spatial appear tempor variat crucial structur paper model structur present predict recurr neural network predrnn architectur enlighten idea video predict system memor spatial appear tempor variat unifi memori pool concret memori state longer constrain insid lstm unit instead allow zigzag direct across stack rnn layer vertic time step horizont core network new spatiotempor lstm lstm unit extract memor spatial tempor video represent simultan predrnn achiev state art predict perform standard video dataset believ general framework extend predict learn task beyond video predict
multi agent predict model attent commnet multi agent predict model essenti step understand physic social team play system recent interact network in propos task model multi agent physic system in scale number interact system typic quadrat higher order number agent paper introduc vain attent commnet multi agent predict model scale linear number agent show vain effect multi agent predict model represent learn transfer learn new data poor task method evalu task challeng multi agent predict domain chess soccer outperform compet multi agent approach
real time imag salienc black box classifi work develop fast salienc detect method appli differenti imag classifi train mask model manipul score classifi mask salient part input imag model generalis well unseen imag requir singl forward pass perform salienc detect therefor suitabl use real time system test approach cifar imagenet dataset show produc salienc map easili interpret sharp free artifact suggest new metric salienc test method imagenet object localis task achiev result outperform weak supervis method
prototyp network shot learn propos prototyp network problem shot classif classifi must general new class seen train set given small number exampl new class prototyp network learn metric space classif perform comput distanc prototyp represent class compar recent approach shot learn reflect simpler induct bias benefici limit data regim achiev excel result provid analysi show simpl design decis yield substanti improv recent approach involv complic architectur choic meta learn extend prototyp network shot learn achiev state art result bird dataset
shot learn inform retriev len shot learn refer understand new concept exampl propos inform retriev inspir approach problem motiv increas import maxim leverag avail inform low data regim defin train object aim extract much inform possibl train batch effect optim relat order batch point simultan particular view batch point queri rank remain one base predict relev defin model framework structur predict optim mean averag precis rank method produc state art result standard benchmark shot learn
revers residu network backpropag without store activ residu network resnet demonstr signific improv tradit convolut neural network cnns imag classif increas perform network grow deeper wider howev memori consumpt becom bottleneck need store intermedi activ calcul gradient use backpropag work present revers residu network revnet variant resnet layer activ reconstruct exact next layer therefor activ layer need store memori backprop demonstr effect revnet cifar imagenet establish near ident perform equal size resnet activ storag requir independ depth
gate recurr convolut neural network ocr optic charact recognit ocr aim recogn text natur imag wide research comput vision communiti paper present new architectur name gate recurr convolut layer grcl challeng grcl construct ad gate recurr convolut layer rcl find equip gate control context modul rcl balanc feed forward compon well recurr compon addit build bidirect long short term memori blstm sequenc model test sever variant blstm find suitabl architectur ocr final combin gate recurr convolut neural network grcnn blstm recogn text natur imag grcnn blstm train end end outperform benchmark dataset term state art result includ iiit street view text svt icdar
learn effici object detect model knowledg distil despit signific accuraci improv convolut neural network cnn base object detector often requir prohibit runtim process imag real time applic state art model often use deep network larg number float point oper effort model compress learn compact model fewer number paramet much reduc accuraci work propos new framework learn compact fast object detect network improv accuraci use knowledg distil hint learn although knowledg distil demonstr excel improv simpler classif setup complex detect pose new challeng form regress region propos less volumin label address sever innov weight cross entropi loss address class imbal teacher bound loss handl regress compon adapt layer better learn intermedi teacher distribut conduct comprehens empir evalu differ distil configur multipl dataset includ pascal kitti ilsvrc coco result show consist improv accuraci speed trade off modern multi class detect model
activ bias train accur neural network emphas high varianc sampl self pace learn hard exampl mine weight train instanc improv learn accuraci paper present improv altern base lightweight estim sampl uncertainti stochast gradient descent sgd varianc predict probabl correct class across iter mini batch sgd proxim correct class probabl decis threshold extens experiment result dataset show method reliabl improv accuraci various network architectur includ addit gain top popular train techniqu residu learn momentum adam batch normal dropout distil
decoupl updat updat deep learn requir data use approach obtain data creativ mine data various sourc creat differ purpos unfortun approach often lead noisi label paper propos meta algorithm tackl noisi label problem key idea decoupl updat fromhow updat demonstr effect algorithm mine data gender classif combin label face wild lfw face recognit dataset textual gender servic lead noisi dataset approach simpl implement lead state art result analyz converg properti propos algorithm
langevin dynam continu temper train deep neural network minim non convex high dimension object function challeng especi train modern deep neural network paper novel approach propos divid train process consecut phase obtain better general perform bayesian sampl stochast optim first phase explor energi landscap captur fat mode thesecondo etu theparamet domthefirstphas inthebayesian arn gphase weapplycont uoustemp gand imat othelan dynam createanefficientandeffectivesamp whichthetemperatureisadjustedau maticallyaord thedesig temperatur dynam strategi overcom challeng earli trap bad local minima achiev remark improv various type neural network shown theoret analysi empir experi
differenti learn logic rule knowledg base reason studi problem learn probabilist first order logic rule knowledg base reason learn problem difficult requir learn paramet continu space well structur discret space propos framework neural logic program combin paramet structur learn first order logic rule end end differenti model approach inspir recent develop differenti logic call tensorlog infer task compil sequenc differenti oper design neural control system learn compos oper empir method obtain state art result multipl knowledg base benchmark dataset includ freebas wikimovi
deliber network sequenc generat beyond pass decod encod decod framework achiev promis progress mani sequenc generat task includ machin translat text summar dialog system imag caption etc framework adopt pass forward process decod generat sequenc lack deliber process generat sequenc direct use final output without polish howev deliber common behavior human daili life like read news write paper articl book work introduc deliber process encod decod framework propos deliber network sequenc generat deliber network level decod first pass decod generat raw sequenc second pass decod polish refin raw sentenc deliber sinc second pass deliber decod overal pictur sequenc generat might potenti generat better sequenc look futur word raw sentenc experi neural machin translat text summar demonstr effect propos deliber network
neural program meta induct recent propos method neural program induct work assumpt larg set input output exampl learn given input output map paper aim address problem data comput effici program induct leverag inform relat task specif propos novel approach cross task knowledg transfer improv program induct limit data scenario first propos portfolio adapt set induct model pretrain set relat task best model adapt toward new task use transfer learn second approach meta program induct shot learn approach use make model general new task without addit train test efficaci method construct new benchmark program written karel program languag use extens experiment evalu karel benchmark demonstr propos dramat outperform baselin induct method use knowledg transfer also analyz relat perform approach studi condit perform best particular meta induct outperform exist approach extrem data sparsiti small number exampl avail fewer number avail exampl increas thousand portfolio adapt program induct becom best approach intermedi data size demonstr combin method adapt meta program induct strongest perform
salienc base sequenti imag attent multiset predict human process visual scene select sequenti use attent central model human visual attent salienc map propos hierarch visual architectur oper salienc map use novel attent mechan sequenti focus salient region take addit glimps within region architectur motiv human visual attent use multi label imag classif novel multiset task demonstr achiev high precis recal local object attent unlik convent multi label imag classif model model support multiset predict due reinforc learn base train process allow arbitrari label permut multipl instanc per label
protein interfac predict use graph convolut network present general framework graph convolut classif task label graph node edg featur perform convolut oper neighborhood node interest abl stack multipl layer convolut learn effect latent represent integr inform across input graph demonstr effect approach predict interfac protein challeng problem import applic drug discoveri design propos approach achiev accuraci better state art svm method task also outperform recent propos diffus convolut form graph convolut
dual agent gan photorealist ident preserv profil face synthesi synthes realist profil face promis effici train deep pose invari model larg scale unconstrain face recognit popul sampl extrem pose avoid tedious annot howev learn synthet face achiev desir perform due discrep distribut synthet real face imag narrow gap propos dual agent generat adversari network gan model improv realism face simul output use unlabel real face preserv ident inform realism refin dual agent specif design distinguish real fake ident simultan particular employ shelf face model simul generat profil face imag vari pose gan leverag fulli convolut network generat generat high resolut imag auto encod discrimin dual agent besid novel architectur make sever key modif standard gan preserv pose textur preserv ident stabil train process pose percept loss ident percept loss iii adversari loss boundari equilibrium regular term experiment result show gan present compel perceptu result also signific outperform state art larg scale challeng nist ijb unconstrain face recognit benchmark addit propos gan also promis new approach solv generic transfer learn problem effect
toward robust label nois train deep discrimin neural network collect larg train dataset annot high qualiti label cost process paper propos novel framework train deep convolut neural network noisi label dataset problem formul use undirect graphic model repres relationship noisi clean label train semi supervis set propos structur infer latent clean label tractabl regular train use auxiliari sourc inform propos model appli imag label problem shown effect label unseen imag well reduc label nois train cifar coco dataset
soft hard vector quantize end end learn compress represent present new approach learn compress represent deep architectur end end train strategi method base soft continu relax quantize entropi anneal discret counterpart throughout train showcas method challeng applic imag compress neural network compress task typic approach differ method soft hard quantize approach give result competit state art
select classif deep neural network select classif techniqu also known reject option yet consid context deep neural network dnns techniqu potenti signific improv dnns predict perform trade coverag paper propos method construct select classifi given train neural network method allow user set desir risk level test time classifi reject instanc need grant desir risk high probabl empir result cifar imagenet convinc demonstr viabil method open possibl oper dnns mission critic applic exampl use method unpreced error top imagenet classif guarante probabl almost test coverag
deep lattic network partial monoton function propos learn deep model monoton respect user specifi set input altern layer linear embed ensembl lattic calibr piecewis linear function appropri constraint monoton joint train result network implement layer project new comput graph node tensorflow use adam optim batch stochast gradient experi benchmark real world dataset show layer monoton deep lattic network achiev state art perform classif regress monoton guarante
learn prune deep neural network via layer wise optim brain surgeon develop slim accur deep neural network becom crucial real world applic especi employ embed system though previous work along research line shown promis result exist method either fail signific compress well train deep network requir heavi retrain process prune deep network boost predict perform paper propos new layer wise prune method deep neural network propos method paramet individu layer prune independ base second order deriv layer wise error function respect correspond paramet prove final predict perform drop prune bound linear combin reconstruct error caus layer therefor guarante need perform light retrain process prune network resum origin predict perform conduct extens experi benchmark dataset demonstr effect prune method compar sever state art baselin method
bayesian compress deep learn compress comput effici deep learn becom problem great signific work argu principl effect way attack problem take bayesian point view sparsiti induc prior prune larg part network introduc novelti paper use hierarch prior prune node instead individu weight use posterior uncertainti determin optim fix point precis encod weight factor signific contribut achiev state art term compress rate still stay competit method design optim speed energi effici
lower bound robust adversari perturb input output map learn state art neural network signific discontinu possibl caus neural network use imag recognit misclassifi input appli specif hard percept perturb input call adversari perturb mani hypothes propos explain exist peculiar sampl well sever method mitig proven explan remain elus howev work take step toward formal character adversari perturb deriv lower bound magnitud perturb necessari chang classif neural network bound experiment verifi mnist cifar data set
sobolev train neural network heart deep learn aim use neural network function approxim train produc output input emul ground truth function data creation process mani case access input output pair ground truth howev becom common access deriv target output respect input exampl ground truth function neural network network compress distil general target deriv comput ignor paper introduc sobolev train neural network method incorpor target deriv addit target valu train optimis neural network approxim function output also function deriv encod addit inform target function within paramet neural network therebi improv qualiti predictor well data effici general capabl learn function approxim provid theoret justif approach well exampl empir evid distinct domain regress classic optimis dataset distil polici agent play atari larg scale applic synthet gradient domain use sobolev train employ target deriv addit target valu result model higher accuraci stronger generalis
structur bayesian prune via log normal multipl nois dropout base regular method regard inject random nois pre defin magnitud differ part neural network train recent shown bayesian dropout procedur improv general also lead extrem spars neural architectur automat set individu nois magnitud per weight howev sparsiti hard use acceler sinc unstructur paper propos new bayesian model take account comput structur neural network provid structur sparsiti remov neuron convolut channel cnns inject nois neuron output keep weight unregular establish probabilist model proper truncat log uniform prior nois truncat log normal variat approxim ensur term evid lower bound comput close form model lead structur sparsiti remov element low snr comput graph provid signific acceler number deep neural architectur model easi implement correspond addit dropout like layer comput graph
popul match discrep applic deep learn differenti estim distanc distribut base sampl import mani deep learn task estim maximum mean discrep mmd howev mmd suffer sensit kernel bandwidth hyper paramet weak gradient larg mini batch size use train object paper propos popul match discrep pmd estim distribut distanc base sampl well algorithm learn paramet distribut use pmd object pmd defin minimum weight match sampl popul distribut prove pmd strong consist estim first wasserstein metric appli pmd deep learn task domain adapt generat model empir result demonstr pmd overcom aforement drawback mmd outperform mmd task term perform well converg speed
investig learn dynam deep neural network use random matrix theori evid well condit singular valu distribut input output jacobian lead substanti improv train perform deep neural network deep linear network conclus evid initi use orthogon random matric lead dramat improv train howev benefit initi strategi proven much less obvious realist nonlinear network use random matrix theori studi condit jacobian nonlinear neural network random initi show singular valu distribut jacobian sensit distribut weight also nonlinear surpris find benefit orthogon initi neglig rectifi linear network substanti tanh network provid rule thumb initi tanh network display dynam isometri full depth final perform experi mnist cifar10 use wide array optim show conclus singular valu distribut jacobian intim relat learn dynam final show spectral densiti jacobian evolv relat slowli train good initi affect learn dynam far initi set weight
robust imit divers behavior deep generat model recent shown great promis imit learn motor control given enough data even supervis approach shot imit learn howev vulner cascad failur agent trajectori diverg demonstr compar pure supervis method generat adversari imit learn gail learn robust control fewer demonstr inher mode seek difficult train paper show combin favour aspect approach base model new type variat autoencod demonstr trajectori learn semant polici embed show embed learn dof jaco robot arm reach task smooth interpol result smooth interpol reach behavior leverag polici represent develop new version gail much robust pure supervis control especi demonstr avoid mode collaps captur mani divers behavior gail demonstr approach learn divers gait demonstr bipe dof humanoid mujoco physic environ
question ask program generat hallmark human intellig abil ask rich creativ reveal question introduc cognit model capabl construct human like question approach treat question formal program execut state world output answer model specifi probabl distribut complex composit space program favor concis program help agent learn current context evalu approach model type open end question generat human attempt learn ambigu situat game find model predict question peopl ask general novel situat creativ way addit compar number model variant assess featur critic produc human like question
variat law visual attent dynam scene comput model visual attent crossroad disciplin like cognit scienc comput neurosci comput vision paper propos approach base principl foundat law drive emerg visual attent devis variat law eye movement reli general view least action principl physic potenti energi captur detail well peripher visual featur kinet energi correspond classic interpret analyt mechan addit lagrangian contain bright invari term character signific scanpath trajectori obtain differenti equat visual attent stationari point general action propos algorithm estim model paramet final report experiment result valid model task salienc detect
flexibl statist infer mechanist model neural dynam mechanist model singl neuron dynam extens studi comput neurosci howev identifi model quantit reproduc empir measur data challeng propos overcom limit use likelihood free infer approach also known approxim bayesian comput abc perform full bayesian infer singl neuron model approach build recent advanc abc learn neural network map featur observ data posterior distribut paramet learn bayesian mixtur densiti network approxim posterior multipl round adapt chosen simul furthermor propos effici approach handl miss featur paramet set simul fail preval issu model neural dynam well strategi automat learn relev featur use recurr neural network synthet data approach effici estim posterior distribut recov ground truth paramet vitro record membran voltag recov multivari posterior biophys paramet yield model predict voltag trace accur match empir data approach enabl neuroscientist perform bayesian infer complex neuron model without design model specif algorithm close gap mechanist statist approach singl neuron model
train recurr network generat hypothes brain solv hard navig problem self local navig noisi sensor ambigu world comput challeng yet anim human excel robot simultan locat map slam algorithm solv problem though joint sequenti probabilist infer coordin extern spatial landmark generat first neural solut slam problem train recurr lstm network perform set hard navig task requir general complet novel trajectori environ goal make sens divers phenomenolog brain spatial navig circuit relat function show hidden unit represent exhibit sever key properti hippocamp place cell includ stabl tune curv remap environ result also proof concept end end learn slam algorithm use recurr network demonstr approach advantag robot slam
yass yet anoth spike sorter spike sort critic first step extract neural signal larg scale electrophysiolog data manuscript describ automat effici reliabl pipelin spike sort dens multi electrod array mea neural signal appear across mani electrod spike sort current repres major comput bottleneck present sever new techniqu make dens mea spike sort robust scalabl pipelin base effici multi stage triag cluster pursuit approach initi extract clean high qualiti waveform electrophysiolog time seri temporarili discard noisi orcollid event repres neuron fire synchron accomplish develop neural net detect method follow effici outlier triag clean waveform use infer number neuron shape nonparametr bayesian cluster cluster approach adapt coreset approach data reduct use effici infer method dirichlet process mixtur model framework dramat improv scalabl reliabl entir pipelin thetriag waveform final recov match pursuit deconvolut techniqu propos method improv state art term accuraci stabil real biophys realist simul mea data furthermor propos pipelin effici learn templat cluster much faster real time 512 electrod dataset use primarili singl cpu core
neural system identif larg popul separ neuroscientist classifi neuron differ type perform similar comput differ locat visual field tradit neural system identif method capit separ learn deep convolut featur space share among mani neuron provid excit path forward architectur design need account data limit new experiment techniqu enabl record thousand neuron experiment time limit sampl small fraction neuron respons space show major bottleneck fit convolut neural network cnns neural data estim individu recept field locat problem scratch surfac thus far propos cnn architectur spars pool layer factor spatial featur dimens network scale well thousand neuron short record train end end explor architectur ground truth data explor challeng limit cnn base system identif moreov show network model outperform current state art system identif model mous primari visual cortex public avail dataset
simpl model recognit recal memori show sever strike differ memori perform recognit recal task explain ecolog bias endem classic memori experi experi univers involv stimuli retriev cue show sensibl think recal simpli retriev item probe cue typic item list better think recognit retriev cue probe item test theori manipul number item cue memori experi show crossov effect memori perform within subject recognit perform superior recal perform number item greater number cue recal perform better recognit convers hold build simpl comput model around theori use sampl approxim ideal bayesian observ encod retriev situat occurr frequenc stimuli retriev cue model robust reproduc number dissoci recognit recal previous use argu dual process account declar memori
gaussian process base nonlinear latent structur discoveri multivari spike train data larg bodi recent work focus method identifi low dimension latent structur multi neuron spike train data method employ either linear latent dynam linear log linear map latent space spike rate propos doubli nonlinear latent variabl model popul spike train identifi nonlinear low dimension structur under appar high dimension spike train data model poisson gaussian process latent variabl model gplvm defin low dimension latent variabl govern gaussian process nonlinear tune curv parametr exponenti sampl second gaussian process poisson observ nonlinear tune curv allow discoveri low dimension latent embed even spike rate span high dimension subspac hippocamp place cell code learn model introduc decoupl laplac approxim fast approxim infer method allow effici maxim margin likelihood latent path integr tune curv show method outperform previous approach maxim laplac approxim base margin likelihood converg speed valu final object appli model spike train record hippocamp place cell show outperform varieti previous method latent structur discoveri includ variat auto encod base method parametr nonlinear map latent space spike rate deep neural network
deep adversari neural decod present novel approach solv problem reconstruct perceiv stimuli brain respons combin probabilist infer deep learn approach first invert linear transform latent featur brain respons maximum posteriori estim invert nonlinear transform perceiv stimuli latent featur adversari train convolut neural network test approach function magnet reson imag experi show generat state art reconstruct perceiv face brain activ
cross spectral factor analysi neuropsychiatr disord schizophrenia depress often disrupt way differ region brain communic anoth order build greater understand neurolog basi disord introduc novel model multisit local field potenti lfps low frequenc voltag oscil measur electrod implant mani brain region simultan propos model call cross spectral factor analysi csfa break observ lfps electr function connectom electom defin differ spatiotempor properti electom defin uniqu frequenc power phase coher pattern mani brain region properti grant featur via gaussian process formul multipl kernel learn framework critic electom interpret use design follow causal studi furthermor use formul lfp signal map lower dimension space better tradit approach remark addit interpret propos approach achiev state art predict abil compar black box approach look behavior paradigm genotyp predict task mous model demonstr featur basi captur neural dynam relat outcom conclud discuss csfa analysi use conjunct experi design causal studi provid gold standard valid infer neural relationship
cognit impair predict alzheim diseas regular modal regress accur automat predict cognit assess via neuroimag marker critic earli detect alzheim diseas linear regress model success use associ studi neuroimag featur cognit perform alzheim diseas studi howev exist method built least squar mean squar error mse criterion sensit outlier perform degrad heavi tail nois complex brain disord data paper beyond criterion investig regular modal regress statist learn viewpoint new regular scheme base modal regress propos estim variabl select robust outlier heavi tail nois skew nois conduct theoret analysi establish approxim bound learn condit mode function sparsiti analysi variabl select robust character experiment evalu simul data adni cohort data provid support promis perform propos algorithm
stochast submodular maxim case coverag function continu optim techniqu sgd extens main workhors modern machin learn nevertheless varieti import machin learn problem requir solv discret optim problem submodular object goal paper unleash toolkit modern continu optim discret problem first introduc framework emph stochast submodular optim instead emph oracl access under object explicit consid statist comput aspect evalu object provid formal emph stochast submodular maxim class import discret optim problem show state art techniqu continu optim lift realm discret optim extens experiment evalu demonstr practic impact propos approach
gradient method submodular maxim paper studi problem maxim continu submodular function natur aris mani learn applic involv util function activ learn sens matrix approxim network infer despit appar lack convex function prove stochast project gradient method provid strong approxim guarante maxim continu submodular function convex constraint specif prove monoton continu submodular function fix point project gradient ascent provid factor approxim global maxima also studi stochast gradient mirror method show iter method reach solut achiev expectaion object valu exceed opt2 immedi implic result bridg discret continu submodular maxim final experi real data demonstr project gradient method consist achiev best util compar continu baselin remain competit term comput effort
non convex finit sum optim via scsg method develop class algorithm variant stochast control stochast gradient scsg method smooth nonconvex finit sum optim problem assum smooth compon complex scsg reach stationari point min 1n2 strict outperform stochast gradient descent moreov scsg never wors state art method base varianc reduct signific outperform target accuraci low similar acceler also achiev function satisfi polyak lojasiewicz condit empir experi demonstr scsg outperform stochast gradient method train multi layer neural network term train valid loss
influenc maxim almost submodular threshold function influenc maxim problem select node social network maxim influenc spread problem extens studi work focus submodular influenc diffus model paper motiv empir evid explor influenc maxim non submodular regim particular studi general threshold model fraction node non submodular threshold function threshold function close upper lower bound submodular function call almost submodular first show strong hard result nc approxim influenc maxim unless network almost submodular node paramet depend although threshold function close submodular influenc maxim still hard approxim provid approxim algorithm number almost submodular node final conduct experi number real world dataset result demonstr approxim algorithm outperform benchmark algorithm
subset select nois problem select best element subset univers involv mani applic previous studi assum nois free environ noisi monoton submodular object function paper consid realist general situat evalu subset noisi monoton function necessarili submodular multipl addit nois understand impact nois first show approxim ratio greedi algorithm poss power algorithm nois free subset select noisi environ propos incorpor nois awar strategi poss result new ponss algorithm better approxim ratio empir result influenc maxim spars regress problem show superior perform ponss
polynomi time algorithm dual volum sampl studi dual volum sampl method select column short wide matrix probabl select proport volum span row induc submatrix method propos avron boutsidi 2013 show promis method column subset select multipl applic howev wider adopt hamper lack polynomi time sampl algorithm remov hindranc develop exact random polynomi time sampl algorithm well derandom thereaft studi dual volum sampl via theori real stabl polynomi prove distribut satisfi strong rayleigh properti result remark consequ especi impli provabl fast mix markov chain sampler make dual volum sampl much attract practition sampler close relat classic algorithm popular experiment design method date lack theoret analysi known empir work well
lookahead bayesian optim inequ constraint consid task optim object function subject inequ constraint object constraint expens evalu bayesian optim popular way tackl optim problem expens object function evalu most appli unconstrain problem sever approach propos address expens constraint limit greedi strategi maxim immedi reward address limit propos lookahead approach select next evalu order maxim long term feasibl reduct object function present numer experi demonstr perform improv lookahead approach compar greedi algorithm constrain expect improv eic predict entropi search constraint pesc
non monoton continu submodular maxim structur algorithm submodular continu function import object wide real world applic span map infer determinant point process dpps mean field infer probabilist submodular model amongst other submodular captur subclass non convex function enabl exact minim approxim maxim polynomi time work studi problem maxim non monoton submodular continu function general close convex constraint start investig sever properti underli object use devis optim algorithm provabl guarante concret first devis phase algorithm approxim guarante algorithm allow use exist method ensur find approxim stationari point subroutin thus enabl util recent progress non convex optim present non monoton frank wolf variant approxim guarante sublinear converg rate final extend approach broader class general submodular continu function captur wider spectrum applic theoret find valid sever synthet real world problem instanc
solv almost system random quadrat equat paper deal find dimension solut bmx system quadrat equat bmai bmx general known hard put forth novel procedur start emph weight maxim correl initi obtain power iter follow success refin base emph iter reweight gradient type iter novel techniqu distinguish prior work inclus fresh weight regular certain random measur model propos procedur return true solut bmx high probabl time proport read data bmai provid number equat constant time number unknown name empir upshot contribut perfect signal recoveri high dimension regim given inform theoret limit number equat near optim statist accuraci presenc addit nois extens numer test use synthet data real imag corrobor improv signal recoveri perform comput effici relat state art approach
learn relus via gradient descent paper studi problem learn rectifi linear unit relus function form vctx max vctw vctx vctw denot weight vector studi problem high dimension regim number observ fewer dimens weight vector assum weight vector belong close set convex nonconvex captur known side inform structur focus realiz model input chosen gaussian distribut label generat accord plant weight vector show project gradient descent initi vct0 converg linear rate plant model number sampl optim numer constant result dynam converg shallow neural net provid insight toward understand dynam deeper architectur
stochast mirror descent non convex optim paper examin class non convex stochast program call emph variat coher proper includ quasi pseudo convex optim problem establish converg class problem studi well known smd method show algorithm last iter converg problem global optimum probabl result contribut landscap non convex optim clarifi convex quasi convex essenti global converg rather variat coher much weaker requir suffic local class account local variat coher problem show last iter stochast mirror descent converg local optima high probabl final consid last iter converg rate problem sharp minima deriv special case conclus probabl last iter stochast gradient descent reach exact global optimum finit number step result contrast exist work linear program exhibit asymptot converg rate
acceler first order method geodes convex optim riemannian manifold paper propos acceler first order method geodes convex optim general standard nesterov acceler method euclidean space nonlinear riemannian space first deriv equat approxim linear gradient like updat euclidean space geodes convex optim particular analyz global converg properti acceler method geodes strong convex problem show method improv converg rate sqrt moreov method also improv global converg rate geodes general convex problem final give specif iter scheme matrix karcher mean problem valid theoret result experi
fine grain complex empir risk minim kernel method neural network empir risk minim erm ubiquit machin learn under supervis learn method larg bodi work algorithm various erm problem exact comput complex erm still understood address issu multipl popular erm problem includ kernel svms kernel ridg regress train final layer neural network particular give condit hard result problem base complex theoret assumpt strong exponenti time hypothesi assumpt show algorithm solv aforement erm problem high accuraci sub quadrat time also give similar hard result comput gradient empir loss main comput burden mani non convex learn task
larg scale quadrat constrain quadrat program via low discrep sequenc consid problem solv larg scale quadrat constrain quadrat program problem occur natur mani scientif web applic although effici method tackl problem most scalabl paper develop method transform quadrat constraint linear form sampl set low discrep point transform problem solv appli state art larg scale solver show converg approxim solut true solut well finit sampl error bound experiment result also shown prove scalabl practic
new altern direct method linear program well known linear program constraint matrix altern direct method multipli converg global linear rate log howev rate relat problem dimens algorithm exhibit slow fluctuat tail converg practic paper propos new variabl split method prove method converg rate 2log proof base simultan estim distanc pair primal dual iter optim primal dual solut set certain residu practic result new first order solver exploit sparsiti specif structur matrix signific speedup import problem basi pursuit invers covari matrix estim svm nonneg matrix factor problem compar current fastest solver
dykstra algorithm admm coordin descent connect insight extens studi connect dykstra algorithm project onto intersect convex set augment lagrangian method multipli admm block coordin descent prove coordin descent regular regress problem separ penalti function seminorm exact equival dykstra algorithm appli dual problem admm dual problem also seen equival special case set linear subspac connect asid interest right suggest new way analyz extend coordin descent exampl exist converg theori dykstra algorithm polyhedra discern coordin descent lasso problem converg asymptot linear rate also develop parallel version coordin descent base dykstra admm connect
smooth primal dual coordin descent algorithm nonsmooth convex optim propos new random coordin descent method convex optim templat broad applic analysi reli novel combin idea appli primal dual gap function smooth acceler homotopi non uniform sampl result method featur first converg rate guarante best known varieti common structur assumpt templat provid numer evid support theoret result comparison state art algorithm
first order adapt sampl size method reduc complex empir risk minim paper studi empir risk minim erm problem larg scale dataset incorpor idea adapt sampl size method improv guarante converg bound first order stochast determinist method contrast tradit method attempt solv erm problem correspond full dataset direct adapt sampl size scheme start small number sampl solv correspond erm problem statist accuraci sampl size grown geometr scale factor use solut previous erm warm start new erm theoret analys show use adapt sampl size method reduc overal comput cost achiev statist accuraci whole dataset broad rang determinist stochast first order method gain specif choic method particular acceler gradient descent stochast varianc reduc gradient comput cost advantag logarithm number train sampl numer experi various dataset confirm theoret claim showcas gain use propos adapt sampl size scheme
acceler consensus via min sum split appli min sum messag pass protocol solv consensus problem distribut optim show ordinari min sum algorithm converg modifi version known split yield converg problem solut prove proper choic tune paramet allow min sum split yield subdiffus acceler converg rate match rate obtain shift regist method acceler scheme embodi min sum split consensus problem bear similar lift markov chain techniqu multi step first order method convex optim
integr method optim algorithm show acceler optim method seen particular instanc multi step integr scheme numer analysi appli gradient flow equat compar recent advanc vein differenti equat consid basic gradient flow deriv class multi step scheme includ acceler algorithm use classic condit numer analysi multi step scheme integr differenti equat use larger step size intuit explain acceler phenomenon
effici use limit memori resourc acceler linear learn work propos generic approach effici use comput acceler gpus fpgas train larg scale machin learn model train data exceed memori capac techniqu build upon primal dual coordin select use dualiti gap select criteria dynam decid part data made avail fast process provid strong theoret guarante motiv gap base select scheme provid effici practic implement thereof illustr power approach demonstr perform train general linear model larg scale dataset exceed memori size modern gpu show order magnitud speedup exist approach
screen rule regular ise model estim discov screen rule regular ise model estim simpl close form screen rule necessari suffici condit exact recov blockwis structur solut given regular paramet enough sparsiti screen rule combin exact inexact optim procedur deliv solut effici practic screen rule especi suitabl larg scale exploratori data analysi number variabl dataset thousand interest relationship among hand variabl within moder size cluster interpret experiment result various dataset demonstr effici insight gain introduct screen rule
uproot reroot higher order graphic model idea uproot reroot graphic model introduc specif binari pairwis model weller way transform model whole equival class relat model infer model yield infer result other help sinc infer relev bound much easier obtain accur model class introduc method extend approach model higher order potenti develop theoret insight exampl demonstr triplet consist polytop tri uniqu univers root demonstr empir reroot signific improv accuraci method infer higher order model neglig comput cost
concentr multilinear function ise model applic network data prove near tight concentr measur polynomi function ise model high temperatur improv radius concentr guarante known result polynomi factor dimens number node ise model show result optim logarithm factor dimens obtain result extend strengthen exchang pair approach use prove concentr measur set chatterje demonstr efficaci function statist test strength interact social network synthet real world data
infer graphic model via semidefinit program hierarchi maximum posteriori probabl map infer graphic model amount solv graph structur combinatori optim problem popular infer algorithm belief propag general belief propag gbp intim relat linear program relax within sherali adam hierarchi despit popular algorithm well understood sum squar sos hierarchi base semidefinit program sdp provid superior guarante unfortun sos relax graph vertic requir solv sdp variabl degre hierarchi practic approach scale beyond ten variabl paper propos sdp relax map infer use sos hierarchi innov focus comput effici first analog variant introduc decis variabl correspond contigu region graphic model second solv result sdp use non convex burer monteiro style method develop sequenti round procedur demonstr result algorithm solv problem ten thousand variabl within minut signific outperform gbp practic problem imag denois ise spin glass final specif graph type establish suffici condit tight propos partial sos relax
beyond normal learn spars probabilist graphic model non gaussian set present algorithm identifi spars depend structur continu non gaussian probabl distribut given correspond set data condit independ structur arbitrari distribut repres undirect graph markov random field algorithm learn structur restrict discret gaussian case new approach allow realist accur descript distribut question turn better estim spars markov structur sparsiti graph interest acceler infer improv sampl method reveal import depend variabl algorithm reli exploit connect sparsiti graph sparsiti transport map determinist coupl probabl measur anoth
dynam import sampl anytim bound partit function comput partit function key infer task mani graphic model paper propos dynam import sampl scheme provid anytim finit sampl bound partit function algorithm balanc advantag major infer strategi heurist search variat bound mont carlo method blend sampl search refin variat defin propos algorithm combin general recent work anytim search probabilist bound partit function use intellig chosen weight averag sampl construct unbias estim partit function strong finit sampl confid interv inherit rapid earli improv rate sampl long term benefit improv propos search give signific improv anytim behavior flexibl trade off memori time solut qualiti demonstr effect approach empir real world problem instanc taken recent uai competit
nonbacktrack bound influenc independ cascad model paper develop upper lower bound influenc measur network precis expect number node seed set influenc independ cascad model particular bound exploit nonbacktrack walk fortuin kasteleyn ginibr fkg type inequ comput messag pass implement nonbacktrack walk recent allow headway communiti detect paper show use also impact influenc comput provid knob control trade effici accuraci bound final tight bound illustr simul various network model
rigor dynam consist estim arbitrarili condit linear system problem estim random vector noisi linear measur unknown paramet distribut must also learn aris wide rang statist learn linear invers problem show comput simpl iter messag pass algorithm provabl obtain asymptot consist estim certain high dimension larg system limit lsl general parameter previous messag pass techniqu requir sub gaussian matric often fail matrix ill condit propos algorithm call adapt vector approxim messag pass adapt vamp auto tune appli right rotate random import class includ matric arbitrarili bad condit show paramet estim mean squar error mse iter converg determinist limit precis predict simpl set state evolut equat addit simpl testabl condit provid mse match bay optim valu predict replica method paper thus provid comput simpl method provabl guarante optim consist larg class linear invers problem
learn disentangl represent semi supervis deep generat model variat autoencod vae learn represent data joint train probabilist encod decod network typic model encod featur data singl variabl interest learn disentangl represent encod distinct aspect data separ variabl propos learn represent use model architectur general standard vae employ general graphic model structur encod decod allow train partial specifi model make relat strong assumpt subset interpret variabl reli flexibl neural network learn represent remain variabl defin general object semi supervis learn model class approxim use import sampl procedur appli general class model evalu framework abil learn disentangl represent qualit explor generat capac quantit evalu discrimin abil varieti model dataset
gaug variat infer comput partit function import statist infer task aris applic graphic model sinc comput intract approxim method use resolv issu practic mean field belief propag arguabl popular success approach variat type paper propos new variat scheme coin gaug gaug improv respect provid lower bound partit function util call gaug transform modifi factor keep partit function invari moreov prove exact gms singl loop special structur even though bare perform bad case extens experi complet gms relat small size larg 300 variabl confirm newli propos algorithm outperform general
variat infer via upper bound minim variat infer wide use effici altern mcmc posit famili approxim distribut find member closest true posterior close usual measur via diverg though success approach also problem notabl typic lead underestim posterior varianc paper propos chivi new black box variat infer algorithm minim diverg chivi minim upper bound model evid term cubo minim cubo lead better estim posterior use classic lower bound elbo provid sandwich estim margin likelihood studi chivi model probit regress gaussian process classif cox process model basketbal play compar classic chivi produc better error rate accur estim posterior varianc
collaps variat bay markov jump process markov jump process continu time stochast process wide use statist applic natur scienc recent machin learn infer model typic proceed via markov chain mont carlo suffer various comput challeng work propos novel collaps variat infer algorithm address issu work leverag idea discret time markov chain exploit connect idea call uniform algorithm proceed margin paramet markov jump process approxim distribut trajectori factor distribut segment piecewis constant function unlik mcmc scheme margin transit time piecewis constant process scheme optim discret time result signific comput save appli idea synthet data well dataset check record demonstr superior perform state art mcmc method
bayesian dyadic tree histogram regress mani machin learn tool regress base recurs partit covari space smaller region regress function estim local among regress tree ensembl demonstr impress empir perform work shed light machineri behind bayesian variant method particular studi bayesian regress histogram bayesian dyadic tree simpl regress case predictor focus reconstruct regress surfac piecewis constant number jump unknown show suitabl design prior posterior distribut concentr around true step regress function minimax rate log factor result requir knowledg true number step width true partit cell thus bayesian dyadic regress tree fulli adapt recov true piecewis regress function near well knew exact number locat jump result constitut first step toward understand bayesian tree ensembl work well practic asid discuss prior distribut balanc interv partit relat problem geometr probabl name quantifi probabl cover circumfer circl random arc whose endpoint confin grid new variant origin problem
differenti privat bayesian learn distribut data mani applic machin learn exampl health care would benefit method guarante privaci data subject differenti privaci becom establish standard protect learn result standard algorithm requir singl trust parti access entir data clear weak consid bayesian learn distribut set parti hold singl sampl sampl data propos learn strategi base secur multi parti sum function aggreg summari data holder gaussian mechan method build asymptot optim practic effici bayesian infer rapid diminish extra cost
model power condit independ test consid problem non parametr condit independ test test continu random variabl given sampl joint distribut continu random vector determin whether independenti approach convert condit independ test classif problem allow har power classifi like gradient boost tree deep neural network model handl complex probabl distribut allow perform signific better compar prior state art high dimension test main technic challeng classif problem need sampl condit product distribut fci joint distribut independenti given access sampl true joint distribut tackl problem propos novel nearest neighbor bootstrap procedur theoret show generat sampl inde close fci term total variat distanc develop theoret result regard general bound classif problem translat error bound test provid novel analysi rademach type classif bound presenc non textit near independ sampl empir valid perform algorithm simul real dataset show perform gain previous method
world collid integr differ counterfactu assumpt fair machin learn use make crucial decis peopl live near decis risk individu certain race gender sexual orient subpopul unfair discrimin recent method demonstr use techniqu counterfactu infer make predict fair across differ subpopul method requir provid causal model generat data hand genera valid causal model imposs use observ data alon without assumpt henc desir integr compet causal model provid counterfactu fair decis regardless world correct paper show possibl make predict approxim fair respect multipl possibl causal model thus bypass problem exact causal specif frame goal learn fair classifi optim problem fair constraint provid techniqu relax solv optim problem demonstr flexibl model real world fair classif problem show model seamless balanc fair multipl world predict accuraci
lda uncov latent pattern text base sequenti decis process sequenti decis make often import use end user understand under pattern caus lead correspond decis howev typic deep reinforc learn algorithm seldom provid inform due black box natur paper present probabilist model lda uncov latent pattern text base sequenti decis process model understood variant latent topic model tailor maxim total reward draw interest connect approxim maximum likelihood estim lda celebr learn algorithm demonstr text game domain propos method provid viabl mechan uncov latent pattern decis process also obtain state art reward game
probabilist model integr error assess function cardiac model paper studi numer comput integr repres estim predict output comput model respect distribut uncertain input model function cardiac model motiv work neither possess close form express evalu either requir 100 cpu hour preclud standard numer integr method propos treat integr estim problem joint model priori unknown function priori unknown distribut result posterior distribut integr explicit account dual sourc numer approxim error due sever limit comput budget construct appli account statist principl manner impact numer error present confound factor function cardiac model assess
expect propag exponenti famili use algebra exponenti famili distribut high use machin learn sinc calcul perform effici natur paramet exponenti famili recent extend emph exponenti famili contain student distribut famili member thus allow handl noisi data well howev sinc exponenti famili defin emph deform exponenti cannot deriv effici learn algorithm exponenti famili expect propag paper borrow mathemat tool algebra statist physic show pseudo addit distribut allow perform calcul exponenti famili distribut natur paramet develop expect propag algorithm exponenti famili provid determinist approxim posterior predict distribut simpl moment match final appli propos algorithm bay point machin student process classif demonstr perform numer
probabilist framework nonlinear stochast neural network present probabilist framework nonlinear base doubli truncat gaussian distribut set truncat point appropri abl generat various type nonlinear within unifi framework includ sigmoid tanh relu common use nonlinear neural network framework readili integr exist stochast neural network hidden unit character random variabl allow first time learn nonlinear alongsid model weight network extens experi demonstr perform improv brought propos framework integr restrict boltzmann machin rbm tempor rbm truncat gaussian graphic model tggm
clone mcmc parallel high dimension gaussian gibb sampl propos general gibb sampler algorithm obtain sampl approx imat distribut high dimension gaussian distribut similar hogwild method approach target origin gaussian distribut interest approxim contrari hogwild method singl paramet allow trade bias varianc show empir method flexibl perform well compar hogwild type algorithm
learn spatiotempor piecewis geodes trajectori longitudin manifold valu data introduc hierarch model allow estim group averag piecewis geodes trajectori riemannian space measur individu variabl model fall well defin mix effect model subject specif trajectori defin spatial tempor transform group averag piecewis geodes path compon compon thus appli model wide varieti situat due non linear model use stochast approxim expect maxim algorithm estim model paramet experi synthet data valid choic model appli metastat renal cancer chemotherapi monitor run estim recist score treat patient estim time escap treatment experi highlight role differ paramet respons treatment
scalabl levi process prior spectral kernel learn gaussian process rich distribut function generalis properti determin kernel function propos distribut kernel form model spectral densiti levi process result distribut support stationari covari includ popular rbf period matern kernel combin induct bias enabl automat data effici learn long rang extrapol state art predict perform posterior infer develop revers jump mcmc approach includ automat select model order exploit algebra structur propos process train predict show propos model empir recov flexibl ground truth covari demonstr extrapol sever benchmark
infer latent structur human decis make raw visual input goal imit learn match exampl expert behavior without access reinforc signal expert demonstr provid human howev often show signific variabl due latent factor explicit model introduc extens generat adversari imit learn method infer latent structur human decis make unsupervis way method imit complex behavior also learn interpret meaning represent demonstr approach applic high dimension environ includ raw visual input highway drive domain show model learn demonstr abl produc differ drive style accur anticip human action method surpass various baselin term perform function
hybrid reward architectur reinforc learn main challeng reinforc learn generalis typic deep method achiev approxim optim valu function low dimension represent use deep network approach work well mani domain domain optim valu function cannot easili reduc low dimension represent learn slow unstabl paper contribut toward tackl challeng domain propos new method call hybrid reward architectur hydra hydra take input decompos reward function learn separ valu function compon reward function compon typic depend subset featur overal valu function much smoother easier approxim low dimension represent enabl effect learn demonstr hydra toy problem atari game pac man hydra achiev human perform
shallow updat deep reinforc learn deep reinforc learn drl method deep network dqn achiev state art result varieti challeng high dimension domain success main attribut power deep neural network learn rich domain represent approxim valu function polici batch reinforc learn method linear represent hand stabl requir less hyper paramet tune yet substanti featur engin necessari achiev good result work propos hybrid approach least squar deep network dqn combin rich featur represent learn drl algorithm stabil linear least squar method period train last hidden layer drl network batch least squar updat key approach bayesian regular term least squar updat prevent fit recent data test dqn atari game demonstr signific improv vanilla dqn doubl dqn also investig reason superior perform method interest found perform improv attribut larg batch size use method optim last layer
toward general simplic continu control remark success deep learn speech recognit comput vision motiv effort adapt similar techniqu problem domain includ reinforc learn consequ method produc rich motor behavior simul robot task success larg attribut use multi layer neural network work among first care studi might respons recent advanc main result call emerg narrat question show much simpler architectur base linear rbf parameter achiev compar perform state art result studi differ polici represent regard perform measur hand also toward robust extern perturb find learn neural network polici standard train scenario robust linear rbf polici fact remark brittl final direct modifi train scenario order favor robust polici find compel case favor multi layer architectur overal studi suggest multi layer architectur default choic unless side side comparison simpler architectur show otherwis general hope result lead interest care studi architectur choic associ trade off train generaliz robust polici
interpol polici gradient merg polici polici gradient estim deep reinforc learn polici model free deep reinforc learn method use previous collect data improv sampl effici polici polici gradient techniqu hand polici algorithm often stabl easier use paper examin theoret empir approach merg polici updat deep reinforc learn theoret result show polici updat valu function estim interpol polici polici gradient updat whilst still satisfi perform bound analysi use control variat method produc famili polici gradient algorithm sever recent propos algorithm special case famili provid empir comparison techniqu remain algorithm detail fix show differ mix polici gradient estim polici sampl contribut improv empir perform final algorithm provid general unif exist deep polici gradient techniqu theoret guarante bias introduc polici updat improv state art model free deep method number openai gym continu control benchmark
scalabl plan tensorflow hybrid nonlinear domain given recent deep learn result demonstr abil effect optim high dimension non convex function gradient descent optim gpus ask paper whether symbol gradient optim tool tensorflow effect plan hybrid mix discret continu nonlinear domain high dimension state action space end demonstr hybrid plan tensorflow rmsprop gradient descent competit mix integ linear program milp base optim piecewis linear plan domain comput optim solut substanti outperform state art interior point method nonlinear plan domain furthermor remark tensorflow high scalabl converg strong polici larg scale concurr domain total 576 000 continu action horizon time step minut provid number insight clarifi strong perform includ observ despit long horizon rmsprop avoid vanish explod gradient problem togeth result suggest new frontier high scalabl plan nonlinear hybrid domain leverag gpus power recent advanc gradient descent high optmiz toolkit like tensorflow
task base end end model learn stochast optim machin learn techniqu becom widespread becom common see predict algorithm oper within larger process howev criteria train algorithm often differ ultim criteria evalu paper propos end end approach learn probabilist machin learn model within context stochast program manner direct captur ultim task base object use present experiment evalu propos approach classic inventori stock problem real world electr grid schedul task case show propos approach outperform tradit model pure black box polici optim approach
valu predict network paper propos novel deep reinforc learn approach call valu predict network vpn integr model free model base method singl neural network contrast typic model base method vpn learn dynam model whose abstract state train make option condit predict futur valu rather futur observ experiment result show vpn sever advantag model free model base baselin stochast environ care plan requir build accur observ predict model difficult furthermor vpn outperform deep network dqn sever atari game even short lookahead plan demonstr potenti new way learn good state represent
variabl import use decis tree decis tree random forest well establish model offer good predict perform also provid rich featur import inform practition often employ variabl import method reli impur base inform method remain poor character theoret perspect provid novel insight perform method deriv finit sampl perform guarante high dimension set various model assumpt demonstr effect impur base method via extens set simul
express power neural network view width express power neural network import understand deep learn exist work consid problem view depth network paper studi width affect express neural network classic result state emph depth bound depth network suitabl activ function univers approxim show univers approxim theorem emph width bound relu network width relu network input dimens univers approxim moreov except measur set function cannot approxim width relu network exhibit phase transit sever recent work demonstr benefit depth prove depth effici neural network class deep network cannot realiz shallow network whose size emph exponenti bound pose dual question width effici relu network wide network cannot realiz narrow network whose size substanti larger show exist class wide network cannot realiz narrow network whose depth emph polynomi bound hand demonstr extens experi narrow network whose depth exceed polynomi bound constant factor approxim wide shallow network high accuraci result provid comprehens evid depth effect width express relu network
sgd learn conjug kernel class network show standard stochast gradient decent sgd algorithm guarante learn polynomi time function competit best function conjug kernel space network defin dani frostig singer result hold log depth network rich famili architectur best knowledg first polynomi time guarante standard neural network learn algorithm network depth corollari follow neural network depth log sgd guarante learn polynomi time constant degre polynomi polynomi bound coeffici likewis follow sgd larg enough network learn continu function polynomi time complement classic express result
radon machin effect parallelis machin learn order simplifi adapt learn algorithm grow amount data well grow need accur confid predict critic applic paper propos novel provabl effect parallelis scheme contrast parallelis techniqu scheme appli broad class learn algorithm without mathemat deriv without write singl line addit code achiev treat learn algorithm black box appli parallel random data subset result hypothes assign leav aggreg tree bottom replac set hypothes correspond inner node tree radon point consid confid paramet epsilon delta input learn algorithm effici sampl complex polynomi epsilon delta time complex polynomi sampl complex parallelis scheme algorithm achiev guarante appli polynomi number core polylogarithm time result allow effect parallelis broad class learn algorithm intrins relat nick class decis problem well learnabl exact learn cost parallelis form slight larger sampl complex empir studi confirm potenti parallis scheme rang data set sever learn algorithm
nois toler interact learn use pairwis comparison studi problem interact learn binari classifi use noisi label pairwis comparison oracl comparison oracl answer given instanc like posit learn oracl multipl applic obtain direct label harder pairwis comparison easier algorithm leverag type oracl paper attempt character access easier comparison oracl help improv label total queri complex show comparison oracl reduc learn problem learn threshold function present algorithm interact queri label comparison oracl character queri complex tsybakov adversari nois condit comparison label oracl lower bound show label total queri complex almost optim
pac bayesian analysi random learn applic stochast gradient descent analyz general properti random learn algorithm focus stochast gradient descent sgd use novel combin pac bay algorithm stabil import risk bound hold posterior distribut algorithm hyperparamet includ distribut depend train data inspir adapt sampl algorithm sgd optim posterior runtim analyz algorithm context risk bound evalu empir benchmark dataset
revisit perceptron effici label optim learn halfspac long stand problem effici learn linear separ use label possibl presenc nois work propos effici perceptron base algorithm activ learn homogen linear separ uniform distribut bound nois label flip probabl eta algorithm achiev near optim tild frac 2eta frac epsilon label complex time tild frac epsilon 2eta adversari nois tild omega epsilon fraction label flip algorithm achiev near optim tild frac epsilon label complex time tild frac epsilon furthermor show activ learn algorithm convert effici passiv learn algorithm near optim sampl complex respect epsilon
sampl comput effici learn algorithm concav distribut provid new result nois toler sampl effici learn algorithm concav distribut new class concav distribut broad natur general log concav includ mani import addit distribut pareto distribut distribut class studi context effici sampl integr optim much remain unknown geometri class distribut applic context learn challeng unlik common use distribut learn uniform general log concav distribut broader class close margin oper mani distribut fat tail work introduc new convex geometri tool studi properti concav distribut use properti provid bound quantiti interest learn includ probabl disagr halfspac disagr outsid band disagr coeffici use result signific general prior result margin base activ learn disagr base activ learn passiv learn intersect halfspac analysi geometr properti concav distribut might independ interest optim broad
nearest neighbor sampl compress effici consist infinit dimens examin bay consist recent propos nearest neighbor base multiclass learn algorithm algorithm deriv sampl compress bound enjoy statist advantag tight fulli empir general bound well algorithm advantag runtim memori save prove algorithm strong bay consist metric space finit doubl dimens first consist result effici nearest neighbor sampl compress scheme rather surpris discov algorithm continu bay consist even certain infinit dimension set basic measur theoret condit classic consist proof hing violat surpris sinc known bay consist set pose sever challeng open problem futur research
learn identifi gaussian bayesian network polynomi time sampl complex learn direct acycl graph dag structur bayesian network observ data notori difficult problem mani non identifi hard result known paper propos provabl polynomi time algorithm learn spars gaussian bayesian network equal nois varianc class bayesian network dag structur uniqu identifi observ data high dimension set show k4log number sampl suffic method recov true dag structur high probabl number variabl maximum markov blanket size obtain theoret guarante condit call emph restrict strong adjac faith rsaf strict weaker strong faith condit method base condit independ test need success sampl complex method match inform theoret limit term depend valid theoret find synthet experi
world graph discov statist structur link fundament problem analysi social network choos misspecifi model equival incorrect infer algorithm result invalid analysi even fals uncov pattern fact artifact model work focus unifi wide use link format model stochast block model sbm small world latent space model swm integr techniqu kernel learn spectral graph theori nonlinear dimension reduct develop first statist sound polynomi time algorithm discov latent pattern spars graph model network come sbm algorithm output block structur swm algorithm output estim node latent posit
mean field residu network edg chao studi random initi residu network use mean field theori theori differ equat classic feedforward neural network tanh activ exhibit exponenti behavior averag propag input forward gradient backward exponenti forward dynam caus rapid collaps input space geometri exponenti backward dynam caus drastic vanish explod gradient show contrast convert residu connect activ tanh power relu unit network adopt subexponenti forward backward dynam mani case fact polynomi expon polynomi obtain analyt method prove verifi empir correct term edg chao hypothesi subexponenti polynomi law allow residu network tohov boundari stabil chao thus preserv geometri input space gradient inform flow also train grid tanh residu network mnist observ predict theori develop paper peak perform model determin product standard deviat weight squar root depth thus addit improv understand residu network theoret tool guid research toward better initi scheme
learn uncertain curv wasserstein metric gaussian process introduc novel framework statist analysi popul non degener gaussian process gps natur represent uncertain curv allow inher variat uncertainti function valu data proper incorpor popul analysi use wasserstein metric geometr space gps mean covari function compact index space prove exist uniqu barycent popul gps well converg metric barycent finit dimension counterpart justifi practic comput final demonstr framework experiment valid dataset repres brain connect climat chang sourc code releas upon public
cluster network valu data communiti detect focus cluster node detect communiti most singl network problem consider practic interest receiv great deal attent research communiti abl cluster within network import emerg need abl cluster multipl network larg motiv routin collect network data generat potenti differ popul network node correspond node correspond present cluster summar network graphon estim wherea node correspond present propos novel solut cluster network associ comput feasibl featur vector network base trace power adjac matrix illustr method simul real data set theoret justif given term consist
power truncat svd general high rank matrix estim problem show given estim mata close general high rank posit semi definit psd matrix mata spectral norm mata mata simpl truncat singular valu decomposit mata produc multipl approxim mata frobenius norm observ lead mani interest result general high rank matrix estim problem high rank matrix complet show possibl recov general high rank matrix mata relat error frobenius norm partial observ sampl complex independ spectral gap mata high rank matrix denois design algorithm recov matrix mata relat error frobenius norm nois perturb observ without assum mata exact low rank low dimension estim high dimension covari given sampl dimens mat0 mata show possibl estim covari matrix mata relat error frobenius norm improv classic covari estim result requir
adagan boost generat model generat adversari network gan effect method train generat model complex data natur imag howev notori hard train suffer problem miss mode model abl produc exampl certain region space propos iter procedur call adagan everi step add new compon mixtur model run gan algorithm weight sampl inspir boost algorithm mani potenti weak individu predictor greedili aggreg form strong composit predictor prove analyt increment procedur lead converg true distribut finit number step step optim converg exponenti rate otherwis also illustr experiment procedur address problem miss mode
adagan boost generat model generat adversari network gan effect method train generat model complex data natur imag howev notori hard train suffer problem miss mode model abl produc exampl certain region space propos iter procedur call adagan everi step add new compon mixtur model run gan algorithm weight sampl inspir boost algorithm mani potenti weak individu predictor greedili aggreg form strong composit predictor prove analyt increment procedur lead converg true distribut finit number step step optim converg exponenti rate otherwis also illustr experiment procedur address problem miss mode
discov potenti influenc via inform bottleneck discov potenti influenc variabl anoth variabl fundament scientif practic interest exist correl measur suitabl discov averag influenc fail discov potenti influenc bridg gap postul set natur axiom expect measur potenti influenc satisfi show rate inform bottleneck hypercontract coeffici satisfi propos axiom iii provid novel estim estim hypercontract coeffici sampl numer experi demonstr propos estim discov potenti influenc various indic dataset robust discov gene interact gene express time seri data statist power estim correl measur binari hypothesi test canon potenti influenc
phase transit pool data problem code distribut comput invers problem comput intens distribut parallel comput often bottleneck small set slow worker known straggler paper util emerg idea code comput design novel error correct code inspir techniqu solv linear invers problem specif iter method parallel implement affect straggler exampl applic includ invers problem person pagerank sampl graph provabl show code comput techniqu reduc mean squar error comput deadlin constraint fact ratio mean squar error replic base code techniqu diverg infin deadlin increas experi person pagerank perform real system real social network show ratio larg 104 unlik code comput techniqu propos thus far strategi combin output worker includ straggler produc accur estim comput deadlin also ensur accuraci degrad grace event number straggler larg paper studi pool data problem identifi label associ larg collect item base sequenc pool test reveal count label within pool noiseless set exact recoveri identifi exact asymptot threshold requir number test optim decod prove phase transit complet success complet failur addit present novel noisi variat problem provid inform theoret framework character requir number test general nois model result reveal nois make problem consider difficult strict increas scale law even low nois level
queri complex cluster side inform suppos given set element cluster unknown cluster oracl interact answer pair wise queri form element belong cluster goal recov optimum cluster ask minimum number queri paper initi rigor theoret studi basic problem queri complex interact cluster provid strong inform theoret lower bound well near match upper bound cluster problem come similar matrix use autom process cluster similar point togeth howev obtain ideal similar function extrem challeng due ambigu data represent poor data qualiti etc primari reason make cluster hard improv accuraci cluster fruit approach recent year ask domain expert crowd obtain label data interact mani heurist propos use similar function come queri strategi howev systemat theoret studi main contribut paper show dramat power side inform aka similar matrix reduc queri complex cluster natur model similar matrix similar valu drawn independ arbitrari probabl distribut under pair element belong cluster otherwis show given similar matrix queri complex reduc drastic similar matrix log denot squar helling diverg moreov also inform theoret optim within logn factor algorithm effici paramet free work without knowledg depend logarithm
revisit fuzzi neural network demystifi batch normal relu general ham network revisit fuzzi neural network cornerston notion textit general ham distanc provid novel theoret justifi approach rectifi understand tradit neural comput turn mani use neural network method batch normal rectifi linear unit could interpret new framework rectifi general ham network gnn propos accord ghn lend rigiour analysi within fuzzi logic theori also demonstr superior perform varieti learn task term fast learn speed well control behaviour simpl paramet set
posterior sampl reinforc learn worst case regret bound present algorithm base posterior sampl aka thompson sampl achiev near optim worst case regret bound under markov decis process mdp communic finit though unknown diamet main result high probabl regret upper bound dsat communic mdp state action diamet s5a regret compar total reward achiev algorithm total expect reward optim infinit horizon undiscount averag reward polici time horizon result improv best previous known upper bound dsat achiev algorithm set match depend establish lower bound dsat problem
framework multi rmed andit test onlin fdr control propos altern framework exist setup control fals alarm multipl test run time setup aris mani practic applic pharmaceut compani test new treatment option control pill differ diseas internet compani test default webpag versus various altern time framework propos replac sequenc test sequenc best arm mab instanc continu monitor data scientist interleav mab test onlin fals discoveri rate fdr algorithm obtain best world low sampl complex time onlin fdr control main contribut propos reason definit null hypothesi mab instanc demonstr deriv alway valid sequenti valu allow continu monitor mab test iii show use reject threshold onlin fdr algorithm confid level mab algorithm result sampl optim high power low fdr point time run extens simul verifi claim also report result real data collect new yorker cartoon caption contest
mont carlo tree search best arm identif recent advanc bandit tool techniqu sequenti learn steadili enabl new applic promis resolut rang challeng relat problem studi game tree search problem goal quick identifi optim move given game tree sequenti sampl stochast payoff develop new algorithm tree arbitrari depth oper summar deeper level tree confid interv depth appli best arm identif procedur root prove new sampl complex guarante refin depend problem instanc show experiment algorithm outperform exist elimin base algorithm match previous special purpos method depth tree
minim explor structur stochast bandit paper introduc address wide class stochast bandit problem function map arm correspond reward exhibit known structur properti exist structur linear lipschitz unimod combinatori duel cover framework deriv asymptot instanc specif regret lower bound problem develop ossb algorithm whose regret match fundament limit ossb base classic principl optim face uncertainti thompson sampl rather aim match minim explor rate sub optim arm character deriv regret lower bound illustr effici ossb use numer experi case linear bandit problem show ossb outperform exist algorithm includ thompson sampl
regret analysi continu duel bandit duel bandit learn framework feedback inform learn process restrict noisi comparison pair action paper address duel bandit problem base cost function continu space propos stochast mirror descent algorithm show algorithm achiev sqrtt logt regret bound strong convex smooth assumpt cost function clarifi equival regret minim duel bandit convex optim cost function moreov consid lower bound convex optim turn algorithm achiev optim converg rate convex optim optim regret duel bandit except logarithm factor
elementari symmetr polynomi optim experiment design revisit classic problem optim experiment design o new mathemat model ground geometr motiv specif introduc model base elementari symmetr polynomi polynomi captur partial volum offer grade interpol wide use optim optim design model obtain special case analyz properti model deriv greedi convex relax algorithm comput associ design analysi establish approxim guarante algorithm empir result substanti claim demonstr curious phenomenon concern greedi algorithm final byproduct obtain new result theori elementari symmetr polynomi independ interest
onlin learn linear dynam system present effici practic algorithm onlin predict discret time linear dynam system despit non convex optim problem use improp learn convex relax algorithm come provabl guarante near optim regret bound compar best lds hindsight overparameter small logarithm factor analysi bring togeth idea improp learn convex relax onlin regret minim spectral theori hankel matric
effici flexibl infer stochast system mani real world dynam system describ stochast differenti equat thus paramet infer challeng import problem mani disciplin provid grid free flexibl algorithm offer paramet state infer stochast system compar approch base variat approxim state art method show signific advantag runtim accuraci
group spars addit machin famili learn algorithm generat addit model attract much attent recent flexibl interpret high dimension data analysi among learn model group variabl shown competit perform predict variabl select howev previous work main focus least squar regress problem classif task thus desir design new addit classif model variabl select capabl mani real world applic focus high dimension data classif address challeng problem paper investig classif group spars addit model reproduc kernel hilbert space novel classif method call emph group spars addit machin groupsam propos explor util structur inform among input variabl general error bound deriv prove integr sampl error analysi empir cover number hypothesi error estim step stone techniqu new bound show groupsam achiev satisfactori learn rate polynomi decay experiment result synthet data benchmark dataset consist show effect new approach
bregman diverg stochast varianc reduct saddl point adversari predict adversari machin learner compet adversari gain much recent interest machin learn natur form saddl point optim often separ structur sometim also unmanag larg dimens work show adversari predict multivari loss solv much faster use first reduc problem size exponenti use appropri suffici statist adapt new stochast varianc reduc algorithm balamurugan bach 2016 allow bregman diverg prove linear rate converg retain show adversari predict use diverg achiev speedup exampl time compar euclidean altern verifi theoret find extens experi exampl applic adversari predict lpboost
onlin multiclass boost recent work extend theoret analysi boost algorithm multiclass problem onlin set howev multiclass extens batch set onlin extens consid binari classif fill gap literatur defin justifi weak learn condit onlin multiclass boost condit lead optim boost algorithm requir minim number weak learner achiev certain accuraci addit propos adapt algorithm near optim enjoy excel perform real data due adapt properti
univers consist minimax rate onlin mondrian forest establish consist algorithm mondrian forest cite lakshminarayanan2014mondrianforest lakshminarayanan2016mondrianuncertainti random classif algorithm implement onlin first amend origin mondrian forest algorithm propos cite lakshminarayanan2014mondrianforest consid emph fix lifetim paramet inde fact paramet fix actual hinder statist consist origin procedur modifi mondrian forest algorithm grow tree increas lifetim paramet use altern updat rule allow work also onlin fashion second provid theoret analysi establish simpl condit consist theoret analysi also exhibit surpris fact algorithm achiev minimax rate optim rate estim lipschitz regress function strong extens previous result cite arlot2014purf_bia emph arbitrari dimens
mean teacher better role model weight averag consist target improv semi supervis deep learn result recent propos tempor ensembl achiev state art result sever semi supervis learn benchmark maintain exponenti move averag label predict train exampl penal predict inconsist target howev target chang per epoch tempor ensembl becom unwieldi learn larg dataset overcom problem propos mean teacher method averag model weight instead label predict addit benefit mean teacher improv test accuraci enabl train fewer label tempor ensembl mean teacher achiev error rate svhn 250 label better tempor ensembl 1000 label
learn complementari label collect label data cost thus critic bottleneck real world classif task mitig problem consid complementari label specifi class pattern belong collect complementari label would less labori ordinari label sinc user care choos correct class mani candid class howev complementari label less inform ordinari label thus suitabl approach need better learn complementari label paper show unbias estim classif risk obtain complementari label loss function satisfi particular symmetr condit theoret prove estim error bound propos method experiment demonstr use propos algorithm
posit unlabel learn non negat risk estim emph posit emph unlabel data binari classifi train learn state art emph unbias learn howev model flexibl empir risk train data negat suffer serious overfit paper propos emph non negat risk estim learn minim robust overfit thus abl train flexibl model given limit data moreov analyz emph bias emph consist emph mean squar error reduct propos risk estim emph estim error correspond risk minim experi show propos risk estim success fix overfit problem unbias counterpart
semisupervis cluster queri local encod sourc code sourc code canon problem data compress inform theori local encod sourc code compress bit depend bit input paper show recent popular model semisupervis cluster equival local encod sourc code model task perform multiclass label unlabel element begin ask parallel set simpl queri oracl provid possibl erron binari answer queri queri cannot involv fix constant number element label element cluster must done base noisi queri answer goal recov correct label minim number queri equival local encod sourc code lead find lower bound number queri requir varieti scenario also abl show fundament limit pairwis cluster queri propos pairwis queri provabl perform better
learn error structur predict approxim infer work tri understand differ exact approxim infer algorithm structur predict compar estim approxim error underestim overestim model result show perspect learn error perform approxim infer could good exact infer error analys also suggest new margin exist learn algorithm empir evalu text classif sequenti label depend pars wit success approxim infer benefit propos margin
optim generaliz parametr learn consid parametr learn problem object learner determin parametr loss function employ empir risk minim possibl regular infer paramet vector bias toward train sampl bias measur cross valid procedur practic data set partit train set use train valid set use train left measur sampl perform classic cross valid strategi leav cross valid loocv sampl left valid train done rest sampl present learner process repeat sampl loocv rare use practic due high comput complex paper first develop comput effici approxim loocv aloocv provid theoret guarante perform use aloocv provid optim algorithm find optim regular empir risk minim framework numer experi illustr accuraci effici aloocv well propos framework optim regular
multi object non parametr sequenti predict onlin learn research main focus minim object function mani real world applic howev sever object function consid simultan recent algorithm deal sever object function case present paper extend multi object framework case stationari ergod process thus allow depend among observ first identifi asymptomat lower bound predict strategi present algorithm whose predict achiev optim solut fulfil continu convex constrain criterion
fix rank approxim posit semidefinit matrix stream data sever import applic stream pca semidefinit program involv larg scale posit semidefinit psd matrix present sequenc linear updat storag limit possibl retain sketch psd matrix paper develop new algorithm fix rank psd approxim sketch approach combin nystr approxim novel mechan rank truncat theoret analysi establish propos method achiev prescrib relat error schatten norm exploit spectral decay input matrix comput experi show propos method domin altern techniqu fix rank psd matrix approxim across wide rang exampl
communic effici stochast gradient descent applic neural network parallel implement stochast gradient descent sgd receiv signific research attent thank excel scalabl properti fundament barrier parallel sgd high bandwidth cost communic gradient updat node consequ sever lossi compres heurist propos node communic quantiz gradient although effect practic heurist alway guarante converg clear whether improv paper propos quantiz sgd qsgd famili compress scheme gradient updat provid converg guarante qsgd allow user smooth trade emph communic bandwidth emph converg time node adjust number bit sent per iter cost possibl higher varianc show trade inher sens improv past threshold would violat inform theoret lower bound qsgd guarante converg convex non convex object asynchroni extend stochast varianc reduc techniqu appli train deep neural network imag classif autom speech recognit qsgd lead signific reduct end end train time exampl 16gpus train resnet152 network full accuraci imagenet faster full precis variant
machin learn adversari byzantin toler gradient descent studi resili byzantin failur distribut implement stochast gradient descent sgd far distribut machin learn framework larg ignor possibl failur especi arbitrari byzantin one caus failur includ softwar bug network asynchroni bias local dataset well attack tri compromis entir system assum set worker byzantin ask resili sgd without limit dimens size paramet space first show gradient aggreg rule base linear combin vector propos worker current approach toler singl byzantin failur formul resili properti aggreg rule captur basic requir guarante converg despit byzantin worker propos emph krum aggreg rule satisfi resili properti argu first provabl byzantin resili algorithm distribut sgd also report experiment evalu krum
rank data continu label orient recurs partit formul supervis learn problem refer continu rank continu real valu label assign observ take valu featur space goal order possibl observ mean score function tend increas decreas togeth highest probabl problem general multi partit rank certain extent task find optim score function natur cast optim dedic function cri terion call iroc curv maxim kendal relat pair theoret side describ optim element problem provid statist guarante empir kendal maximiza tion appropri condit class score function candid also propos recurs statist learn algorithm tailor empir iroc curv optim produc piecewis constant score function fulli describ orient binari tree preliminari numer experi highlight differ natur regress continu rank provid strong empir evid perform empir optim criteria propos
practic data depend metric compress provabl guarante introduc new distanc preserv compact represent multi dimension point set given point dimension space coordin repres use bit bit per point produc represent size log epsilon log bit per point approxim distanc factor epsilon algorithm almost match recent bound indyk 2017 much simpler compar algorithm product quantize jegou 2011 state art heurist metric compress method evalu algorithm sever data set sift mnist new york citi taxi time seri synthet dimension data set embed high dimension space algorithm produc represent compar better produc provabl guarante perform
simpl strategi recov inner product coars quantiz random project random project increas adopt divers set task machin learn involv dimension reduct specif line research topic investig use quantize subsequ project aim addit data compress motiv applic nearest neighbor search linear learn revisit problem recov inner product respect cosin similar set show even coars scalar quantize bit per project loss accuraci tend rang neglig tomoder implic scenario practic interest need sophist recoveri approach like maximum likelihood estim consid previous work subject propos herein also yield consider improv term accuraci ham distanc base approach icml 2014 compar term simplic
cluster stabl instanc euclidean mean euclidean mean problem arguabl wide studi cluster problem machin learn mean object hard worst case practition enjoy remark success appli heurist like lloyd algorithm problem address disconnect studi follow question properti real world instanc enabl design effici algorithm prove guarante find optim cluster consid natur notion call addit perturb stabil believ captur mani practic instanc euclidean mean cluster stabl instanc uniqu optim mean solut chang even point perturb littl euclidean distanc captur properti mean optim solut toler measur error uncertainti point design effici algorithm provabl recov optim cluster instanc addit perturb stabl instanc addit separ design simpl effici algorithm provabl guarante also robust outlier also complement result studi amount stabil real dataset demonstr algorithm perform well benchmark dataset
distribut hierarch cluster graph cluster fundament task mani data mine machin learn pipelin particular identifi good hierarch structur time fundament challeng problem sever applic amount data analyz increas astonish rate day henc need new solut effici comput effect hierarch cluster huge data main focus paper minimum span tree mst base cluster particular propos affin novel hierarch cluster base boruvka mst algorithm prove certain theoret guarante affin well classic algorithm show practic superior sever state art cluster algorithm furthermor present mapreduc algorithm affin first work case input graph dens take constant round base mst algorithm dens graph improv upon prior work karloff second algorithm assumpt densiti input graph find affin cluster log round use distribut hash tabl dhts show experiment algorithm scalabl huge data set
spars mean embed mean cluster algorithm ubiquit tool data mine machin learn show promis perform howev high comput cost hinder applic broad domain research success address obstacl dimension reduct method recent cite dblp journal tit boutsidiszmd15 develop state art random project method faster mean cluster method deliv mani improv dimension reduct method exampl compar advanc singular valu decomposit base featur extract approach cite dblp journal tit boutsidiszmd15 reduc run time factor min 2log data matrix data point featur lose factor approxim accuraci unfortun still requir ndk2log matrix multipl cost prohibit larg valu break bottleneck care build spars embed mean cluster algorithm requir nnz nnz denot number non zero fast matrix multipl moreov propos algorithm improv cite dblp journal tit boutsidiszmd15 result approxim accuraci factor empir studi corrobor theoret find demonstr approach abl signific acceler mean cluster achiev satisfactori cluster perform
medoid mean seed show experiment algorithm claran han 1994 find better medoid solut voronoi iter algorithm hasti 2001 find along similar voronoi iter algorithm lloyd mean algorithm motiv use claran mean initi show claran outperform algorithm dataset mean decreas mean initi mean squar error mse final mse introduc algorithm improv claran improv complex runtim make extrem viabl initi scheme larg dataset
appli algorithm foundat hierarch cluster hierarch cluster data analysi method use decad despit widespread use lack analyt foundat method foundat would support method current use guid futur improv paper give appli algorithm foundat hierarch cluster goal paper give analyt framework support observ seen practic paper consid dual problem framework hierarch cluster introduc dasgupta main result popular algorithm use practic averag linkag agglom cluster small constant approxim ratio paper establish use recurs mean divis cluster poor lower bound approxim ratio perhap explain popular practic motiv poor perform mean seek find divis algorithm perform well theoret paper give constant approxim algorithm paper repres first work give foundat hierarch cluster algorithm use practic
inhomogoen hypergraph cluster applic hypergraph partit import problem machin learn comput vision network analyt wide use method hypergraph partit reli minim normal sum cost partit hyperedg across cluster algorithm solut base approach assum differ partit hyperedg incur cost howev assumpt fail leverag fact differ subset vertic within hyperedg differ structur import henc propos new hypergraph cluster techniqu term inhomogen hypergraph partit assign differ cost differ hyperedg cut prove inhomogen partit produc quadrat approxim optim solut inhomogen cost satisfi submodular constraint moreov demonstr inhomogen partit offer signific perform improv applic structur learn rank subspac segment motif cluster
subspac cluster via tangent cone given sampl lie near number fix subspac subspac cluster task group sampl base correspond subspac mani subspac cluster method oper assign affin pair point feed affin common cluster algorithm paper propos new paradigm subspac cluster comput affin base under conic geometri union subspac propos conic subspac cluster csc approach consid convex hull collect normal data point tangent cone sampl union subspac under data impos strong associ tangent cone point origin subspac contain addit describ novel geometr perspect paper provid practic algorithm subspac cluster leverag perspect tangent cone membership test estim affin algorithm accompani determinist stochast guarante properti learn affin matrix direct translat overal cluster accuraci
tensor biclust consid dataset data collect multipl featur multipl individu multipl time type data repres dimension individu featur time tensor becom increas promin various area scienc tensor biclust problem comput subset individu subset featur whose signal trajectori time lie low dimension subspac model similar among signal trajectori allow differ scale across differ individu differ featur studi inform theoret limit problem generat model moreov propos effici spectral algorithm solv tensor biclust problem analyz achiev bound asymptot regim final show effici propos method sever synthet real dataset
unifi approach interpret model predict understand model made certain predict crucial mani applic howev larg modern dataset best accuraci often achiev complex model even expert struggl interpret ensembl deep learn model creat tension accuraci interpret respons varieti method recent propos help user interpret predict complex model present unifi framework interpret predict name shap shapley addit explan assign featur import particular predict key compon shap framework identif class addit featur import measur theoret result uniqu solut class set desir properti class unifi exist method sever recent method class desir properti mean framework inform develop new method explain predict model demonstr sever new method present paper base shap framework show better comput perform better consist human intuit exist method
effici sublinear regret algorithm onlin spars linear regress onlin spars linear regress task appli linear regress analysi exampl arriv sequenti subject resourc constraint limit number featur exampl observ despit import mani practic applic recent shown polynomi time sublinear regret algorithm unless bpp exponenti time sublinear regret algorithm known paper introduc mild assumpt solv problem assumpt present polynomi time sublinear regret algorithm onlin spars linear regress addit thorough experi public avail data demonstr algorithm outperform known algorithm
unbias estim linear regress via volum sampl given full rank matrix column row consid task estim pseudo invers base pseudo invers sampl subset column size least number row show possibl subset column chosen proport squar volum span row chosen submatrix volum sampl result estim unbias surpris covari estim also close form equal specif factor time pseudo invers play import part solv linear least squar problem tri predict label column assum label expens given label small subset column sampl use method show weight vector solut sub problem unbias estim optim solut whole problem base column label believ new formula establish fundament connect linear least squar volum sampl use method obtain algorithm volum sampl faster state art obtain bound total loss estim least squar solut label column
separ loss function revisit discrimin generat model revisit classic analysi generat discrimin model general exponenti famili high dimension set toward develop novel technic machineri includ notion separ general loss function allow provid general framework obtain converg rate general estim use machineri analyz converg rate generat discrimin model provid insight nuanc behavior high dimens result also applic differenti paramet estim quantiti interest differ generat model paramet
general linear model regress distanc set penalti estim general linear model glm complic presenc constraint handl constraint maxim penal log likelihood penalti lasso effect high dimens often lead sever shrinkag paper explor instead penal squar distanc constraint set distanc penalti flexibl algebra regular penalti avoid drawback shrinkag optim distanc penal object make use major minim principl result algorithm construct within framework amen acceler come global converg guarante applic shape constraint spars regress rank restrict matrix regress synthet real data showcas strong empir perform distanc penal even non convex constraint
group addit structur identif kernel nonparametr regress addit model popular use model high dimension nonparametr regress analysi howev main drawback neglect possibl interact predictor variabl paper reexamin group addit model propos literatur rigor defin intrins group addit structur relationship respons variabl
predictor vector vectx develop effect structur penal kernel method simultan identif intrins group addit structur nonparametr function estim method util novel complex measur deriv group addit structur show propos method consist identifi intrins group addit structur simul studi real data applic demonstr effect propos method general tool high dimension nonparametr regress
learn overcomplet hmms studi basic problem learn overcomplet hmms mani hidden state small output alphabet despit signific practic import hmms poor understood known posit negat result effici learn paper present sever new result posit negat help defin boundari tractabl learn set intract set show posit result larg subclass hmms whose transit matric spars well condit small probabl mass short cycl also show learn imposs given polynomi number sampl hmms small output alphabet whose transit matric random regular graph larg degre
matrix norm estim entri singular valu data matrix form provid insight structur data effect dimension choic hyper paramet higher level data analysi tool howev mani practic applic collabor filter network analysi get partial observ scenario consid fundament problem recov various spectral properti under matrix sampl entri propos framework first estim schatten norm matrix sever valu use surrog estim spectral properti interest spectrum rank paper focus technic challeng accur estim schatten norm sampl matrix introduc novel unbias estim base count small structur graph provid guarante match empir perform theoret analysi show schatten norm recov accur strict smaller number sampl compar need recov under low rank matrix numer experi suggest signific improv upon compet approach use matrix complet method
optim shrinkag singular valu random data contamin low rank matrix contamin uniform distribut nois miss valu outlier corrupt entri reconstruct singular valu singular vector contamin matrix key problem machin learn comput vision data scienc paper show common contamin model includ arbitrari combin uniform nois miss valu outlier corrupt entri describ effici use singl framework develop asymptot optim algorithm estim manipul singular valu appli contamin model consid final find explicit signal nois cutoff estim singular valu decomposit must fail well defin sens
new theori nonconvex matrix complet preval matrix complet theori repli assumpt locat miss data distribut uniform random uniform sampl nevertheless reason observ miss often depend unseen observ thus miss data practic usual occur nonuniform fashion rather random break limit random assumpt paper introduc new hypothesi call isomer condit provabl weaker random assumpt arguabl hold even miss data place irregular equip new tool prove seri theorem miss data recoveri matrix complet particular prove exact solut identifi target matrix includ critic point common use nonconvex program unlik exist nonconvex theori use condit convex program theori show nonconvex program work much weaker condit compar exist theori nonuniform sampl theori flexibl power
learn low dimension metric paper investig theoret foundat metric learn focus key question fulli address prior work consid learn general low dimension low rank metric well spars metric develop upper lower minimax bound general error quantifi sampl complex metric learn term dimens featur space dimens rank under metric also bound accuraci learn metric relat under true generat metric result involv novel mathemat approach metric learn problem also shed new light special case ordin embed aka non metric multidimension scale
fast altern minim algorithm dictionari learn present theoret guarante altern minim algorithm dictionari learn spars code problem dictionari learn problem factor sampl appropri basi dictionari time spars vector algorithm simpl altern minim procedur switch gradient descent minim everi step dictionari learn specif altern minim algorithm dictionari learn well studi theoret empir howev contrast previous theoret analysi problem replac condit oper norm true under dictionari condit matrix infin norm allow get converg rate term error estim dictionari infin norm also allow initi random converg global optimum guarante reason generat model allow dictionari grow oper norm handl arbitrari level overcomplet sparsiti inform theoret optim incoher dictionari also present statist guarante present sampl complex guarante algorithm
consist robust regress present first effici provabl consist estim robust regress problem area robust learn optim generat signific amount interest learn statist communiti recent year owe applic scenario corrupt data well handl model mis specif particular special interest devot fundament problem robust linear regress estim toler corrupt constant fraction respons variabl wide studi surpris howev date awar polynomi time estim offer consist estim presenc dens unbound corrupt work present estim call crr solv open problem put forward work bhatia 2015 consist analysi requir novel stage proof techniqu involv care analysi stabil order list independ interest show crr offer consist estim empir far superior sever recent propos algorithm robust regress problem includ extend lasso torrent algorithm comparison crr offer compar better model recoveri runtim faster order magnitud
partial hard threshold toward unifi analysi support recoveri machin learn compress sens central import understand tractabl algorithm recov support spars signal compress measur paper present toward principl analysi support recoveri perform famili hard threshold algorithm end appeal partial hard threshold pht oper propos recent jain ieee tran inform theori 2017 show proper condit pht recov arbitrari spars signal within slog iter condit number special pht oper obtain best known result hard threshold pursuit orthogon match pursuit replac experi simul data complement theoret find also illustr interest phase transit iter number cannot signific reduc
minimax estim bandabl precis matric invers covari matrix provid consider insight understand statist model multivari set particular distribut variabl assum multivari normal sparsiti pattern invers covari matrix common refer precis matrix correspond adjac matrix represent gauss markov graph encod condit independ statement variabl minimax result spectral norm previous establish covari matric spars band spars precis matric establish minimax estim bound estim band precis matric spectral norm result great improv upon exist bound particular find minimax rate estim band precis matric match estim band covari matric key insight analysi abl obtain bare noisi estim time subblock precis matrix invert slight wider block empir covari matrix along diagon theoret result complement experi demonstr sharp bound
diffus approxim onlin princip compon estim global converg paper propos adopt diffus approxim tool studi dynam oja iter onlin stochast gradient method princip compon analysi oja iter maintain run estim true princip compon stream data enjoy less tempor spatial complex show oja iter top eigenvector generat continu state discret time markov chain unit sphere character oja iter phase use diffus approxim weak converg tool phase analysi provid finit sampl error bound run estim match minimax inform lower bound pca bound nois
estim covari structur heavi tail distribut propos analyz new estim covari matrix admit strong theoret guarante weak assumpt under distribut exist moment low order estim covari matric correspond sub gaussian distribut well understood much less known case heavi tail data balasubramanian yuan write data real world experi oftentim tend corrupt outlier exhibit heavi tail case clear covari matrix estim remain optim possibl strategi deal heavi tail distribut warrant studi make step toward answer question prove tight deviat inequ propos estim depend paramet control intrins dimens associ covari matrix oppos dimens ambient space particular result applic case high dimension observ
learn koopman invari subspac dynam mode decomposit spectral decomposit koopman oper attract attent tool analysi nonlinear dynam system dynam mode decomposit popular numer algorithm koopman spectral analysi howev often need prepar nonlinear observ manual accord under dynam alway possibl sinc priori knowledg paper propos fulli data driven method koopman spectral analysi base principl learn koopman invari subspac observ data end propos minim residu sum squar linear least squar regress estim set function transform data form linear regress fit well introduc implement neural network evalu perform empir use nonlinear dynam system applic
tochast approxim canon correl analysi propos novel first order stochast approxim algorithm canon correl analysi cca algorithm present instanc noisi matrix stochast gradient msg noisi matrix exponenti gradient meg achiev suboptim popul object time poli probabl least input dimension also consid practic variant propos algorithm compar method cca theoret empir
dive shallow comput perspect larg scale shallow learn remark recent success deep neural network easi analyz theoret particular hard disentangl relat signific architectur optim achiev accur classif larg dataset flip side shallow method kernel method encount obstacl scale larg data practic method variant gradient descent use success deep learn seem perform par appli kernel method difficulti sometim attribut limit shallow architectur paper first identifi basic limit gradient descent base optim method use conjunct smooth kernel analysi demonstr vanish small fraction function space reachabl polynomi number gradient descent iter drastic limit approxim power gradient descent fix comput budget lead serious regular issu pure algorithm persist even limit infinit data address shortcom practic introduc eigenpro iter base simpl direct precondit scheme use small number approxim eigenvector also view learn new kernel optim gradient descent turn inject small amount approxim second order inform lead major improv converg larg data translat signific perform boost state art kernel method particular abl match improv result recent report literatur small fraction comput budget final feel result show need broader comput perspect modern larg scale learn complement tradit statist converg analys
unreason effect structur random orthogon embed examin class embed base structur random matric orthogon row appli mani machin learn applic includ dimension reduct kernel approxim johnson lindenstrauss transform angular kernel show select matric yield guarante improv perform accuraci speed compar earlier method introduc matric complex entri give signific accuraci improv provid geometr markov chain base perspect help understand benefit empir result suggest approach help wider rang applic
general properti learn random featur studi general properti ridg regress random featur statist learn framework show first time learn bound achiev
nlog random featur rather suggest previous result prove faster learn rate show might requir random featur unless sampl accord possibl problem depend distribut result shed light statist comput trade off larg scale kernel learn show potenti effect random featur reduc comput complex keep optim general properti
gaussian quadratur kernel featur kernel method recent attract resurg interest match perform deep neural network task speech recognit random fourier featur map techniqu common use scale kernel machin employ random featur map mean sampl requir achiev approxim error paper investig altern scheme construct featur map determinist rather random approxim kernel frequenc domain use gaussian quadratur show determinist featur map construct achiev error sampl goe valid method dataset differ domain mnist timit show determinist featur faster generat achiev compar accuraci state art kernel method base random fourier featur
linear time kernel good fit test propos novel adapt test good fit comput cost linear number sampl learn test featur best indic differ observ sampl refer model minim fals negat rate featur construct via stein method mean necessari comput normalis constant model analys asymptot bahadur effici new test prove mean shift altern test alway greater relat effici previous linear time kernel test regardless choic paramet test experi perform method exceed earlier linear time test match exceed power quadrat time kernel test high dimens model structur exploit good fit test perform far better quadrat time sampl test base maximum mean discrep sampl drawn model
converg rate partit base bayesian multivari densiti estim method studi class non parametr densiti estim bayesian set estim obtain adapt partit sampl space suitabl prior analyz concentr rate posterior distribut demonstr rate direct depend dimens problem sever special case anoth advantag class bayesian densiti estim adapt unknown smooth true densiti function thus achiev optim conv
power absolut discount dimension distribut estim categor model natur fit mani problem learn distribut categori sampl high dimension dilut data minimax optim pessimist remedi issu serendipit discov estim absolut discount correct empir frequenc subtract constant observ categori redistribut among unobserv outperform classic estim empir use extens natur languag model paper rigor explain prowess estim use less pessimist notion show absolut discount recov classic minimax risk rate emph adapt effect dimens rather true dimens strong relat good ture estim inherit emph competit properti use power law distribut corner stone result valid theori via synthet data applic global terror databas
optim learn popul paramet consid follow fundament estim problem entiti unknown paramet observ independ random variabl binomi accur recov histogram cumul densiti function empir estim would recov histogram earth mover distanc equival distanc cdfs show provid suffici larg achiev error inform theoret optim also extend result multi dimension paramet case captur set member popul multipl associ paramet beyond theoret result demonstr recoveri algorithm perform well practic varieti dataset provid illumin insight sever domain includ polit sport analyt
communic effici distribut learn discret distribut initi systemat studi distribut learn densiti estim distribut model problem data drawn unknown distribut partit across multipl machin machin must succinct communic refere end refere estim under distribut data problem motiv press need build communic effici protocol various distribut system power consumpt limit bandwidth impos stringent communic constraint give first upper lower bound communic complex nonparametr densiti estim discret probabl distribut distanc specif result includ follow case unknown distribut arbitrari machin sampl show interact protocol learn distribut must essenti communic entir sampl case structur distribut
histogram monoton design distribut protocol achiev better communic guarante trivial one show tight bound regim
improv dynam regret non degeneraci function recent grow research interest analysi dynam regret measur perform onlin learner sequenc local minim exploit strong convex previous studi shown dynam regret upper bound path length compar sequenc paper illustr dynam regret improv allow learner queri gradient function multipl time meanwhil strong convex weaken non degeneraci condit specif introduc squar path length could much smaller path length new regular compar sequenc multipl gradient access learner first demonstr dynam regret strong convex function upper bound minimum path length squar path length extend theoret guarante function semi strong convex self concord best knowledg first time semi strong convex self concord util tighten dynam regret
paramet free onlin learn via model select introduc new framework deriv effici algorithm obtain model select oracl inequ adversari onlin learn set also sometim describ paramet free onlin learn work area focus specif high structur function class nest ball hilbert space eschew approach propos generic meta algorithm framework achiev oracl inequ minim structur assumpt allow deriv new comput effici algorithm oracl bound wide rang set result previous unavail give first comput effici algorithm work arbitrari banach space mild smooth assumpt previous result appli hilbert case deriv new oracl inequ various matrix class non nest convex set generic regular final general provid oracl inequ arbitrari non linear class contextu learn model particular give new algorithm learn multipl kernel result deriv unifi meta algorithm scheme base novel multi scale algorithm predict expert advic base random playout independ interest
fast rate bandit optim upper confid frank wolf consid problem bandit optim inspir stochast optim onlin learn problem bandit feedback problem object minim global loss function action necessarili cumul loss framework allow studi general class problem applic statist machin learn field solv problem analyz upper confid frank wolf algorithm inspir techniqu bandit convex optim give theoret guarante perform algorithm various class function discuss optim result
onlin learn transduct regret studi onlin learn general notion transduct regret regret modif rule appli expert sequenc oppos singl expert represent weight finit state transduc show transduct regret general exist notion regret includ extern regret intern regret swap regret condit swap regret present general onlin learn algorithm minim transduct regret extend work design effici algorithm time select sleep expert set product studi algorithm swap regret mild assumpt effici exist method
multi arm bandit metric movement cost consid non stochast multi arm bandit problem set fix known metric action space determin cost switch pair action loss onlin learner compon first usual loss select action second addit loss due switch action main contribut give tight character expect minimax regret set term complex measur under metric depend cover number finit metric space max setc1 3t2 show best possibl regret bound general previous known regret bound special case unit switch cost regret max setk1 3t2 interv metric regret max sett2 infinit metric space lipschitz loss function deriv tight regret bound minkowski dimens space known tight even switch cost
differenti privat empir risk minim revisit faster general paper studi differenti privat empir risk minim erm differ set smooth strong convex loss function without non smooth regular give algorithm achiev either optim near optim util bound less gradient complex compar previous work erm smooth convex loss function high dimens set give algorithm achiev upper bound less gradient complex previous one last general expect excess empir risk convex polyak lojasiewicz condit give tighter upper bound util compar result cite dblp journal corr zhangzmw17
certifi defens data poison attack machin learn system train user provid data suscept data poison attack wherebi malici user inject data aim corrupt learn model recent work propos number attack defens littl understood worst case perform defens face determin attack remedi construct upper bound loss across broad famili attack defend oper via outlier remov follow empir risk minim bound come pair candid attack near realiz upper bound give power tool quick assess defens given dataset empir find even simpl defens mnist dogfish dataset certifi resili attack contrast imdb sentiment dataset driven test error ad poison data
spars approxim conic hull consid problem comput restrict nonneg matrix factor nmf matrix specif seek factor column subset equival given matrix consid problem find small subset column conic hull ep approxim conic hull column distanc everi column conic hull column ep fraction angular diamet size smallest ep approxim produc eps2 size eps1 approxim yield first provabl polynomi time ep approxim class nmf problem also desir approxim independ furthermor prove approxim conic caratheodori theorem general sparsiti result show column ep approxim eps2 spars combin result facilit reduct problem approxim convex hull prove convex conic hull variant sum hard resolv open problem final provid experiment result convex conic algorithm varieti featur select task
estim high dimension non gaussian multipl index model via stein lemma consid estim parametr compon semi parametr multipl index model high dimension non gaussian set estim leverag score function base second order stein lemma requir gaussian ellipt symmetri assumpt made literatur show estim achiev near optim statist rate converg even score function respons variabl heavi tail util data driven truncat argument base requir concentr result establish supplement theoret result via simul experi confirm theori
solid harmon wavelet scatter predict quantum molecular energi invari descriptor electron densiti introduc solid harmon wavelet scatter represent invari rigid movement stabl deform regress classif imag solid harmon wavelet comput multipli solid harmon function gaussian window dilat differ scale invari scatter coeffici obtain cascad wavelet transform complex modulus nonlinear studi applic solid harmon scatter invari estim quantum molecular energi also invari rigid movement stabl respect deform introduc neural network multipl non linear regress scatter invari provid close state art result databas organ molecul
cluster billion read dna data storag store data synthet dna offer possibl improv inform densiti durabl sever order magnitud compar current storag technolog howev dna data storag requir comput intens process retriev data particular crucial step data retriev pipelin involv cluster billion string respect edit distanc observ dataset domain mani notabl properti contain larg number small cluster well separ edit distanc metric space regim exist algorithm unsuit either long run time low accuraci address issu present novel distribut algorithm approxim comput under cluster algorithm converg effici dataset satisfi certain separ properti come dna storag system also prove assumpt algorithm robust outlier high level nois provid empir justif accuraci scalabl converg algorithm real synthet data compar state art algorithm cluster dna sequenc algorithm simultan achiev higher accuraci 1000x speedup real dataset
deep recurr neural network base identif precursor microrna microrna mirna small non code ribonucl acid rnas play key role post transcript gene regul direct identif matur mirna infeas due short length research instead aim identifi precursor mirna pre mirna mani known pre mirna distinct stem loop secondari structur structur base filter usual first step predict possibl given sequenc pre mirna identifi new pre mirna often non canon structur howev need consid addit featur structur obtain addit characterist exist comput method reli manual featur extract inevit limit effici robust general comput identif address limit exist approach propos pre mirna identif method incorpor deep recurr neural network rnn autom featur learn classif multimod architectur seamless integr prior knowledg secondari structur attent mechan improv long term depend model rnn base class activ map highlight learn represent contrast pre mirna non pre mirna experi recent benchmark propos approach outperform compar state art altern term various perform metric
decod valu network neural machin translat neural machin translat nmt becom popular technolog recent year beam search facto decod method due shrunk search space reduc comput complex issu beam search sinc search local optima time step step forward look usual cannot output best target sentenc inspir success methodolog alphago paper propos use predict network improv beam search take sourc sentenc current avail decod output candid word step input predict long term valu bleu score partial target sentenc complet nmt model follow practic reinforc learn call predict network emph valu network specif propos recurr structur valu network train paramet bilingu data test time choos word decod consid condit probabl given nmt model long term valu predict valu network experi show approach signific improv translat accuraci translat task english french translat chines english translat
toward imagenet cnn nlp pretrain sentenc encod machin translat comput vision benefit initi multipl deep layer weight pre train larg supervis train set like imagenet contrast deep model languag task current benefit transfer unsupervis word vector random initi higher layer paper use encod attent sequenc sequenc model train machin translat initi model differ languag task show transfer improv perform use word vector wide varieti common nlp task sentiment analysi sst imdb question classif entail snli question answer squad
deep voic multi speaker neural text speech introduc techniqu augment neural text speech tts low dimension trainabl speaker embed generat differ voic singl model start point show improv state art approach singl speaker neural tts deep voic tacotron introduc deep voic base similar pipelin deep voic construct higher perform build block demonstr signific audio qualiti improv deep voic improv tacotron introduc post process neural vocod demonstr signific audio qualiti improv demonstr techniqu multi speaker speech synthesi deep voic tacotron multi speaker tts dataset show singl neural tts system learn hundr uniqu voic less half hour data per speaker achiev high audio qualiti synthesi preserv speaker ident almost perfect
modul earli visual process languag common assum languag refer high level visual concept leav low level visual process unaffect view domin current literatur comput model languag vision task visual linguist input most process independ fuse singl represent paper deviat classic pipelin propos modul emph entir visual process linguist input specif condit batch normal paramet pretrain residu network languag embed approach call modul residu network mrn signific improv strong baselin visual question answer task ablat studi show modul earli stage visual process benefici
multimod learn reason visual question answer reason entiti relationship multimod data key goal artifici general intellig visual question answer vqa problem excel way test reason capabl model multimod represent learn howev current vqa model oversimplifi deep neural network compris long short term memori lstm unit question comprehens convolut neural network cnn learn singl imag represent argu singl visual represent contain limit general inform imag content thus limit model reason capabl work introduc modular neural network model learn multimod multifacet represent imag question propos model learn use multimod represent reason imag entiti achiev new state art perform vqa benchmark dataset vqa wide margin
learn model tail describ approach learn long tail imbalanc dataset preval real world set challeng learn accur shot model class tail littl data avail cast problem transfer learn knowledg data rich class head transfer data poor class tail key insight follow first propos transfer meta knowledg learn learn head knowledg encod meta network oper space model paramet train predict mani shot model paramet shot model paramet second transfer meta knowledg progress manner class head thebodi bodi tail transfer knowledg gradual fashion regular meta network shot regress train train data allow final network captur dynam transfer meta knowledg data rich data poor regim demonstr result imag classif dataset sun place imagenet tune long tail set signific outperform widespread heurist data resampl reweight
interpret global optim predict textual ground use imag concept textual ground import challeng task human comput interact robot knowledg mine exist algorithm general formul task select solut set bound box propos obtain deep net base system work demonstr cast problem textual ground unifi framework permit effici search possibl bound box henc abl consid signific propos due unifi formul approach reli success first stage beyond demonstr train paramet model use word embed captur spatial imag relationship provid interpret last approach outperform current state art method flickr 30k entiti referitgam dataset respect
multiscal quantize fast similar search propos multiscal quantize approach fast similar search larg high dimension dataset key insight approach quantize method particular product quantize perform poor varianc norm data point common scenario real world dataset especi product quantize residu obtain coars vector quantize address issu propos multiscal formul learn separ scalar quantize residu norm paramet learn joint stochast gradient descent framework minim overal quantize error provid theoret motiv propos techniqu conduct comprehens experi larg scale public dataset demonstr substanti improv recal exist state art method
maskrnn instanc level video object segment instanc level video object segment import techniqu video edit compress captur tempor coher paper develop maskrnn recurr neural net approach fuse frame output deep net object instanc binari segment net provid mask local net provid bound box due recurr compon local compon method abl take advantag long term tempor structur video data well reject outlier valid propos algorithm challeng benchmark dataset davi 2016 dataset davi 2017 dataset segtrack dataset achiev state art perform
flat2spher learn spheric convolut fast featur 360 imageri 360 camera offer tremend new possibl vision graphic augment realiti spheric imag produc make core featur extract non trivial convolut neural network cnns train imag perspect camera yield flat filter yet 360 imag cannot project singl plane without signific distort naiv solut repeat project view sphere tangent plane accur much comput intens real problem propos learn spheric convolut network translat planar cnn process 360 imageri direct equirectangular project approach learn reproduc flat filter output 360 data sensit vari distort effect across view sphere key benefit effici featur extract 360 imag video abil leverag power pre train network research care hone togeth massiv label imag train set perspect imag valid approach compar sever altern method term raw cnn output accuraci well appli state art flat object detector 360 data method yield accur result save order magnitud comput versus exist exact reproject solut
deep mean shift prior imag restor paper introduc natur imag prior direct repres gaussian smooth version natur imag distribut includ prior formul imag restor bay estim also allow solv nois blind imag restor problem gradient bound estim involv gradient logarithm prior gradient correspond mean shift vector natur imag distribut learn mean shift vector field use denois autoencod demonstr competit result nois blind deblur super resolut demosa
pixel graph associ embed graph use abstract imag content graph repres detail individu object scene captur interact pair object present method train convolut neural network take input imag produc full graph definit done end end singl stage use associ embed network learn simultan identifi element make graph piec togeth benchmark visual genom dataset demonstr state art perform challeng task scene graph generat
shape reconstruct model sketch object reconstruct singl imag high determin problem requir strong prior knowledg plausibl shape introduc challeng learn base approach object annot real imag scarc previous work chose train synthet data ground truth inform suffer domain adapt issu test real data work propos end end trainabl framework sequenti estim sketch object shape disentangl step formul advantag first compar full shape sketch much easier recov imag transfer synthet real imag second reconstruct sketch easili transfer learn model synthet data real imag render sketch invari object appear variat real imag includ light textur etc reliev domain adapt problem third deriv differenti project function shape sketch make framework end end trainabl real imag requir real imag annot framework achiev state art perform shape reconstruct
tempor coher base criteria predict video frame use deep multi stage generat adversari network predict futur sequenc video frame recent sought yet challeng task field comput vision machin learn although effort track use motion trajectori flow featur complex problem generat unseen frame studi extens paper deal problem use convolut model within multi stage generat adversari network gan framework propos method use stage gan generat crisp clear set futur frame although gan use past predict futur none work consid relat subsequ frame tempor dimens main contribut lie formul object function base normal cross correl ncc pairwis contrast diverg pcd solv problem method coupl tradit loss experi real world video dataset viz sport ucf 101 kitti perform analysi reveal superior result recent state art method
learn general intrins imag structur disentangl autoencod intrins decomposit singl imag high challeng task due inher ambigu scarciti train data contrast tradit fulli supervis learn approach paper propos learn intrins imag decomposit explain input imag model render intrins network rin join togeth imag decomposit pipelin predict reflect shape light condit given singl imag recombin function learn shade model use recompos origin input base intrins imag predict network use unsupervis reconstruct error addit signal improv intermedi represent allow larg scale unlabel data use train also enabl transfer learn knowledg imag unseen object categori light condit shape extens experi demonstr method perform well intrins imag decomposit knowledg transfer
unsupervis object learn dens equivari imag label key challeng visual percept extract abstract model object object categori visual measur affect complex nuisanc factor viewpoint occlus motion deform start recent idea viewpoint factor propos new approach given larg number imag object supervis extract dens object centric coordin frame coordin frame invari deform imag come dens equivari label neural network map imag pixel correspond object coordin demonstr applic method simpl articul object deform object human face learn embed random synthet transform optic flow correspond without manual supervis
side unsupervis domain map unsupervis domain map learner given unmatch dataset goal learn map gab translat sampl analog sampl recent approach shown learn simultan gab invers map gba convinc map obtain work present method learn gab without learn gba done learn map maintain distanc pair sampl moreov good map obtain even maintain distanc differ part sampl map present experiment result new method allow side map learn also lead prefer numer result exist circular base constraint entir code made public avail
contrast learn imag caption imag caption popular topic comput vision achiev substanti progress recent year howev distinct natur descript often overlook previous work close relat qualiti caption distinct caption like describ imag uniqu aspect work propos new learn method contrast learn imag caption specif via constraint formul top refer model propos method encourag distinct maintain overal qualiti generat caption test method challeng dataset improv baselin model signific margin also show studi propos method generic use model various structur
dynam rout capsul capsul group neuron whose activ vector repres instanti paramet specif type entiti object object part use length activ vector repres probabl entiti exist orient repres instanti paramt activ capsul level make predict via transform matric instanti paramet higher level capsul multipl predict agre higher level capsul becom activ show discriminin train multi layer capsul system achiev state art perform mnist consider better convolut net recogn high overlap digit achiev result use iter rout agreement mechan lower level capsul prefer send output higher level capsul whose activ vector big scalar product predict come lower level capsul
uncertainti need bayesian deep learn comput vision major type uncertainti model aleator uncertainti captur nois inher observ hand epistem uncertainti account uncertainti model uncertainti explain away given enough data tradit difficult model epistem uncertainti comput vision new bayesian deep learn tool possibl studi benefit model epistem aleator uncertainti bayesian deep learn model vision task present bayesian deep learn framework combin input depend aleator uncertainti togeth epistem uncertainti studi model framework per pixel semant segment depth regress task explicit uncertainti formul lead new loss function task interpret learn attenu make loss robust noisi data also give new state art result segment depth regress benchmark
effici optim linear dynam system applic cluster spars code linear dynam system ldss fundament tool model spatio tempor data various disciplin though rich model analyz ldss free difficulti main ldss compli euclidean geometri henc convent learn techniqu appli direct paper propos effici project gradient descent method minim general form loss function demonstr cluster spars code ldss solv propos method effici end first deriv novel canon form repres paramet lds show gradient descent updat project space ldss achiev dexter contrast previous studi solut avoid approxim lds model optim process extens experi reveal superior perform propos method term converg classif accuraci state art techniqu
label distribut learn forest label distribut learn ldl general learn framework assign instanc distribut set label rather singl label multipl label current ldl method either restrict assumpt express form label distribut limit represent learn learn deep featur end end manner paper present label distribut learn forest ldlfs novel label distribut learn algorithm base differenti decis tree sever advantag decis tree potenti model general form label distribut mixtur leaf node predict learn differenti decis tree combin represent learn defin distribut base loss function forest enabl tree learn joint show updat function leaf node predict guarante strict decreas loss function deriv variat bound effect propos ldlfs verifi sever ldl task comput vision applic show signific improv state art ldl method
graph match via multipl updat algorithm graph match fundament problem comput vision machin learn area problem usual formul quadrat program problem doubli stochast discret integ constraint sinc hard approxim algorithm requir paper present new algorithm call multipl updat graph match mpgm develop multipl updat techniqu solv match problem mpgm main benefit theoret mpgm solv general problem doubli stochast constraint natur direct whose converg kkt optim guarante empir mpgm general return spars solut thus also incorpor discret constraint approxim optim effici simpl implement experi synthet real world match task show benefit mpgm algorithm
train quantiz net deeper understand current deep neural network deploy low power embed devic first train full precis model use power comput hardwar deriv correspond low precis model effici infer system howev train model direct coars quantiz weight key step toward learn embed platform limit comput resourc memori capac power consumpt numer recent public studi method train quantiz network weight studi most empir work investig train method quantiz neural network theoret viewpoint first explor accuraci guarante train method convex assumpt look behavior algorithm non convex problem show train algorithm exploit high precis represent import anneal properti pure quantiz train method lack explain mani observ empir differ type algorithm
inner loop free admm use auxiliari deep neural network propos new method use appli deep learn techniqu acceler popular altern direct method multipli admm solut invers problem admm updat consist proxim oper least squar regress includ big matrix invers explicit solut updat dual variabl typic inner loop requir solv first sub minim problem due intract prior matrix invers avoid drawback limit propos textit inner loop free updat rule pre train deep convolut architectur specif learn condit denois auto encod impos implicit data depend prior regular ground truth first sub minim problem design follow empir bayesian strategi lead call amort infer matrix invers second sub problem learn convolut neural network approxim matrix invers invers map learn feed input learn forward network note train neural network requir ground truth measur data independ extens experi synthet data real dataset demonstr effici accuraci propos method compar convent admm solut use inner loop solv invers problem
toward accur binari convolut neural network introduc novel scheme train binari convolut neural network cnns cnns weight activ constrain run time known use binari weight activ drastic reduc memori size access replac arithmet oper effici bitwis oper lead much faster test time infer lower power consumpt howev previous work binar cnns usual result sever predict accuraci degrad paper address issu major innov approxim full precis weight linear combin multipl binari weight base employ multipl binari activ allevi inform loss implement result binari cnn denot abc net shown achiev much closer perform full precis counterpart even reach compar predict accuraci imagenet forest trail dataset given adequ binari weight base activ
runtim neural prune paper propos runtim neural prune rnp framework prune deep neural network dynam runtim unlik exist neural prune method produc fix prune model deploy method preserv full abil origin network conduct prune accord input imag current featur map adapt prune perform bottom layer layer manner model markov decis process use reinforc learn train agent judg import convolut kernel conduct channel wise prune condit differ sampl network prune imag easier task sinc abil network fulli preserv balanc point easili adjust accord avail resourc method appli shelf network structur reach better tradeoff speed accuraci especi larg prune rate
structur embed model group data word embed power approach analyz languag exponenti famili embed efe extend type data develop structur exponenti famili embed efe method discov embed vari across relat group data studi word usag congression speech vari across state parti affili word use differ across section arxiv purchas pattern groceri vari across season key success method group share statist inform develop share strategi hierarch model amort demonstr benefit approach empir studi speech abstract shop basket show sefe enabl group specif interpret word usag outperform efe predict held data
poincar embed learn hierarch represent represent learn becom invalu approach learn symbol data text graph howev complex symbol dataset often exhibit latent hierarch structur state art method typic learn embed euclidean vector space account properti purpos introduc new approach learn hierarch represent symbol data embed hyperbol space precis dimension poincar ball due under hyperbol geometri allow learn parsimoni represent symbol data simultan captur hierarchi similar introduc effici algorithm learn embed base riemannian optim show experiment poincar embed outperform euclidean embed signific data latent hierarchi term represent capac term general abil
languag model recurr highway hypernetwork provid extens experiment theoret support efficaci recurr highway network rhns recurr hypernetwork complimentari origin work demonstr experiment rhns benefit far better gradient flow lstms coupl great improv task accuraci rais provid solut sever theoret issu hypernetwork believ yield gain futur along dramat reduc comput cost combin rhns hypernetwork make signific improv current state art languag model perform penn treebank reli much simpler regular final argu rhns drop replac lstms analog lstms vanilla rnns hypernetwork facto augment analog attent recurr architectur
prevent gradient explos gate recurr unit gate recurr unit gru success recurr neural network architectur time seri data gru typic train use gradient base method subject explod gradient problem gradient increas signific problem caus abrupt chang dynam gru due small variat paramet paper find condit dynam gru chang drastic propos learn method address explod gradient problem method constrain dynam gru drastic chang evalu method experi languag model polyphon music model experi show method prevent explod gradient problem improv model accuraci
wider deeper cheaper faster tensor lstms sequenc learn long short term memori lstm popular approach boost abil recurr neural network store longer term tempor inform capac lstm network increas widen ad layer howev former introduc addit paramet latter increas runtim altern propos tensor lstm hidden state repres tensor updat via cross layer convolut increas tensor size network widen effici without addit paramet sinc paramet share across differ locat tensor delay output network deepen implicit littl addit runtim sinc deep comput timestep merg tempor comput sequenc experi conduct challeng sequenc learn task show potenti propos model
fast slow recurr neural network process sequenti data variabl length major challeng wide rang applic speech recognit languag model generat imag model machin translat address challeng propos novel recurr neural network rnn architectur fast slow rnn rnn rnn incorpor strength multiscal rnns deep transit rnns process sequenti data differ timescal learn complex transit function time step next evalu rnn charact base languag model data set penn treebank hutter prize wikipedia improv state art result bit per charact bpc respect addit ensembl rnns achiev bpc hutter prize wikipedia outperform best known compress algorithm respect bpc measur also present empir investig learn network dynam rnn explain improv perform compar rnn architectur approach general kind rnn cell possibl build block rnn architectur thus flexibl appli differ task
cold start reinforc learn softmax polici gradient present learn algorithm target effici solv fundament problem structur output predict exposur bias problem model expos train data distribut fail expos predict wrong object problem train model conveni object function give suboptim perform method base polici gradient approach reinforc learn succeed avoid common overhead procedur associ approach name warm start train varianc reduct polici updat propos cold start reinforc learn method base new softmax polici gradient softmax polici combin effici simplic maximum likelihood approach effect reward base signal empir evid valid method structur output predict automat summar imag caption task
deep learn precipit nowcast benchmark new model goal make high resolut forecast region rainfal precipit nowcast becom import fundament technolog under various public servic rang rainfal alert flight safeti recent convolut lstm convlstm model shown outperform tradit optic flow base method precipit nowcast suggest deep learn model huge potenti solv problem howev convolut recurr structur convlstm base model locat invari natur motion transform rotat locat variant general furthermor sinc deep learn base precipit nowcast newli emerg area clear evalu protocol yet establish address problem propos new model benchmark precipit nowcast specif beyond convlstm propos trajectori gru trajgru model activ learn locat variant structur recurr connect besid provid benchmark includ real world larg scale dataset hong kong observatori new train loss comprehens evalu protocol facilit futur research gaug state art
recurr ladder network propos recurr extens ladder network cite ladder motiv infer requir hierarch latent variabl model demonstr recurr ladder abl handl wide varieti complex learn task need iter infer tempor model architectur show close optim result tempor model video data competit result music model improv perceptu group base higher order abstract stochast textur motion cue present result fulli supervis semi supervis unsupervis task result suggest propos architectur principl power tool learn hierarchi abstract handl tempor inform model relat interact object
predict state decod encod futur recurr network recurr neural network rnns vital model techniqu reli intern state learn indirect optim supervis unsupervis reinforc train loss rnns use model dynam process character under latent state whose form often unknown preclud analyt represent insid rnn predict state represent psr literatur latent state process model intern state represent direct model distribut futur observ recent work area reli explicit repres target suffici statist probabl distribut seek combin advantag rnns psrs augment exist state art recurr neural network predict state decod psds add supervis network intern state represent target predict futur observ psds simpl implement easili incorpor exist train pipelin via addit loss regular demonstr effect psds experiment result differ domain probabilist filter imit learn reinforc learn method improv statist perform state art recurr baselin fewer iter less data
qmdp net deep learn plan partial observ paper introduc qmdp net neural network architectur plan partial observ qmdp net combin strength model free learn model base plan recurr polici network repres polici connect model plan algorithm solv model thus embed solut structur plan network learn architectur qmdp net fulli differenti allow end end train train qmdp net set differ environ general new one transfer larger environ well preliminari experi qmdp net show strong perform sever robot task simul interest qmdp net encod qmdp algorithm sometim outperform qmdp algorithm experi qmdp net increas robust end end learn
filter variat object evid lower bound elbo appear mani algorithm maximum likelihood estim mle latent variabl sharp lower bound margin log likelihood neural latent variabl model optim elbo joint variat posterior model paramet produc state art result inspir success elbo surrog mle object consid extens elbo famili lower bound defin mont carlo estim margin likelihood show tight bound asymptot relat varianc under estim introduc special case filter variat object take argument elbo pass particl filter form tighter bound filter variat object optim tractabl stochast gradient particular suit mle sequenti latent variabl model standard sequenti generat model task present uniform improv comput budget model train elbo iwa object includ whole nat per timestep improv
unsupervis learn disentangl latent represent sequenti data present factor hierarch variat autoencod learn disentangl represent sequenti data without supervis specif exploit multi scale natur inform sequenti data formul explicit within factor hierarch graphic model impos sequenc specif prior global prior differ set latent variabl model evalu speech corpora demonstr qualit abil transform speaker linguist content manipul differ set latent variabl quantit abil outperform vector baselin speaker verif reduc word error rate much mismatch train test scenario automat speech recognit task
neural discret represent learn learn use represent without supervis remain key challeng machin learn paper propos simpl yet power generat model learn discret represent model vector quantis variat autoencod vae differ vae key way encod network output discret rather continu code prior learnt rather static order learn discret latent represent incorpor idea vector quantis use method allow model circumv issu posterior collaps latent ignor pair power autoregress decod typic observ vae framework pair represent autoregress prior model generat high qualiti imag video speech well high qualiti speaker inpaint provid evid util learnt represent
variat memori address generat model aim augment generat model extern memori interpret output memori modul stochast address condit mixtur distribut read oper correspond sampl discret memori address retriev correspond content memori perspect allow appli variat infer memori address enabl effect train memori modul use target inform guid memori lookup stochast address particular well suit generat model natur encourag multimod promin aspect high dimension dataset treat chosen address latent variabl also allow quantifi amount inform gain memori lookup measur contribut memori modul generat process illustr advantag approach incorpor variat autoencod appli result model task generat shot learn intuit behind architectur memori modul pick relev templat memori continu part model concentr model remain variat demonstr empir model abl identifi access relev memori content even hundr unseen omniglot charact memori
cortic microcircuit gate recurr neural network cortic circuit exhibit intric recurr architectur remark similar across differ brain area stereotyp structur suggest exist common comput principl remain larg elus inspir gate memori network name long short term memori lstm net introduc recurr neural network rnn inform gate inhibitori unit subtract balanc subrnn propos subrnn natur map onto known canon excitatori inhibitori cortic microcircuit show network subtract gate easier optimis standard multipl gate moreov subrnn yield near exact solut standard long term depend task tempor addit task empir result across sever long term depend task generalis tempor addit multipl tempor mnist word level languag model show subrnn outperform achiev similar perform lstm network test work suggest novel view cortex solv complex contextu problem provid first step toward unifi machin learn recurr network biolog counterpart
continu learn deep generat replay attempt train comprehens artifici intellig capabl solv multipl task imped chronic problem call catastroph forget although simpli replay previous data allevi problem requir larg memori even wors often infeas real world applic access past data limit inspir generat natur hippocampus short term memori system primat brain propos deep generat replay novel framework cooper dual model architectur consist deep generat model generat task solv model solver model train data previous task easili sampl interleav new task test method sever sequenti learn set involv imag classif task
hierarch attent recurr track class agnost object track particular difficult clutter environ target specif discrimin model cannot learn priori inspir human visual cortex employ spatial attent separ andwhat process pathway activ suppress irrelev visual featur work develop hierarch attent recurr model singl object track video first layer attent discard major background select region contain object interest subsequ layer tune visual featur particular track object framework fulli differenti train pure data driven fashion gradient method improv train converg augment loss function term number auxiliari task relev track evalu propos model perform dataset increas difficulti pedestrian track kth activ recognit dataset kitti object track dataset
vae learn via stein variat gradient descent new method learn variat autoencod vae develop base stein variat gradient descent key advantag approach need make parametr assumpt form encod distribut perform enhanc integr propos encod import sampl excel perform demonstr across multipl unsupervis semi supervis problem includ semi supervis analysi imagenet data demonstr scalabl model larg dataset
learn inpaint imag compress studi design deep architectur lossi imag compress present architectur recip context multi stage progress encod empir demonstr import compress perform specif show predict origin imag data residu multi stage progress architectur facilit learn lead improv perform approxim origin content learn inpaint neighbor imag pixel perform compress reduc amount inform must store achiev high qualiti approxim incorpor design choic baselin progress encod yield averag reduct file size similar qualiti compar origin residu encod
visual interact network glanc human make rich predict futur state wide rang physic system modern approach engin robot graphic often restrict narrow domain requir direct measur under state introduc visual interact network general purpos model learn dynam physic system raw visual observ predict futur state model consist perceptu front end base convolut neural network dynam predictor base interact network joint train perceptu front end learn pars dynam visual scene set factor latent object represent dynam predictor learn roll state forward time comput interact dynam produc predict physic trajectori arbitrari length found input video frame visual interact network generat accur futur trajectori hundr time step wide rang physic system model also appli scene invis object infer futur state effect visibl object implicit infer unknown mass object result demonstr perceptu modul object base dynam predictor modul induc factor latent represent support accur dynam predict work open new opportun model base decis make plan raw sensori observ complex physic environ
neuralfdr learn discoveri threshold hypothesi featur dataset grow richer import challeng leverag full featur data maxim number use discoveri control fals posit address problem context multipl hypothes test hypothesi observ valu along set featur specif hypothesi exampl genet associ studi hypothesi test correl variant trait rich set featur variant locat conserv epigenet etc could inform like variant true associ howev popular test approach benjamini hochberg procedur independ hypothesi weight ihw either ignor featur assum featur categor propos new algorithm neuralfdr automat learn discoveri threshold function hypothesi featur parametr discoveri threshold neural network enabl flexibl handl multi dimension discret continu featur well effici end end optim prove neuralfdr strong fals discoveri rate fdr guarante show make substanti discoveri synthet real dataset moreov demonstr learn discoveri threshold direct interpret
eigen distort hierarch represent develop method compar hierarch imag represent term abil explain perceptu sensit human specif util fisher inform establish model deriv predict local sensit perturb around given natur imag given imag comput eigenvector fisher inform matrix largest smallest eigenvalu correspond model predict least notic imag distort respect human subject measur amount distort reliabl detect ad imag compar threshold predict correspond model use method test abil varieti represent mimic human perceptu sensit find earli layer vgg16 deep neural network optim object recognit provid better match human percept later layer better match stage convolut neural network cnn train databas human rate distort imag qualiti hand find simpl model earli visual process incorpor stage local gain control train databas distort rate predict human sensit signific better cnn layer vgg16
fli oper batch dynam comput graph dynam neural network toolkit pytorch dynet chainer offer flexibl implement model cope data vari dimens structur relat toolkit oper static declar comput tensorflow cntk theano howev exist toolkit static dynam requir develop organ comput batch necessari exploit high perform data parallel algorithm hardwar batch task general difficult becom major hurdl architectur becom complex paper present algorithm implement dynet toolkit automat batch oper develop simpli write minibatch comput aggreg singl instanc comput batch algorithm seamless execut fli comput effici batch varieti task obtain throughput similar manual batch well compar speedup singl instanc learn architectur impract batch manual
learn affin via spatial propag network paper propos spatial propag network learn affin matrix show construct row column linear propag model spatial variant transform matrix constitut affin matrix model dens global pairwis similar imag specif develop way connect linear propag model formul spars transform matrix element output deep cnn result dens affin matrix effect model task specif pairwis similar instead design similar kernel accord imag featur point direct output similar pure data driven manner spatial propag network generic framework appli numer task tradit benefit design affin imag mat color guid filter name furthermor model also learn semant awar affin high level vision task due learn capabl deep model valid propos framework refin object segment experi helen face pars pascal voc 2012 semant segment task show spatial propag network provid general effect effici solut generat high qualiti segment result
supervis adversari domain adapt work provid framework address problem supervis domain adapt deep model main idea exploit adversari learn learn embed subspac simultan maxim confus domain semant align embed version supervis set becom attract especi target data sampl need label scenario align separ semant probabl distribut difficult lack data found care design train scheme wherebi typic binari adversari discrimin augment distinguish differ class possibl effect address supervis adapt problem addit approach high speed adapt requir extrem low number label target train sampl even per categori effect extens compar approach state art domain adapt experi use dataset handwritten digit recognit use dataset visual object recognit
deep hyperspher learn convolut inner product found basi convolut neural network cnns key end end visual represent learn benefit deeper architectur recent cnns demonstr increas strong represent abil despit improv increas depth larger paramet space also led challeng proper train network light challeng propos hyperspher convolut sphereconv novel learn framework give angular represent hyperspher introduc spherenet deep hyperspher convolut network distinct convent inner product base convolut network particular spherenet adopt sphereconv basic convolut oper supervis general angular softmax loss natur loss formul sphereconv show spherenet effect encod discrimin represent allevi train difficulti lead easier optim faster converg better classif perform convolut counterpart also provid theoret justif advantag hyperspher optim experi ablat studi verifi conclus
riemannian approach batch normal batch normal proven effect algorithm deep neural network train normal input neuron reduc intern covari shift space weight vector layer natur interpret riemannian manifold invari linear scale weight follow intrins geometri manifold provid new learn rule effici easier analyz also propos intuit effect gradient clip regular method propos algorithm util geometri manifold result algorithm consist outperform origin various type network architectur dataset
backprop without learn rate coin bet deep learn method achiev state art perform mani applic scenario yet method requir signific amount hyperparamet tune order achiev best result particular tune learn rate stochast optim process still main bottleneck paper propos new stochast gradient descent procedur deep network requir learn rate set contrari previous method adapt learn rate make use assum curvatur object function instead reduc optim process game bet coin propos learn rate free optim algorithm scenario theoret converg proven convex quasi convex function empir evid show advantag algorithm popular stochast gradient algorithm
converg block coordin descent train dnns tikhonov regular lift relu function higher dimension space develop smooth multi convex formul train feed forward deep neural network dnns allow develop block coordin descent bcd train algorithm consist sequenc numer well behav convex optim use idea proxim point method convex analysi prove bcd algorithm converg global stationari point linear converg rate order experi mnist databas dnns train bcd algorithm consist yield better test set error rate ident dnn architectur tarin via stochast gradient descent sgd variant caff toolbox
collabor deep learn fix topolog network signific recent interest parallel deep learn algorithm order handl enorm growth data model size advanc focus model parallel engag multipl comput agent via use central paramet server aspect data parallel along decentr comput explor suffici context paper present new consensus base distribut sgd cdsgd momentum variant cdmsgd algorithm collabor deep learn fix topolog network enabl data parallel well decentr comput framework extrem use learn agent access local privat data communic constrain environ analyz converg properti propos algorithm strong convex nonconvex object function fix diminish step size use concept lyapunov function construct demonstr efficaci algorithm comparison baselin central sgd recent propos feder averag algorithm also enabl data parallel base benchmark dataset mnist cifar cifar 100
regular affect critic point linear network paper concern problem repres learn linear transform use linear neural network recent year grow interest studi network part due success deep learn main question bodi research also paper pertain exist optim properti critic point mean squar loss function primari concern robust critic point regular loss function optim control model introduc purpos learn algorithm regular form backprop deriv use hamilton formul optim control formul use provid complet character critic point term solut nonlinear matrix valu equat refer characterist equat analyt numer tool bifurc theori use comput critic point via solut characterist equat main conclus critic point diagram fundament differ even arbitrari small amount regular
predict organ reaction outcom weisfeil lehman network predict organ reaction outcom fundament problem comput chemistri sinc reaction involv hundr atom fulli explor space possibl transform intract current solut util reaction templat limit space suffer coverag effici issu paper propos templat free approach effici explor space product molecul first pinpoint reaction center set node edg graph edit occur sinc small number atom contribut reaction center direct enumer candid product generat candid score weisfeil lehman differ network model high order interact chang occur node across molecul framework outperform top perform templat base approach margin run order magnitud faster final demonstr model accuraci rival perform domain expert
predict scene pars motion dynam futur import intellig system textit autonom vehicl robot anticip futur order plan earli make decis accord predict futur scene pars motion dynam help agent understand visual environ better former provid dens semant segment textit object present later provid dens motion inform textit object move futur paper propos novel model predict futur scene pars motion dynam unobserv video frame simultan use histori inform preced frame correspond scene pars result input model abl predict scene pars motion arbitrari time step ahead import model superior compar method predict pars motion individu solv predict task joint fulli exploit complementari relationship best knowledg paper first aim learn predict futur scene pars motion dynam simultan larg scale cityscap dataset demonstr model produc signific better pars motion predict compar well establish baselin addit also present predict steer angl vehicl use model good result verifi capabl model learn under latent paramet
houdini democrat adversari exampl generat adversari exampl critic step evalu improv robust learn machin far exist method work classif design alter true perform measur problem hand introduc novel flexibl approach name houdini generat adversari specif tailor final perform measur task consid success appli houdini rang applic speech recognit pose estim
geometr matrix complet recurr multi graph neural network matrix complet model among common formul recommend system recent work show boost perform techniqu introduc pairwis relationship user item form graph impos smooth prior graph howev techniqu fulli exploit local stationari structur user item graph number paramet learn linear number user item propos novel approach overcom limit use geometr deep learn graph matrix complet architectur combin novel multi graph convolut neural network learn meaning statist graph structur pattern user item recurr neural network appli learnabl diffus score matrix neural network system comput attract requir constant number paramet independ matrix size appli method sever standard dataset show outperform state art matrix complet techniqu
compress awar train deep neural network recent year great progress made varieti applic domain thank develop increas deeper neural network unfortun huge number unit network make expens comput memori wise overcom exploit fact deep network parametr sever compress strategi propos method howev typic start network train standard manner without consid futur compress paper propos explicit account compress train process end introduc regular encourag paramet matrix layer low rank train show allow learn much compact yet least effect model state art compress techniqu
non parametr neural network deep neural network dnns probabilist graphic model pgms main tool statist model dnns provid abil model rich complex relationship input independ output variabl pgms provid abil encod depend among output variabl end end train model structur graphic depend top independ neural predict recent emerg principl way combin paradigm type model proven power discrimin set discret output extens structur continu space well perform effici infer space lack propos non parametr neural network n3s modular approach clean separ non parametr structur posterior represent discrimin infer scheme allow end end train compon experi evalu abil n3s captur structur posterior densiti model comput complex statist densiti infer compar model number baselin includ popular variat sampl base infer scheme term accuraci speed
gibbsnet iter adversari infer deep graphic model direct latent variabl model formul joint distribut advantag sampl fast exact yet weak need specifi often simpl fix prior limit express model undirect latent variabl model discard requir specifi prior yet sampl general requir iter procedur block gibb sampl requir mani step achiev sampl joint distribut propos novel approach learn joint distribut data latent code use adversari learn iter procedur gradual refin joint distribut better match data distribut step gibbsnet best world theori practic achiev speed simplic direct latent variabl model guarante assum adversari game reach virtual train criteria global minimum produc sampl sampl iter achiev express flexibl undirect latent variabl model gibbsnet away need explicit abil classif class condit generat joint imag attribut model singl model train specif task show empir gibbsnet abl learn complex show lead improv inpaint iter refin dozen step stabl generat without collaps thousand step despit train step
explor general deep learn goal understand drive general deep network consid sever recent suggest explan includ norm base control sharp robust studi measur ensur general highlight import scale normal make connect sharp pac bay theori investig well measur explain differ observ phenomena
regular deep neural network nois interpret optim overfit critic challeng deep neural network various type regular method improv general perform inject nois hidden unit train dropout known success regular still clear enough train techniqu work well practic maxim benefit presenc conflict object optim true data distribut prevent overfit regular paper address issu interpret convent train method regular nois inject optim lower bound true object propos techniqu achiev tighter lower bound use multipl nois sampl per mini batch demonstr effect idea sever comput vision applic
extract low dimension dynam multipl larg scale neural popul record learn predict correl power approach understand neural popul dynam extract low dimension trajectori popul record use dimension reduct method current approach dimension reduct neural data limit singl popul record identifi dynam embed across multipl measur propos approach extract low dimension dynam multipl sequenti record algorithm scale data compris million observ dimens make possibl access dynam distribut across larg popul multipl brain area build subspac identif approach dynam system perform paramet estim minim moment match object use scalabl stochast gradient descent algorithm model optim predict tempor covari across neuron across time show approach natur handl miss data multipl partial record identifi dynam predict correl even presenc sever subsampl small overlap record demonstr effect approach simul data whole brain larval zebrafish imag dataset
adapt sampl popul neuron adapt sampl method neurosci primarili focus maxim fire rate singl record neuron record neuron usual possibl find singl stimulus maxim fire rate neuron motiv object function take account record popul neuron togeth propos adept adapt sampl method optim popul object function simul experi first confirm popul object function elicit vari stimulus respons singl neuron object function test adept close loop electrophysiolog experi popul activ record macaqu cortic area known mid level visual process adept use output deep convolut neural network model featur embed predict neural respons adept elicit mean stimulus respons larger random chosen natur imag well larger scatter stimulus respons adapt sampl method enabl new scientif discoveri record popul neuron heterogen respons properti
onacid onlin analysi calcium imag data real time optic imag method use calcium indic critic monitor activ larg neuron popul vivo imag experi typic generat larg amount data need process extract activ imag neuron sourc deriv process algorithm activ area research exist method requir process larg amount data time render vulner volum record data prevent real time experiment interrog introduc onacid onlin framework analysi stream calcium imag data includ motion artifact correct neuron sourc extract iii activ denois deconvolut approach combin extend previous work onlin dictionari learn calcium imag data analysi deliv autom pipelin discov track activ hundr cell real time therebi enabl new type close loop experi appli algorithm larg scale experiment dataset benchmark perform manual annot data show outperform popular offlin approach
detrend partial cross correl brain connect analysi brain connect analysi critic compon ongo human connectom project deciph healthi diseas brain recent work highlight power law multi time scale properti brain signal howev remain lack method specif quantifi short long rang brain connect paper use detrend partial cross correl analysi dpcca propos novel function connect measur delin brain interact multipl time scale control covari use rich simul fmri data valid propos method appli real fmri data cocain depend predict task show compar extant method dpcca base approach distinguish short long rang function connect also improv featur extract subsequ increas classif accuraci togeth paper contribut broad new comput methodolog understand neural inform process
practic bayesian optim model fit bayesian adapt direct search comput model field comput neurosci often evalu via stochast simul numer approxim fit model impli difficult optim problem complex possibl noisi paramet landscap bayesian optim success appli solv expens black box problem engin machin learn explor whether appli general tool model fit first present novel algorithm bayesian adapt direct search bad achiev competit perform afford comput overhead run time typic model perform extens benchmark bad mani common state art nonconvex deriv free optim set model fit problem real data model studi behavior cognit comput neurosci default set bad consist find compar better solut method show great promis bad particular general model fit tool
error detect correct framework connectom signific advanc made recent year problem neural circuit reconstruct electron microscop imageri improv imag acquisit imag align boundari detect great reduc achiev error rate order make progress argu autom error detect essenti focuss effort attent human machin paper report use autom error detect attent signal flood fill error correct modul demonstr signific improv upon state art segment perform
cake effect brain connect causal kernel fundament goal network neurosci understand activ region drive activ elsewher process refer effect connect propos model causal interact use integro differenti equat causal kernel allow rich analysi effect connect approach combin tractabl flexibl autoregress model biophys interpret dynam causal model causal kernel learn nonparametr use gaussian process regress yield effici framework causal infer construct novel class causal covari function enforc desir properti causal kernel approach call cake construct model hyperparamet biophys mean therefor easili interpret demonstr efficaci cake number simul give exampl realist applic magnetoencephalographi meg data
learn neural represent human cognit across mani fmri studi cognit neurosci enjoy rapid increas extens public brain imag dataset open door design deploy larg scale statist model target unifi perspect avail data impli find scalabl autom solut old challeng aggreg heterogen inform brain function univers cognit system relat psycholog behavior brain network cast challeng machin learn approach predict condit statist brain map across differ studi leverag multi task learn multi scale dimens reduct learn low dimension represent brain imag carri robust cognit inform robust associ psycholog stimuli multi dataset classif model achiev best predict perform sever larg refer dataset compar model forgo learn cognit awar low dimens represent bring substanti perform boost analysi small dataset introspect identifi univers templat cognit concept
map distinct timescal function interact among brain network brain process occur various timescal rang millisecond neuron minut hour behavior character function coupl among brain region divers timescal key understand brain produc behavior appli instantan lag base measur condit linear depend base granger gewek causal infer network connect distinct timescal function magnet reson imag fmri data due slow sampl rate fmri wide held produc spurious unreli estim function connect appli fmri data challeng claim combin simul novel machin learn approach first show simul fmri data instantan lag base identifi distinct timescal complementari pattern function connect next analyz fmri record 500 human subject show linear classifi train either instantan lag base connect reliabl distinguish task versus rest brain state cross valid accuraci import instantan lag base exploit mark differ spatial tempor pattern connect achiev robust classif approach provid novel framework uncov valid function connect network oper distinct timescal brain
robust estim neural signal calcium imag calcium imag promin technolog neurosci research allow simultan record larg number neuron awak anim autom extract neuron tempor activ imag dataset import step path produc neurosci result howev near imag dataset typic contain gross contamin sourc could contribut technolog use under biolog tissu although attempt made better extract neural signal limit gross contamin scenario effort address contamin full general statist estim work proceed new direct propos extract cell activ use robust estim deriv optim robust loss base simpl abstract calcium imag data also find simpl practic optim routin loss provabl fast converg use propos robust loss matrix factor framework extract neuron tempor activ calcium imag dataset demonstr superior robust estim approach exist method simul real dataset
learn morpholog brain signal use alpha stabl convolut spars code neural time seri data contain wide varieti prototyp signal waveform atom signific import clinic cognit research goal analyz data henc extract shift invari atom even though success report exist algorithm limit applic due heurist natur moreov often vulner artifact impuls nois typic present raw neural record studi address issu propos novel probabilist convolut spars code csc model learn shift invari atom raw neural signal contain potenti sever artifact core model call csc lie famili heavi tail distribut call stabl distribut develop novel comput effici mont carlo expect maxim algorithm infer maxim step boil weight csc problem develop comput effici optim algorithm result show propos algorithm achiev state art converg speed besid csc signific robust artifact compar compet algorithm extract spike burst oscil even reveal subtl phenomena cross frequenc coupl appli noisi neural time seri
stream weak submodular interpret neural network fli mani machin learn applic import explain predict black box classifi exampl deep neural network assign imag particular class cast interpret black box classifi combinatori maxim problem propos effici stream algorithm solv subject cardin constraint extend idea badanidiyuru 2014 provid constant factor approxim guarante algorithm case random stream order weak submodular object function first theoret guarante general class function also show algorithm exist worst case stream order algorithm obtain similar explan incept predict time faster state art lime framework ribeiro 2016
decompos submodular function minim discret continu paper investig connect discret continu approach decompos submodular function minim provid improv run time estim state art continu algorithm problem use combinatori argument also provid systemat experiment comparison type method base clear distinct level level algorithm
differenti learn submodular function incorpor discret optim algorithm within modern machin learn model exampl possibl use deep architectur layer whose output minim cut parametr graph given model train end end leverag gradient inform introduct layer seem challeng due non continu output paper focus problem submodular minim show layer inde possibl key idea continu relax output without sacrif guarante provid easili comput approxim jacobian complement complet theoret analysi final contribut let experiment learn probabilist log supermodular model via level variat infer formul
robust optim non convex object consid robust optim problem goal optim worst case class object function develop reduct robust improp optim bayesian optim given oracl return approxim solut distribut object comput distribut solut approxim worst case show derandom solut hard general done broad class statist learn task appli result robust neural network train submodular optim evalu approach experiment charact classif task subject adversari distort robust influenc maxim larg network
optim landscap tensor decomposit non convex optim local search heurist wide use machin learn achiev mani state art result becom increas import understand work hard problem typic data landscap mani object function learn conjectur geometr properti local optima approxim global optima thus solv effici local search algorithm howev establish properti difficult paper analyz optim landscap random complet tensor decomposit problem mani applic unsupervis lean especi learn latent variabl model practic effici solv gradient ascent non convex object show small constant among set point function valu factor larger expect function local maxima approxim global maxima previous best known result character geometri small neighborhood around true compon result impli even initi bare better random guess gradient ascent algorithm guarante solv problem main techniqu use kac rice formula random matrix theori best knowledg first time kac rice formula success appli count number local minima high structur random polynomi depend coeffici
gradient descent take exponenti time escap saddl point although gradient descent almost alway escap saddl point asymptot lee 2016 paper show even fair natur random initi scheme non patholog function signific slow saddl point take exponenti time escap hand gradient descent perturb 2015 jin 2017 slow saddl point find approxim local minim polynomi time result conclud gradient descent inher slower justifi import ad perturb effici non convex optim experi also provid demonstr theoret find
convolut phase retriev studi convolut phase retriev problem ask recov unknown signal length measur consist magnitud cyclic convolut known kernel length model motiv applic channel estim optic underwat acoust communic signal interest act given channel filter phase inform difficult imposs acquir show random mathbf effici recov global phase use combin spectral initi general gradient descent main challeng cope depend measur oper overcom challeng use idea decoupl theori suprema chao process restrict isometri properti random circul matric recent analysi altern minim method
implicit regular matrix factor studi implicit regular optim underdetermin quadrat object matrix gradient descent factor conjectur provid empir theoret evid small enough step size initi close enough origin gradient descent full dimension factor converg minimum nuclear norm solut
near linear time approxim algorithm optim transport via sinkhorn iter comput optim transport distanc earth mover distanc fundament problem machin learn statist comput vision despit recent introduct sever algorithm good empir perform unknown whether general optim transport distanc approxim near linear time paper demonstr ambiti goal fact achiev cuturi sinkhorn distanc provid guidanc toward paramet tune algorithm result reli new analysi sinkhorn iter also direct suggest new algorithm greenkhorn theoret guarante numer simul clear illustr greenkhorn signific outperform classic sinkhorn algorithm practic
frank wolf equilibrium comput consid frank wolf method constrain convex optim first order project free procedur show algorithm recast differ light emerg special case particular meta algorithm comput equilibria saddl point convex concav sum game equilibrium comput trick reli exist regret onlin learn generat sequenc iter also provid proof converg vanish regret show state equival sever nice properti particular exhibit modular give rise various old new algorithm explor result method provid experiment result demonstr correct effici
greedi algorithm cone constrain optim converg guarante greedi optim method match pursuit frank wolf algorithm regain popular recent year due simplic effect theoret guarante address optim textit linear span textit convex hull set atom respect paper consid intermedi case optim textit convex cone parametr conic hull generic atom set lead first principl definit non negat algorithm give explicit converg rate demonstr excel empir perform novel algorithm analysi tailor particular function atom set particular deriv sublinear converg general smooth convex object linear converg strong convex object case general set atom furthermor establish clear correspond algorithm known algorithm literatur novel algorithm analys target general atom set general object function henc direct applic larg varieti learn set
cyclic coordin descent beat random coordin descent coordin descent method seen resurg recent interest applic machin learn well larg scale data analysi superior empir perform method variant cyclic coordin descent ccd random coordin descent rcd determinist random version method light recent result literatur common percept rcd alway domin ccd term perform paper question percept provid exampl general problem class ccd determinist order faster rcd term asymptot worst case converg furthermor provid lower upper bound amount improv rate determinist relat rcd amount improv depend determinist order use also provid character best determinist order lead maximum improv converg rate term combinatori properti hessian matrix object function
linear converg frank wolf type algorithm trace norm ball propos rank variant classic frank wolf algorithm solv convex minim trace norm ball algorithm replac top singular vector comput svd frank wolf top singular vector comput svd done repeat appli svd time algorithm linear converg rate object function smooth strong convex optim solut rank improv converg rate total complex frank wolf method variant
adapt acceler gradient converg method lderian error bound condit recent studi shown proxim gradient method acceler gradient method apg restart enjoy linear converg weaker condit strong convex name quadrat growth condit qgc howev faster converg restart apg method reli potenti unknown constant qgc appropri restart apg restrict applic address issu develop novel adapt gradient converg method leverag magnitud proxim gradient criterion restart termin analysi extend much general condit beyond qgc name lderian error bound heb condit key techniqu develop novel synthesi adapt regular condit restart scheme extend previous work focus strong convex problem much broader famili problem furthermor demonstr result import implic applic machin learn object function coerciv semi algebra converg speed essenti total number iter object function consist huber norm regular convex smooth piecewis quadrat loss squar loss squar hing loss huber loss propos algorithm paramet free enjoy faster linear converg without assumpt restrict eigen valu condit notabl linear converg result aforement problem global instead local best knowledg improv result first shown work
search dark practic svrg method error bound condit guarante paper develop practic stochast varianc reduc gradient svrg method error bound condit theoret guarante error bound condit inher properti optim problem recent reviv optim develop fast algorithm improv global converg without strong convex particular condit interest quadrat error bound aka second order growth condit weaker strong convex leverag develop linear converg mani gradient proxim gradient method sever recent studi also deriv linear converg quadrat error bound condit stochast varianc reduc gradient method import mileston stochast optim solv machin learn problem howev studi overlook critic issu algorithm depend unknown paramet analog strong convex modulus error bound condit usual difficult estim therefor make algorithm practic solv mani interest machin learn problem address issu propos novel techniqu automat search unknown paramet fli optim maintain almost converg rate oracl set assum involv paramet given
geometr descent method convex composit minim paper extend geometr descent method recent propos bubeck lee singh tackl nonsmooth strong convex composit problem prove propos algorithm dub geometr proxim gradient method geopg converg linear rate
condit number problem numer result linear regress logist regress elast net regular show geopg compar favor nesterov acceler proxim gradient method especi problem ill condit
faster non ergod stochast altern direct method multipli studi stochast convex optim subject linear equal constraint tradit stochast altern direct method multipli nesterov acceler scheme achiev ergod sqrt converg rate number iter introduc varianc reduct techniqu converg rate improv ergod paper propos new stochast admm elabor integr nesterov extrapol techniqu nesterov extrapol algorithm achiev non ergod converg rate optim separ linear constrain non smooth convex problem converg rate base admm method actual tight sqrt non ergod sens best knowledg first work achiev truli acceler stochast converg rate constrain convex problem experiment result demonstr algorithm signific faster exist state art stochast admm method
doubli acceler stochast varianc reduc dual averag method regular empir risk minim develop new acceler stochast gradient method effici solv convex regular empir risk minim problem mini batch set use mini batch becom golden standard machin learn communiti mini batch set stabil gradient estim easili make good use parallel comput core propos method incorpor new doubl acceler techniqu varianc reduct techniqu theoret analyz propos method show method much improv mini batch effici previous acceler stochast method essenti need mini batch achiev optim iter complex non strong strong convex object train set size show even non mini batch set method surpass best known converg rate non strong convex object achiev strong convex object
limit varianc reduct acceler scheme finit sum optim studi condit abl effici appli varianc reduct acceler scheme finit sum problem first show perhap surpris finit sum structur suffici obtain complex bound
smooth strong convex finit sum must also know exact individu function refer oracl iter next show broad class first order coordin descent finit sum algorithm includ sdca svrg sag possibl get acceler complex bound unless strong convex paramet given explicit last show class algorithm use minim
smooth non strong convex finit sum optim complex bound
nonlinear acceler stochast algorithm extrapol method use last iter optim algorithm produc better estim optimum shown achiev optim converg rate determinist set use simpl gradient iter studi extrapol method stochast set iter produc either simpl acceler stochast gradient algorithm first deriv converg bound arbitrari potenti bias perturb produc asymptot bound use ratio varianc nois accuraci current point final appli acceler techniqu stochast algorithm sgd saga svrg katyusha differ set show signific perform gain
acceler averag stochast descent dynam formul studi general famili continu time stochast dynam acceler first order minim smooth convex function build averag formul acceler mirror descent propos stochast variant gradient contamin nois studi result stochast differenti equat prove bound rate chang energi function associ problem use deriv estim converg rate function valu expect persist asymptot vanish nois discuss interact paramet dynam learn rate averag weight variat nois process show particular asymptot rate variat affect choic paramet ultim converg rate
multiscal semi markov dynam intracort brain comput interfac intracort brain comput interfac allow peopl tetraplegia control comput cursor imagin motion paralyz limb standard decod deriv kalman filter assum markov dynam angl intend movement unimod likelihood channel neural activ due error made decod noisi neural data user attempt move cursor goal angl cursor goal posit chang rapid propos dynam bayesian network includ screen goal posit part latent state thus allow motion cue aggreg much longer histori neural activ multiscal model explicit captur relationship instantan angl motion long term goal incorpor semi markov dynam motion trajectori also propos flexibl likelihood model record neural popul offlin experi record neural data demonstr signific improv predict motion direct compar kalman filter baselin deriv effici onlin infer algorithm enabl clinic trial particip tetraplegia control comput cursor neural activ real time
eeg graph factor graph base model captur spatial tempor observ relationship electroencephalogram paper report factor graph base model brain activ joint describ instantan observ base tempor spatial depend factor function repres depend defin manual base domain knowledg model valid use clinic collect intracrani electroencephalogram eeg data epilepsi patient applic seizur onset local result indic model outperform convent approach devis use observ depend alon better auc furthermor also show manual definit factor function allow solv graph infer exact use graph cut algorithm experi show propos infer techniqu provid gain auc compar sampl base altern
asynchron parallel coordin minim map infer find maximum posteriori map assign central task graphic model sinc modern applic give rise larg problem instanc increas need effici solver work propos improv effici coordin minim base dual decomposit solver run updat asynchron parallel case messag pass infer perform multipl process unit simultan without coordin read write share memori analyz converg properti result algorithm identifi set speedup gain expect numer evalu show approach inde achiev signific speedup common comput vision task
speed latent variabl gaussian graphic model estim via nonconvex optim studi estim latent variabl gaussian graphic model lvggm precis matrix superposit spars matrix low rank matrix order speed estim spars plus low rank compon propos sparsiti constrain maximum likelihood estim base matrix factor effici altern gradient descent algorithm hard threshold solv algorithm order magnitud faster convex relax base method lvggm addit prove algorithm guarante linear converg unknown spars low rank compon optim statist precis experi synthet genom data demonstr superior algorithm state art algorithm corrobor theori
expxorcist nonparametr graphic model via condit exponenti densiti non parametr multivari densiti estim face strong statist comput bottleneck practic approach impos near parametr assumpt form densiti function paper leverag recent develop propos class non parametr model attract comput statist properti approach reli simpl function space assumpt condit distribut variabl condit variabl non parametr exponenti famili form
reduc reparameter gradient varianc optim noisi gradient becom ubiquit statist machin learn reparameter gradient gradient estim comput via reparameter trick repres class noisi gradient often use mont carlo variat infer mcvi howev gradient estim noisi optim procedur slow fail converg way reduc nois use sampl gradient estim comput expens instead view noisi gradient random variabl form inexpens approxim generat procedur gradient sampl approxim high correl noisi gradient construct make use control variat varianc reduct demonstr approach non conjug multi level hierarch model bayesian neural net observ gradient varianc reduct multipl order magnitud 000
robust condit probabl condit probabl core concept machin learn exampl optim predict label given input correspond maxim condit probabl common approach infer task learn model condit probabl howev model often base strong assumpt log linear model henc estim condit probabl robust high depend valid assumpt propos framework reason condit probabl without assum anyth under distribut except knowledg second order margin estim data show set lead guarante bound condit probabl calcul effici varieti set includ structur predict final appli semi supervis deep learn obtain result competit variat autoencod
stein variat gradient descent gradient flow stein variat gradient descent svgd determinist sampl algorithm iter transport set particl approxim given distribut base effici gradient base updat guarante optim decreas diverg within function space paper develop first theoret analysi svgd establish empir measur svgd sampl weak converg target distribut show asymptot behavior svgd character nonlinear fokker planck equat known vlasov equat physic develop geometr perspect view svgd gradient flow diverg function new metric structur space distribut induc stein oper
parallel stream wasserstein barycent effici aggreg data differ sourc challeng problem particular sampl sourc distribut differ differ inher infer task present reason sensor sensor network place far apart affect individu measur convers comput advantag split bayesian infer task across subset data data need ident distribut across subset principl way fuse probabl distribut via len optim transport wasserstein barycent singl distribut summar collect input measur respect geometri howev comput barycent scale poor requir discret input distribut barycent improv situat present scalabl communic effici parallel algorithm comput wasserstein barycent arbitrari distribut algorithm oper direct continu input distribut optim stream data method even robust nonstationari input distribut produc barycent estim track input measur time algorithm semi discret need discret barycent estim best knowledg also provid first bound qualiti approxim barycent discret becom finer final demonstr practic effect method track move distribut sphere well larg scale bayesian infer task
aid algorithm measur accuraci probabilist infer algorithm approxim probabilist infer algorithm central mani field exampl includ sequenti mont carlo infer robot variat infer machin learn markov chain mont carlo infer statist key problem face practition measur accuraci approxim infer algorithm specif dataset exist techniqu measur infer accuraci often brittl special type infer algorithm paper introduc auxiliari infer diverg estim aid algorithm measur accuraci approxim infer algorithm aid base observ infer algorithm treat probabilist model random variabl use within infer algorithm view auxiliari variabl view lead new estim symmetr diverg output distribut infer algorithm paper illustr applic aid algorithm infer regress hidden markov dirichlet process mixtur model experi show aid captur qualit behavior broad class infer algorithm detect failur mode infer algorithm miss standard heurist
deep dynam poisson factor model new model name deep dynam poisson factor model analyz sequenti count vector propos paper model base poisson factor analysi method captur depend among time step neural network repres implicit distribut local complic relationship obtain local implicit distribut deep latent structur exploit get long time depend variat infer latent variabl gradient descent base loss function deriv variat distribut perform infer synthet dataset real world dataset appli propos model result show good predict fit perform interpret latent structur
model shrinkag effect gamma process edg partit model edg partit model epm fundament bayesian nonparametr model extract overlap structur binari matrix epm adopt gamma proce prior automat shrink number activ atom howev empir found model shrinkag epm typic work appropri lead overfit solut analysi expect epm intens function suggest gamma prior epm hyperparamet disturb model shrinkag effect intern order ensur model shrinkag effect epm work appropri manner propos novel generat construct epm cepm incorpor constrain gamma prior depm incorpor dirichlet prior instead gamma prior furthermor depm model paramet includ infinit atom prior could margin thus possibl deriv truli infinit depm idepm effici infer use collaps gibb sampler experiment confirm model shrinkag propos model work well idepm indic state art perform general abil link predict accuraci mix effici converg speed
model evid nonequilibrium simul margin likelihood model evid key quantiti bayesian paramet estim model comparison mani probabilist model comput margin likelihood challeng involv sum integr enorm paramet space markov chain mont carlo mcmc power approach comput margin likelihood various mcmc algorithm evid estim propos literatur discuss use nonequilibrium techniqu estim margin likelihood nonequilibrium estim build recent develop statist physic known anneal import sampl ai revers ai probabilist machin learn introduc new estim model evid combin forward backward simul show various challeng model new evid estim outperform forward revers ai
nice adversari train mcmc exist markov chain mont carlo mcmc method either base general purpos domain agnost scheme lead slow converg requir hand craft problem specif propos expert propos nice novel method train flexibl parametr markov chain kernel produc sampl desir properti first propos effici likelihood free adversari train method train markov chain mimic given data distribut leverag flexibl volum preserv flow obtain parametr kernel mcmc use bootstrap approach show train effici markov chain sampl prescrib posterior distribut iter improv qualiti model sampl nice provid first framework automat design effici domain specif mcmc propos empir result demonstr nice combin strong guarante mcmc express deep neural network abl signific outperform compet method hamiltonian mont carlo
identif gaussian process state space model gaussian process state space model gpssm non linear dynam system unknown transit measur map describ gps research gpssms focuss state estim problem howev key challeng gpssms satisfactorili address yet system identif address challeng impos structur gaussian variat posterior distribut latent state parameteris recognit model form direct recurr neural network infer structur allow recov posterior smooth entir sequenc data provid practic algorithm effici comput lower bound margin likelihood use reparameteris trick addit allow arbitrari kernel use within gpssm demonstr effici generat plausibl futur trajectori system seek model gpssm requir small number interact true system
stream spars gaussian process approxim spars approxim gaussian process model provid suit method enabl model deploy larg data regim enabl analyt intract sidestep howev field lack principl method handl stream data posterior distribut function valu hyperparamet updat onlin fashion small number exist approach either use suboptim hand craft heurist hyperparamet learn suffer catastroph forget slow updat new data arriv paper develop new principl framework deploy gaussian process probabilist model stream set provid principl method learn hyperparamet optimis pseudo input locat propos framework experiment valid use synthet real world dataset
bayesian optim gradient bayesian optim shown success global optim expens evalu multimod object function howev unlik optim method bayesian optim typic use deriv inform paper show bayesian optim exploit deriv inform find good solut fewer object function evalu particular develop novel bayesian optim algorithm deriv enabl knowledg gradient dkg step bay optim asymptot consist provid greater step valu inform deriv free set dkg accommod noisi incomplet deriv inform come sequenti batch form option reduc comput cost infer automat select retent singl direct deriv also comput dkg acquisit function gradient use novel fast discret free techniqu show dkg provid state art perform compar wide rang optim procedur without gradient benchmark includ logist regress deep learn kernel learn nearest neighbor
variat infer gaussian process model linear complex larg scale gaussian process infer long face practic challeng due time space complex superlinear dataset size spars variat gaussian process model capabl learn larg scale data standard strategi sparsifi model prevent approxim complex function work propos novel variat gaussian process model decoupl represent mean covari function reproduc kernel hilbert space show new parametr general previous model yield variat infer problem solv stochast gradient ascent time space complex linear number mean function paramet strategi make adopt larg scale express gaussian process model possibl run sever experi regress task show decoupl approach great outperform previous spars variat gaussian process infer procedur
effici model latent inform supervis learn use gaussian process often machin learn data collect combin multipl condit voic record multipl person label could build model captur latent inform relat condit general new data present new model call latent variabl multipl output gaussian process lvmogp allow joint model multipl condit regress general new condit data point test time lvmogp infer posterior gaussian process togeth latent space repres inform differ condit deriv effici variat infer method lvmogp comput complex low spars gaussian process show lvmogp signific outperform relat gaussian process method various task synthet real data
non stationari spectral kernel propos non stationari spectral kernel gaussian process regress propos model spectral densiti non stationari kernel function mixtur input depend gaussian process frequenc densiti surfac solv generalis fourier transform model present famili non stationari non monoton kernel learn input depend potenti long rang non monoton covari input deriv effici infer use model whiten margin posterior show case studi kernel necessari model even rather simpl time seri imag geospati data non stationari characterist
scalabl log determin gaussian process kernel learn applic vari bayesian neural network determinant point process ellipt graphic model kernel learn gaussian process gps must comput log determin posit definit matrix deriv lead prohibit comput propos novel approach estim quantiti fast matrix vector multipl mvms stochast approxim base chebyshev lanczo surrog model converg quick even kernel matric challeng spectra leverag approxim develop scalabl gaussian process approach kernel learn find lanczo general superior chebyshev kernel learn surrog approach high effici accur popular kernel
spectral mixtur kernel multi output gaussian process initi multipl output gaussian process mogp model reli linear transform independ latent singl output gaussian process gps result cross covari function limit parametr interpret thus conflict singl output gps intuit understand lengthscal frequenc magnitud name contrari current approach mogp abl better interpret relationship differ channel direct model cross covari spectral mixtur kernel phase shift propos parametr famili complex valu cross spectral densiti build cramer theorem multivari version bochner theorem provid principl approach design multivari covari function construct kernel abl model delay among channel addit phase differ thus express previous method also provid full parametr interpret relationship across channel propos method valid synthet data compar exist mogp method real world exampl
linear constrain gaussian process consid modif covari function gaussian process correct account known linear constraint model target function transform under function constraint explicit incorpor model guarante fulfil sampl drawn predict made also propos construct procedur design transform oper illustr result simul real data exampl
hindsight experi replay pieter abbeel wojciech zaremba
deal spars reward biggest challeng reinforc learn present novel techniqu call hindsight experi replay allow sampl effici learn reward spars binari therefor avoid need complic reward engin combin arbitrari polici algorithm seen form implicit curriculum demonstr approach task manipul object robot arm particular run experi differ task push slide pick place case use binari reward indic whether task complet ablat studi show hindsight experi replay crucial ingredi make train possibl challeng environ show polici train physic simul deploy physic robot success complet task video present experi avail https goo smrqni
log normal skew estim state action valu reinforc learn overestim state action valu harm reinforc learn agent paper show state action valu estim use bellman equat decompos weight sum path wise valu follow log normal distribut sinc log normal distribut skew distribut estim valu also skew lead imbalanc likelihood overestim degre imbal vari great among action polici within problem instanc make agent prone select action polici inferior expect return higher likelihood overestim present comprehens analysi skew examin factor impact theoret empir result discuss possibl way reduc undesir effect skew
finit sampl analysi gtd polici evalu algorithm markov set reinforc learn key compon polici evalu aim estim valu function expect long term accumul reward start state given polici good polici evalu method algorithm estim valu function given polici accur find better polici state space larg continu emph gradient base tempor differ gtd algorithm linear function approxim valu function wide use consid collect evalu data like time reward consum get clear understand finit sampl perform gtd algorithm import effici polici evalu entir algorithm previous work convert gtd algorithm convex concav saddl point problem provid finit sampl analysi gtd algorithm constant step size assumpt data generat howev know problem data generat markov process rather step size set differ way paper realist markov set deriv finit sampl bound expect high probabl general convex concav saddl point problem henc gtd algorithm bound show markov set variant step size gtd algorithm converg converg rate determin step size relat mix time markov process explain experi repli trick effect sinc improv mix properti markov process best knowledg analysi first provid finit sampl bound gtd algorithm markov set
invers filter hidden markov model paper consid relat invers filter problem hidden markov model hmms given sequenc state posterior system dynam estim correspond sequenc observ estim observ likelihood iii joint estim observ likelihood observ sequenc problem motiv challeng revers engin sensor includ calibr diagnost show avoid comput expens mix integ linear program milp exploit structur hmm filter provid condit quantiti uniqu recov final also consid case posterior corrupt nois shown problem natur pose cluster problem propos algorithm evalu real world polysomnograph data use automat sleep stage
safe model base reinforc learn stabil guarante reinforc learn power paradigm learn optim polici experiment data howev find optim polici reinforc learn algorithm explor possibl action harm real world system consequ learn algorithm rare appli safeti critic system real world paper present learn algorithm explicit consid safeti term stabil guarante specif extend control theoret result lyapunov stabil verif show use statist model dynam obtain high perform control polici provabl stabil certif moreov addit regular assumpt term gaussian process prior prove effect safe collect data order learn dynam thus improv control perform expand safe region state space experi show result algorithm safe optim neural network polici simul invert pendulum without pendulum ever fall
data effici reinforc learn continu state action gaussian pomdp present data effici reinforc learn method continu state action system signific observ nois data effici solut small nois exist pilco learn cartpol swing task 30s pilco evalu polici plan state trajectori use dynam model howev pilco appli polici observ state therefor plan observ space extend pilco filter instead plan belief space consist partial observ markov decis process pomdp plan enabl data effici learn signific observ nois outperform naiv method post hoc applic filter polici optimis origin unfilt pilco algorithm test method cartpol swing task involv nonlinear dynam requir nonlinear control
linear regress without correspond articl consid algorithm statist aspect linear regress correspond covari respons unknown first fulli polynomi time approxim scheme given natur least squar optim problem constant dimens next averag case nois free set respons exact correspond linear function draw standard multivari normal distribut effici algorithm base lattic basi reduct shown exact recov unknown linear function arbitrari dimens final lower bound signal nois ratio establish approxim recoveri unknown linear function
complex learn neural network stun empir success neural network current lack rigor theoret eplan form would explan take face exist complex theoret lower bound first step might show data generat neural network singl hidden layer smooth activ function benign input distribut learn effici demonstr comprehens lower bound rule possibl wide class activ function includ current use input drawn logconcav distribut famili hidden layer function whose output sum gate hard learn precis sens statist queri algorithm includ known variant stochast gradient descent loss function need exponenti number queri even use toler invers proport input dimension moreov hard famili function realiz small sublinear dimens number activ unit singl hidden layer lower bound also robust small perturb true weight systemat experi illustr phase transit train error predict analysi
near optim sketch low rank tensor regress studi least squar regress problem low rank tensor defin 1r1 vector rpd small compar denot outer product vector linear function problem motiv fact number paramet 1dpd signific smaller 1dpd number paramet ordinari least squar regress consid decomposit model tensor well tucker decomposit model show appli data dimension reduct techniqu base spars random project reduc problem much smaller problem min hold simultan obtain signific smaller dimens sparsiti random linear map possibl ordinari least squar regress final give number numer simul support theori
input sparsiti time possibl kernel low rank approxim low rank approxim common tool use acceler kernel method kernel matrix approxim via rank matrix store much less space process quick work studi limit comput effici low rank kernel approxim show broad class kernel includ popular gaussian polynomi kernel comput relat error rank approxim least difficult multipli input data matrix arbitrari matrix bar breakthrough fast matrix multipl larg requir nnz time nnz number non zero lower bound match mani paramet regim recent work subquadrat time algorithm low rank approxim general kernel mm16 mm17 demonstr algorithm unlik signific improv particular nnz input sparsiti runtim time hope show first time nnz time approxim possibl general radial basi function kernel gaussian kernel close relat problem low rank approxim kernel dataset
higher order total variat class grid minimax theori trend filter method consid problem estim valu function node dimension grid graph equal side length smash noisi observ function assum smooth allow exhibit differ amount smooth differ region grid heterogen elud classic measur smooth nonparametr statist holder smooth meanwhil total variat smooth class allow heterogen restrict anoth sens constant function count perfect smooth achiev move past consid higher order class base way compil discret deriv paramet across node relat class holder class deriv minimax error rate higher order class analyz natur associ trend filter method seen optim appropri class
adapt cluster semidefinit program analyz cluster problem flexibl probabilist model aim identifi optim partit sampl perform exact cluster high probabl use convex semidefinit estim interpret correct relax version mean estim analyz non asymptot framework show optim near optim recov partit furthermor perform shown adapt problem effect dimens well unknown number group partit illustr method perform comparison classic cluster algorithm numer experi simul data
compress gram matrix learn neural network polynomi time consid problem learn function class comput neural network various activ relu sigmoid task believ intract worst case major open problem understand minim assumpt class admit effici algorithm work show natur distribut assumpt eigenvalu decay gram matrix yield polynomi time algorithm non realiz set express class network feed forward network relus make assumpt network architectur label given suffici strong polynomi eigenvalu decay obtain fulli polynomi time algorithm paramet respect squar loss milder decay also lead improv algorithm awar prior work assumpt margin distribut alon lead polynomi time algorithm network relus even hidden layer unlik prior assumpt margin distribut gaussian eigenvalu decay observ practic common data set algorithm appli function class embed suitabl rkhs main technic contribut new approach prove general bound kernel regress use compress scheme oppos rademach bound general known sampl complex bound kernel method must depend norm correspond rkhs quick becom larg depend kernel function employ sidestep worst case bound sparsifi gram matrix use recent work recurs nystrom sampl due musco musco prove approxim spars hypothesi admit compress scheme whose true error depend rate eigenvalu decay
learn averag top loss work introduc averag top atk loss new ensembl loss supervis learn atk loss provid natur general wide use ensembl loss name averag loss maximum loss furthermor atk loss combin advantag allevi correspond drawback better adapt differ data distribut show atk loss afford intuit interpret reduc penalti continu convex individu loss correct classifi data atk loss lead convex optim problem solv effect convent sub gradient base method studi statist learn theori matk establish classif calibr statist consist matk provid use insight practic choic paramet demonstr applic matk learn combin differ individu loss function binari multi class classif regress use synthet real dataset
hierarch cluster beyond worst case hiererach cluster comput recurs partit dataset obtain cluster increas finer granular fundament problem data analysi although hierarch cluster most studi procedur linkag algorithm top heurist rather optim problem recent dasgupta propos object function hierarch cluster initi line work develop algorithm explicit optim object see also paper consid fair general random graph model hierarch cluster call hierarch stochast blockmodel hsbm show certain regim svd approach mcsherri combin specif linkag method result cluster give approxim dasgupta cost function also show approach base sdp relax balanc cut base work makarychev combin recurs sparsest cut algorithm dasgupta yield approxim slight larger regim also semi random set adversari remov edg random graph generat accord hsbm final report empir evalu synthet real world data show propos svd base method inde achiev better cost wide use heurstic also result better classif accuraci under problem multi class classif
net trim convex prune deep neural network perform guarante introduc analyz new techniqu model reduct deep neural network larg network theoret capabl learn arbitrarili complex model overfit model redund negat affect predict accuraci model varianc net trim algorithm prune sparsifi train network layer wise remov connect layer solv convex optim program program seek spars set weight layer keep layer input output consist origin train model algorithm associ analysi applic neural network oper rectifi linear unit relu nonlinear activ present parallel cascad version algorithm latter achiev slight simpler model general perform former comput distribut manner case net trim signific reduc number connect network also provid enough regular slight reduc general error also provid mathemat analysi consist initi network retrain model analyz model sampl complex deriv general suffici condit recoveri spars transform matrix singl layer take independ gaussian random vector input show network respons describ use maximum number non weight per node weight learn slog sampl
graph theoret approach multitask key featur neural network architectur abil support simultan interact among larg number unit learn process represent howev rich interact trade abil network simultan carri multipl independ process salient limit mani domain human cognit remain larg unexplor paper use graph theoret analysi network architectur address question task repres edg bipartit graph defin new measur multitask capac network base assumpt task emph need multitask reli independ resourc form match task emph perform without interfer form induc match main result inher tradeoff multitask capac averag degre network hold emph regardless network architectur result also extend network depth greater
posit side demonstr network random like local spars desir multitask properti result shed light parallel process limit neural system provid insight use analysi design parallel architectur
inform theoret analysi general capabl learn algorithm deriv upper bound general error learn algorithm term mutual inform input output upper bound provid theoret guidelin strike right balanc data fit general control input output mutual inform learn algorithm result also use analyz general capabl learn algorithm adapt composit bias accuraci tradeoff adapt data analyt work extend lead nontrivi improv recent result russo zou
independ cluster without matrix independ cluster problem consid follow formul given set random variabl requir find finest partit cluster cluster mutual independ sinc mutual independ target pairwis similar measur use thus tradit cluster algorithm inapplic distribut random variabl general unknown sampl avail thus problem cast term time seri form sampl consid stationari time seri main emphasi latter general case consist comput tractabl algorithm set propos number fascin open direct research outlin
polynomi code optim design high dimension code matrix multipl consid larg scale matrix multipl problem comput carri use distribut system master node multipl worker node worker store part input matric propos comput strategi leverag idea code theori design intermedi comput worker node order effici deal straggl worker propos strategi name emph polynomi code achiev optimum recoveri threshold defin minimum number worker master need wait order comput output furthermor leverag algebra structur polynomi code map reconstruct problem final output polynomi interpol problem solv effici polynomi code provid order wise improv state art term recoveri threshold also optim term sever metric furthermor extend code distribut convolut show order wise optim
estim mutual inform discret continu mixtur estim mutual inform observ sampl basic primit machin learn use sever learn task includ correl mine inform bottleneck chow liu tree condit independ test causal graphic model mutual inform quantiti well defin general probabl space estim develop special case discret continu pair random variabl estim oper use principl calcul differenti entropi pair howev general mixtur space individu entropi well defin even though mutual inform paper develop novel estim estim mutual inform discret continu mixtur prove consist estim theoret well demonstr excel empir perform problem relev wide array applic variabl discret continu other mixtur continu discret compon
best respons regress regress task predictor given set instanc along real valu point subsequ identifi valu new instanc accur possibl work initi studi strateg predict machin learn consid regress task tackl player payoff player proport point predict accur player first revis probabl approxim correct learn framework deal case duel predictor devis algorithm find linear regress predictor best respons necessarili linear regress algorithm show linearithm sampl complex polynomi time complex dimens instanc domain fix also test approach high dimension set show signific defeat classic regress algorithm predict duel togeth work introduc novel machin learn task lend well current competit onlin set provid theoret foundat illustr applic
statist cost share studi cost share problem cooper game situat cost function avail via oracl queri must instead learn sampl drawn distribut repres tupl differ subset player formal approach call statist cost share consid comput core shapley valu expand work balcan 2015 give precis sampl complex bound comput cost share satisfi core properti high probabl function non empti core shapley valu never studi set show submodular cost function curvatur bound curvatur approxim sampl uniform distribut factor bound tight defin statist analogu shapley axiom deriv notion statist shapley valu approxim arbitrarili well sampl distribut function
sampl complex measur applic learn optim auction introduc new sampl complex measur refer split sampl growth rate hypothesi sampl size split sampl growth rate count mani differ hypothes empir risk minim output sub sampl size show expect general error upper bound log result enabl strengthen rademach complex analysi expect general error show sampl complex measur great simplifi analysi sampl complex optim auction design mani auction class studi literatur sampl complex deriv sole notic auction class erm sampl sub sampl pick paramet equal point sampl
multipl weight updat constant step size congest game converg limit cycl chao multipl weight updat mwu method ubiquit meta algorithm work follow distribut maintain certain set step probabl assign action multipli cost action rescal ensur new valu form distribut analyz mwu congest game agent use textit arbitrari admiss constant learn rate prove converg textit exact nash equilibria interest converg result carri near homolog mwu variant step probabl assign action multipli even innocu case agent strategi load balanc game dynam provabl lead limit cycl even chaotic behavior
effici guarante data analysi effici outcom game theoret set main item studi intersect econom comput scienc notion price anarchi take worst case stanc effici analysi consid instanc independ guarante effici propos data depend analog price anarchi refin worst case assum access sampl strateg behavior focus auction set latter non trivial due privat inform held particip approach bound effici data robust statist error mis specif unlik tradit econometr seek learn privat inform player observ behavior analyz properti outcom direct quantifi ineffici without go privat inform appli approach dataset sponsor search auction system find empir result signific improv bound worst case analysi
safe nest subgam solv imperfect inform game unlik perfect inform game imperfect inform game cannot solv decompos game subgam solv independ thus comput intens equilibrium find techniqu use decis must consid strategi game whole possibl solv imperfect inform game exact decomposit possibl approxim solut improv exist solut solv disjoint subgam process refer subgam solv introduc subgam solv techniqu outperform prior method theori practic also show adapt past subgam solv techniqu respond oppon action outsid origin action abstract signific outperform prior state art approach action translat final show subgam solv repeat game progress tree lead signific lower exploit appli techniqu develop first defeat top human head limit texa hold poker
